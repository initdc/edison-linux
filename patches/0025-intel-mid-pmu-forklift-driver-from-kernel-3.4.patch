From 4a6cc01f44b5cb6870c6fe68e8e3714c1946c498 Mon Sep 17 00:00:00 2001
From: David Cohen <david.a.cohen@intel.com>
Date: Tue, 9 Jul 2013 13:56:17 -0700
Subject: [PATCH 025/429] intel-mid, pmu: forklift driver from kernel 3.4

Signed-off-by: David Cohen <david.a.cohen@intel.com>
---
 arch/x86/platform/intel-mid/Makefile          |    6 +
 arch/x86/platform/intel-mid/intel_soc_clv.c   |  145 +
 arch/x86/platform/intel-mid/intel_soc_clv.h   |  352 +++
 arch/x86/platform/intel-mid/intel_soc_dump.c  | 1586 +++++++++++
 arch/x86/platform/intel-mid/intel_soc_mdfld.c |  177 ++
 arch/x86/platform/intel-mid/intel_soc_mdfld.h |  353 +++
 .../intel-mid/intel_soc_mdfld_clv_common.c    |  451 +++
 arch/x86/platform/intel-mid/intel_soc_mrfld.c |  328 +++
 arch/x86/platform/intel-mid/intel_soc_mrfld.h |  156 ++
 .../platform/intel-mid/intel_soc_pm_debug.c   | 2479 +++++++++++++++++
 .../platform/intel-mid/intel_soc_pm_debug.h   |  234 ++
 arch/x86/platform/intel-mid/intel_soc_pmu.c   | 2010 +++++++++++++
 arch/x86/platform/intel-mid/intel_soc_pmu.h   |  507 ++++
 drivers/pci/Makefile                          |    1 +
 drivers/pci/pci-atom_soc.c                    |   78 +
 15 files changed, 8863 insertions(+)
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_clv.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_clv.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_dump.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mdfld.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mdfld.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mdfld_clv_common.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mrfld.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_mrfld.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pm_debug.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pm_debug.h
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pmu.c
 create mode 100644 arch/x86/platform/intel-mid/intel_soc_pmu.h
 create mode 100644 drivers/pci/pci-atom_soc.c

diff --git a/arch/x86/platform/intel-mid/Makefile b/arch/x86/platform/intel-mid/Makefile
index 607ab5fcf874..cbdda58cff57 100644
--- a/arch/x86/platform/intel-mid/Makefile
+++ b/arch/x86/platform/intel-mid/Makefile
@@ -16,3 +16,9 @@ obj-$(CONFIG_X86_INTEL_MID) += intel_mid_scu.o
 >>>>>>> 6a9f567... intel_mid: Added intel mid scu remoteproc init code.
 # BOARD files
 obj-$(CONFIG_X86_INTEL_MID) += board.o
+
+# PMU driver
+obj-$(CONFIG_ATOM_SOC_POWER) += intel_soc_pmu.o intel_soc_pm_debug.o intel_soc_dump.o
+obj-$(CONFIG_REMOVEME_INTEL_ATOM_MDFLD_POWER) += intel_soc_mdfld.o intel_soc_mdfld_clv_common.o
+obj-$(CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER) += intel_soc_clv.o intel_soc_mdfld_clv_common.o
+obj-$(CONFIG_REMOVEME_INTEL_ATOM_MRFLD_POWER) += intel_soc_mrfld.o
diff --git a/arch/x86/platform/intel-mid/intel_soc_clv.c b/arch/x86/platform/intel-mid/intel_soc_clv.c
new file mode 100644
index 000000000000..0e5ce8bbde43
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_clv.c
@@ -0,0 +1,145 @@
+/*
+ * intel_soc_clv.c - This driver provides utility api's for
+ * Cloverview platform
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+
+
+static unsigned short fastonoff_flag;
+
+static ssize_t fastonoff_show(struct kobject *kobj,
+					struct kobj_attribute *attr, char *buf)
+{
+		return sprintf(buf, "%hu\n", fastonoff_flag);
+}
+
+static ssize_t fastonoff_store(struct kobject *kobj,
+			struct kobj_attribute *attr, const char *buf, size_t n)
+{
+	unsigned short value;
+	if (sscanf(buf, "%hu", &value) != 1 ||
+	    (value != 0 && value != 1)) {
+		printk(KERN_ERR "fastonoff_store: Invalid value\n");
+		return -EINVAL;
+	}
+	fastonoff_flag = value;
+	return n;
+}
+
+static struct kobj_attribute fast_onoff_attr =
+	__ATTR(fastonoff, 0644, fastonoff_show, fastonoff_store);
+
+
+static void clv_init_sysfsfs(void)
+{
+	int error;
+	error = sysfs_create_file(power_kobj, &fast_onoff_attr.attr);
+	if (error)
+		printk(KERN_ERR "sysfs_create_file failed: %d\n", error);
+}
+
+static int clv_pmu_init(void)
+{
+	mid_pmu_cxt->s3_hint = C6_HINT;
+	clv_init_sysfsfs();
+	return 0;
+}
+
+static bool clv_pmu_enter(int s0ix_state)
+{
+	u32 s0ix_value;
+	int num_retry = PMU_MISC_SET_TIMEOUT;
+
+	if (fastonoff_flag && (s0ix_state == MID_S3_STATE))
+		s0ix_value = get_s0ix_val_set_pm_ssc(MID_FAST_ON_OFF_STATE);
+	else
+		s0ix_value = get_s0ix_val_set_pm_ssc(s0ix_state);
+
+	/* issue a command to SCU */
+	writel(s0ix_value, &mid_pmu_cxt->pmu_reg->pm_cmd);
+
+	do {
+		if (readl(&mid_pmu_cxt->pmu_reg->pm_msic))
+			break;
+		udelay(1);
+	} while (--num_retry);
+
+	if (!num_retry && !readl(&mid_pmu_cxt->pmu_reg->pm_msic))
+		WARN(1, "%s: pm_msic not set.\n", __func__);
+
+	mid_pmu_cxt->s0ix_entered = s0ix_state;
+
+	return true;
+}
+
+static void clv_pmu_remove(void)
+{
+	/* Place holder */
+}
+
+static void clv_pmu_wakeup(void)
+{
+
+	/* Wakeup allother CPU's */
+	if (mid_pmu_cxt->s0ix_entered)
+		apic->send_IPI_allbutself(RESCHEDULE_VECTOR);
+}
+
+static pci_power_t clv_pmu_choose_state(int device_lss)
+{
+	pci_power_t state;
+
+	switch (device_lss) {
+	case PMU_SECURITY_LSS_04:
+		state = PCI_D2;
+		break;
+
+	case PMU_USB_OTG_LSS_06:
+	case PMU_USB_HSIC_LSS_07:
+	case PMU_UART2_LSS_41:
+		state = PCI_D1;
+		break;
+
+	default:
+		state = PCI_D3hot;
+		break;
+	}
+
+	return state;
+}
+
+/**
+ *      platform_set_pmu_ops - Set the global pmu method table.
+ *      @ops:   Pointer to ops structure.
+ */
+void platform_set_pmu_ops(void)
+{
+	pmu_ops = &clv_pmu_ops;
+}
+
+struct platform_pmu_ops clv_pmu_ops = {
+	.init		= clv_pmu_init,
+	.enter		 = clv_pmu_enter,
+	.wakeup		 = clv_pmu_wakeup,
+	.remove		= clv_pmu_remove,
+	.pci_choose_state = clv_pmu_choose_state,
+	.set_power_state_ops = pmu_set_s0ix_possible,
+	.set_s0ix_complete = s0ix_complete,
+	.nc_set_power_state = mdfld_clv_nc_set_power_state,
+};
diff --git a/arch/x86/platform/intel-mid/intel_soc_clv.h b/arch/x86/platform/intel-mid/intel_soc_clv.h
new file mode 100644
index 000000000000..0b8294eee836
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_clv.h
@@ -0,0 +1,352 @@
+/*
+ * intel_soc_clv.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER
+
+#define   PM_SUPPORT				0x21
+
+#define ISP_POS			7
+#define ISP_SUB_CLASS		0x80
+#define PMU_MISC_SET_TIMEOUT	15000
+
+#define PMU1_MAX_DEVS   8
+#define PMU2_MAX_DEVS   55
+
+#define GFX_LSS_INDEX			1
+#define PMU_SDIO0_LSS_00		0
+#define PMU_EMMC0_LSS_01		1
+#define PMU_AONT_LSS_02			2
+#define PMU_HSI_LSS_03			3
+#define PMU_SECURITY_LSS_04		4
+#define PMU_EMMC1_LSS_05		5
+#define PMU_USB_OTG_LSS_06		6
+#define PMU_USB_HSIC_LSS_07		7
+#define PMU_AUDIO_ENGINE_LSS_08		8
+#define PMU_AUDIO_DMA_LSS_09		9
+#define PMU_SRAM_LSS_10			10
+#define PMU_SRAM_LSS_11			11
+#define PMU_SRAM_LSS_12			12
+#define PMU_SRAM_LSS_13			13
+#define PMU_SDIO2_LSS_14		14
+#define PMU_PTI_DAFCA_LSS_15		15
+#define PMU_SC_DMA_LSS_16		16
+#define PMU_SPIO_LSS_17			17
+#define PMU_SPI1_LSS_18			18
+#define PMU_SPI2_LSS_19			19
+#define PMU_I2C0_LSS_20			20
+#define PMU_I2C1_LSS_21			21
+#define PMU_HPET_LSS_22			22
+#define PMU_EXTTMR_LSS_23		23
+#define PMU_SC_FABRIC_LSS_24		24
+#define PMU_AUDIO_RAM_LSS_25		25
+#define PMU_SCU_ROM_LSS_26		26
+#define PMU_I2C2_LSS_27			27
+#define PMU_SSC_LSS_28			28
+#define PMU_SECURITY_LSS_29		29
+#define PMU_SDIO1_LSS_30		30
+#define PMU_vRTC_LSS_31			31
+#define PMU_SEC_TIMER_LSS_32		32
+#define PMU_I2C3_LSS_33			33
+#define PMU_I2C4_LSS_34			34
+#define PMU_I2C5_LSS_35			35
+#define PMU_SPI3_LSS_36			36
+#define PMU_GPIO1_LSS_37		37
+#define PMU_PWR_BUTTON_LSS_38		38
+#define PMU_GPIO0_LSS_39		39
+#define PMU_KEYBRD_LSS_40		40
+#define PMU_UART2_LSS_41		41
+#define PMU_ADC_LSS_42			42
+#define PMU_CHARGER_LSS_43		43
+#define PMU_SEC_TAPC_LSS_44		44
+#define PMU_RTC_LSS_45			45
+#define PMU_GPI_LSS_46			46
+#define PMU_BCU_LSS_47			47
+#define PMU_SSP2_LSS_48			48
+#define PMU_AUDIO_SLIM1_LSS_49		49
+#define PMU_AUDIO_SLIM2_LSS_50		50
+#define PMU_AUDIO_SSP0_LSS_51		51
+#define PMU_AUDIO_SSP1_LSS_52		52
+#define PMU_IOSF_OCP_BRG_LSS_53		53
+#define PMU_GP_DMA_LSS_54		54
+#define PMU_MSIC_RESET_LSS_55		55
+#define PMU_SOC_FUSE_LSS_56		56
+#define PMU_RSVD3_LSS_57		57
+#define PMU_SSP4_LSS_58			58
+#define PMU_RSVD5_LSS_59		59
+#define PMU_RSVD6_LSS_60		60
+#define PMU_RSVD7_LSS_61		61
+#define PMU_RSVD8_LSS_62		62
+#define PMU_RSVD9_LSS_63		63
+
+#define PMU_MAX_LSS			63
+#define PMU_LSS_IN_FIRST_DWORD		32
+
+#define EMMC0_LSS			PMU_EMMC0_LSS_01
+
+#define S0IX_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+#define S0IX_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define S0IX_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0IX_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I0_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define IGNORE_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_10) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_11) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_12) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_13) | \
+	SSMSK(D0I3_MASK, PMU_PTI_DAFCA_LSS_15))
+
+#define IGNORE_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SC_DMA_LSS_16-16) | \
+	SSMSK(D0I3_MASK, PMU_SPIO_LSS_17-16) | \
+	SSMSK(D0I3_MASK, PMU_HPET_LSS_22-16) | \
+	SSMSK(D0I3_MASK, PMU_EXTTMR_LSS_23-16) | \
+	SSMSK(D0I3_MASK, PMU_SC_FABRIC_LSS_24-16) | \
+	SSMSK(D0I3_MASK, PMU_SCU_ROM_LSS_26-16) | \
+	SSMSK(D0I3_MASK, PMU_SSC_LSS_28-16) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_29-16) | \
+	SSMSK(D0I3_MASK, PMU_vRTC_LSS_31-16))
+
+#define IGNORE_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_SEC_TIMER_LSS_32-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO0_LSS_39-32) | \
+	SSMSK(D0I3_MASK, PMU_ADC_LSS_42-32) | \
+	SSMSK(D0I3_MASK, PMU_CHARGER_LSS_43-32) | \
+	SSMSK(D0I3_MASK, PMU_SEC_TAPC_LSS_44-32) | \
+	SSMSK(D0I3_MASK, PMU_RTC_LSS_45-32) | \
+	SSMSK(D0I3_MASK, PMU_GPI_LSS_46-32) | \
+	SSMSK(D0I3_MASK, PMU_BCU_LSS_47-32))
+
+#define IGNORE_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_IOSF_OCP_BRG_LSS_53-48) | \
+	SSMSK(D0I3_MASK, PMU_MSIC_RESET_LSS_55-48) | \
+	SSMSK(D0I3_MASK, PMU_SOC_FUSE_LSS_56-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD3_LSS_57-48) | \
+	SSMSK(D0I3_MASK, PMU_SSP4_LSS_58-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD5_LSS_59-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD6_LSS_60-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD7_LSS_61-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD8_LSS_62-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD9_LSS_63-48))
+
+#define IGNORE_S3_WKC0 SSWKC(PMU_AONT_LSS_02)
+#define IGNORE_S3_WKC1 SSWKC(PMU_ADC_LSS_42-32)
+
+/* FIXME:: CVT Platform gives SRAM Error if SRAM is put in D0i3 */
+#define S0I3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0I3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_RAM_LSS_25-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0I3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0I3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM2_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+#define S0I1_SSS0 S0I3_SSS0
+#define S0I1_SSS1 S0I3_SSS1
+#define S0I1_SSS2 S0I3_SSS2
+#define S0I1_SSS3 S0I3_SSS3
+
+#define LPMP3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM2_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+extern void pmu_set_s0ix_possible(int state);
+extern void log_wakeup_irq(void);
+extern void s0ix_complete(void);
+extern int mdfld_clv_nc_set_power_state(int, int, int, int *);
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_dump.c b/arch/x86/platform/intel-mid/intel_soc_dump.c
new file mode 100644
index 000000000000..2441b1cf9f3e
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_dump.c
@@ -0,0 +1,1586 @@
+/*
+ * intel_soc_dump.c - This driver provides a debugfs interface to read or
+ * write any registers inside the SoC. Supported access methods are:
+ * mmio, msg_bus, pci and i2c.
+ *
+ * Copyright (c) 2012, Intel Corporation.
+ * Author: Bin Gao <bin.gao@intel.com>
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+/*
+ * Two files are created in debugfs root folder: dump_cmd and dump_output.
+ * Echo a dump command to the file dump_cmd, and then cat the file dump_output.
+ * Even for write command, you still have to run "cat dump_output", otherwise
+ * the data will not be really written.
+ *
+ * It works like this:
+ * $ echo "dump command" > dump_cmd
+ * $ cat dump_output
+ *
+ * I/O memory read: echo "r[1|2|4] mmio <addr> [<len>]" > dump_cmd
+ *     e.g.  echo "r mmio 0xff180000" > dump_cmd
+ *
+ * I/O memory write: echo "w[1|2|4] <addr> <val>" > dump_cmd
+ *     e.g.  echo "w mmio 0xff190000 0xf0107a08" > dump_cmd
+ *
+ * I/O port read: echo "r[1|2|4] port <port>" > dump_cmd
+ *     e.g.  echo "r port 0xcf8" > dump_cmd
+ *
+ * I/O port write: echo "w[1|2|4] <port> <val>" > dump_cmd
+ *     e.g.  echo "w4 port 0xcfc 0x80002188" > dump_cmd
+ *
+ * message bus read: echo "r msg_bus <port> <addr> [<len>]" > dump_cmd
+ *     e.g.  echo "r msg_bus 0x02 0x30" > dump_cmd
+ *
+ * message bus write: echo "w msg_bus <port> <addr> <val>" > dump_cmd
+ *     e.g.  echo "w msg_bus 0x02 0x30 0x1020003f" > dump_cmd
+ *
+ * pci config read: echo "r[1|2|4] pci <bus> <dev> <func> <reg> [<len>]" >
+ * dump_cmd
+ *     e.g.  echo "r1 pci 0 2 0 0x20" > dump_cmd
+ *
+ * pci config write: echo "w[1|2|4] pci <bus> <dev> <func> <reg> <value>" >
+ * dump_cmd
+ *     e.g.  echo "w pci 0 2 0 0x20 0x380020f3" > dump_cmd
+ *
+ * msr read: echo "r[4|8]  msr [<cpu>|all] <reg>" > dump_cmd
+ * read cab be 32bit(r4) or 64bit(r8), default is r8 (=r)
+ * cpu can be 0, 1, 2, 3, ... or all, default is all
+ *     e.g.  echo "r msr 0 0xcd" > dump_cmd
+ *     (read all cpu's msr reg 0xcd in 64bit mode)
+ *
+ * msr write: echo "w[4|8] msr [<cpu>|all] <reg> <val>" > dump_cmd
+ * write cab be 32bit(w4) or 64bit(w8), default is w8 (=w)
+ * cpu can be 0, 1, 2, 3, ... or all, default is all
+ *     e.g.  echo "w msr 1 289 0xf03090a0cc73be64" > dump_cmd
+ *     (write value 0xf03090a0cc73be64 to cpu 1's msr reg 289 in 64bit mode)
+ *
+ * i2c read:  echo "r i2c <bus> <addr>" > dump_cmd
+ *     e.g.  echo "r i2c 1 0x3e" > dump_cmd
+ *
+ * i2c write: echo "w i2c <bus> <addr> <val>" > dump_cmd
+ *      e.g.  echo "w i2c 2 0x70 0x0f" > dump_cmd
+ *
+ * SCU indirect memory read: echo "r[4] scu <addr>" > dump_cmd
+ *     e.g.  echo "r scu 0xff108194" > dump_cmd
+ *
+ * SCU indirect memory write: echo "w[4] scu <addr> <val>" > dump_cmd
+ *     e.g.  echo "w scu 0xff108194 0x03000001" > dump_cmd
+ *
+ *  SCU indirect read/write is limited to those addresses in
+ *  IndRdWrValidAddrRange array in SCU FW.
+ *
+ */
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/debugfs.h>
+#include <linux/io.h>
+#include <linux/err.h>
+#include <linux/seq_file.h>
+#include <linux/i2c.h>
+#include <linux/pm_runtime.h>
+#include <asm/uaccess.h>
+#include <asm/intel-mid.h>
+#include <asm/processor.h>
+#include <asm/msr.h>
+#include <asm/intel_mid_rpmsg.h>
+
+#define MAX_CMDLEN		96
+#define MAX_ERRLEN		255
+#define MIN_ARGS_NUM		3
+#define MAX_ARGS_NUM		8
+#define MAX_MMIO_PCI_LEN	4096
+#define MAX_MSG_BUS_LEN		64
+
+#define ACCESS_WIDTH_DEFAULT	0
+#define ACCESS_WIDTH_8BIT	1
+#define ACCESS_WIDTH_16BIT	2
+#define ACCESS_WIDTH_32BIT	4
+#define ACCESS_WIDTH_64BIT	8
+
+#define ACCESS_BUS_MMIO		1 /* I/O memory */
+#define ACCESS_BUS_PORT		2 /* I/O port */
+#define ACCESS_BUS_MSG_BUS	3 /* message bus */
+#define ACCESS_BUS_PCI		4 /* PCI bus */
+#define ACCESS_BUS_MSR		5 /* MSR registers */
+#define ACCESS_BUS_I2C		6 /* I2C bus */
+#define ACCESS_BUS_SCU_INDRW	7 /* SCU indirect read/write */
+
+#define ACCESS_DIR_READ		1
+#define ACCESS_DIR_WRITE	2
+
+#define RP_INDIRECT_READ	0x02 /* MSG_ID for indirect read via SCU */
+#define RP_INDIRECT_WRITE	0x05 /* MSG_ID for indirect write via SCU */
+
+#define SHOW_NUM_PER_LINE	(32 / access_width)
+#define LINE_WIDTH		(access_width * SHOW_NUM_PER_LINE)
+#define IS_WHITESPACE(c)	((c) == ' ' || (c) == '\t' || (c) == '\n')
+#define ADDR_RANGE(start, size, addr) \
+	((addr >= start) && (addr < (start + size)))
+
+/* mmio <--> device map */
+struct mmio_pci_map {
+	u32 start;
+	size_t size;
+	u32 pci_bus:8;
+	u32 pci_dev:8;
+	u32 pci_func:8;
+	char name[24];
+};
+
+static struct dentry *dump_cmd_dentry, *dump_output_dentry;
+static int dump_cmd_was_set;
+static char dump_cmd_buf[MAX_CMDLEN], err_buf[MAX_ERRLEN + 1];
+
+static int access_dir, access_width, access_bus, access_len;
+static u32 access_value;
+static u64 access_value_64;
+
+/* I/O memory */
+static u32 mmio_addr;
+
+/* I/O port */
+static unsigned port_addr;
+
+/* msg_bus */
+static u8 msg_bus_port;
+static u32 msg_bus_addr;
+
+/* pci */
+static u8 pci_bus, pci_dev, pci_func;
+static u16 pci_reg;
+
+/* msr */
+static int msr_cpu;
+static u32 msr_reg;
+
+/* i2c */
+static u8 i2c_bus;
+static u32 i2c_addr;
+
+/* scu */
+static u32 scu_addr;
+
+static const struct mmio_pci_map soc_pnw_map[] = {
+	{ 0xff128000, 0x400, 0, 0, 1, "SPI0" },
+	{ 0xff128400, 0x400, 0, 0, 2, "SPI1" },
+	{ 0xff128800, 0x400, 0, 2, 4, "SPI2" },
+
+	{ 0xff12a000, 0x400, 0, 0, 3, "I2C0" },
+	{ 0xff12a400, 0x400, 0, 0, 4, "I2C1" },
+	{ 0xff12a800, 0x400, 0, 0, 5, "I2C2" },
+	{ 0xff12ac00, 0x400, 0, 3, 2, "I2C3" },
+	{ 0xff12b000, 0x400, 0, 3, 3, "I2C4" },
+	{ 0xff12b400, 0x400, 0, 3, 4, "I2C5" },
+
+	{ 0xffae5800, 0x400, 0, 2, 7, "SSP0" },
+	{ 0xffae6000, 0x400, 0, 1, 4, "SSP1" },
+	{ 0xffae6400, 0x400, 0, 1, 3, "SSP2" },
+	{ 0xffaf0000, 0x800, 0, 2, 6, "LPE DMA1" },
+
+	{ 0xff0d0000, 0x10000, 0, 1, 5, "SEP SECURITY" },
+	{ 0xff11c000, 0x400, 0, 1, 7, "SCU IPC1" },
+
+	{ 0xdff00000, 0x100000, 0, 2, 0, "GVD BAR0" },
+	{ 0x40000000, 0x10000000, 0, 2, 0, "GVD BAR2" },
+	{ 0xdfec0000, 0x40000, 0, 2, 0, "GVD BAR3" },
+
+	{ 0xff11d000, 0x1000, 0, 2, 2, "PMU" },
+	{ 0xffa60000, 0x20000, 0, 2, 3, "USB OTG" },
+
+	{ 0xdf800000, 0x400000, 0, 3, 0, "ISP" },
+
+	{ 0xff12c000, 0x800, 0, 2, 1, "GPIO0" },
+	{ 0xff12c800, 0x800, 0, 3, 5, "GPIO1" },
+	{ 0xff12b800, 0x800, 0, 2, 5, "GP DMA" },
+
+	{ 0xffa58000, 0x100, 0, 4, 0, "SDIO0(HC2)" },
+	{ 0xffa5c000, 0x100, 0, 4, 1, "SDIO1(HC1a)" },
+	{ 0xffa2a000, 0x100, 0, 4, 2, "SDIO3(HC1b)" },
+	{ 0xffa50000, 0x100, 0, 1, 0, "SDIO3/eMMC0(HC0a)" },
+	{ 0xffa54000, 0x100, 0, 1, 1, "SDIO4/eMMC1(HC0b)" },
+
+	{ 0xffa28080, 0x80, 0, 5, 0, "UART0" },
+	{ 0xffa28100, 0x80, 0, 5, 1, "UART1" },
+	{ 0xffa28180, 0x80, 0, 5, 2, "UART2" },
+	{ 0xffa28400, 0x400, 0, 5, 3, "UART DMA" },
+
+	{ 0xffa2e000, 0x400, 0, 6, 0, "PTI" },
+
+	/* no address assigned:	{ 0x0, 0, 0, 6, 1, "xx" }, */
+
+	{ 0xffa29000, 0x800, 0, 6, 3, "HSI" },
+	{ 0xffa29800, 0x800, 0, 6, 4, "HSI DMA" },
+};
+
+static const struct mmio_pci_map soc_clv_map[] = {
+	{ 0xff138000, 0x400, 0, 0, 3, "I2C0" },
+	{ 0xff139000, 0x400, 0, 0, 4, "I2C1" },
+	{ 0xff13a000, 0x400, 0, 0, 5, "I2C2" },
+	{ 0xff13b000, 0x400, 0, 3, 2, "I2C3" },
+	{ 0xff13c000, 0x400, 0, 3, 3, "I2C4" },
+	{ 0xff13d000, 0x400, 0, 3, 4, "I2C5" },
+
+	{ 0xff128000, 0x400, 0, 0, 1, "SPI0/MSIC" },
+	{ 0xff135000, 0x400, 0, 0, 2, "SPI1" },
+	{ 0xff136000, 0x400, 0, 2, 4, "SPI2" },
+	/* invisible to IA: { 0xff137000, 0, -1, -1, -1, "SPI3" }, */
+
+	{ 0xffa58000, 0x100, 0, 4, 0, "SDIO0 (HC2)" },
+	{ 0xffa48000, 0x100, 0, 4, 1, "SDIO1 (HC1a)" },
+	{ 0xffa4c000, 0x100, 0, 4, 2, "SDIO2 (HC1b)" },
+	{ 0xffa50000, 0x100, 0, 1, 0, "SDIO3/eMMC0 (HC0a)" },
+	{ 0xffa54000, 0x100, 0, 1, 1, "SDIO4/eMMC1 (HC0b)" },
+
+	{ 0xff119000, 0x800, 0, 2, 1, "GPIO0" },
+	{ 0xff13f000, 0x800, 0, 3, 5, "GPIO1" },
+	{ 0xff13e000, 0x800, 0, 2, 5, "GP DMA" },
+
+	{ 0xffa20000, 0x400, 0, 2, 7, "SSP0" },
+	{ 0xffa21000, 0x400, 0, 1, 4, "SSP1" },
+	{ 0xffa22000, 0x400, 0, 1, 3, "SSP2" },
+	/* invisible to IA: { 0xffa23000, 0, -1, -1, -1, "SSP3" }, */
+
+	/* invisible to IA: { 0xffaf8000, 0, -1, -1, -1, "LPE DMA0" }, */
+	{ 0xffaf0000, 0x800, 0, 2, 6, "LPE DMA1" },
+	{ 0xffae8000, 0x1000, 0, 1, 3, "LPE SHIM" },
+	/* { 0xffae9000, 0, 0, 6, 5, "VIBRA" }, LPE SHIM BASE + 0x1000 */
+
+	{ 0xffa28080, 0x80, 0, 5, 0, "UART0" },
+	{ 0xffa28100, 0x80, 0, 5, 1, "UART1" },
+	{ 0xffa28180, 0x80, 0, 5, 2, "UART2" },
+	{ 0xffa28400, 0x400, 0, 5, 3, "UART DMA" },
+
+	{ 0xffa29000, 0x800, 0, 6, 3, "HSI" },
+	{ 0xffa2a000, 0x800, 0, 6, 4, "HSI DMA" },
+
+	{ 0xffa60000, 0x20000, 0, 2, 3, "USB OTG" },
+	{ 0xffa80000, 0x60000, 0, 6, 5, "USB SPH" },
+
+	{ 0xff0d0000, 0x10000, 0, 1, 5, "SEP SECURITY" },
+
+	{ 0xdff00000, 0x100000, 0, 2, 0, "GVD BAR0" },
+	{ 0x40000000, 0x10000000, 0, 2, 0, "GVD BAR2" },
+	{ 0xdfec0000, 0x40000, 0, 2, 0, "GVD BAR3" },
+	/* No address assigned: { 0x0, 0, 0, 6, 1, "HDMI HOTPLUG" }, */
+
+	{ 0xdf800000, 0x400000, 0, 3, 0, "ISP" },
+
+	{ 0xffa2e000, 0x400, 0, 6, 0, "PTI" },
+	{ 0xff11c000, 0x400, 0, 1, 7, "SCU IPC1" },
+	{ 0xff11d000, 0x1000, 0, 2, 2, "PMU" },
+};
+
+static const struct mmio_pci_map soc_tng_map[] = {
+	/* I2C0 is reserved for SCU<-->PMIC communication */
+	{ 0xff18b000, 0x400, 0, 8, 0, "I2C1" },
+	{ 0xff18c000, 0x400, 0, 8, 1, "I2C2" },
+	{ 0xff18d000, 0x400, 0, 8, 2, "I2C3" },
+	{ 0xff18e000, 0x400, 0, 8, 3, "I2C4" },
+	{ 0xff18f000, 0x400, 0, 9, 0, "I2C5" },
+	{ 0xff190000, 0x400, 0, 9, 1, "I2C6" },
+	{ 0xff191000, 0x400, 0, 9, 2, "I2C7" },
+
+	/* SDIO controllers number: 4 (compared to 5 of PNW/CLV) */
+	{ 0xff3fa000, 0x100, 0, 1, 2, "SDIO0 (HC2)" },
+	{ 0xff3fb000, 0x100, 0, 1, 3, "SDIO1 (HC1a)" },
+	{ 0xff3fc000, 0x100, 0, 1, 0, "SDIO3/eMMC0 (HC0a)" },
+	{ 0xff3fd000, 0x100, 0, 1, 1, "SDIO4/eMMC1 (HC0b)" },
+
+	/* GPIO0 and GPIO1 are merged to one GPIO controller in TNG */
+	{ 0xff008000, 0x1000, 0, 12, 0, "GPIO" },
+	{ 0xff192000, 0x1000, 0, 21, 0, "GP DMA" },
+
+	/* SSP Audio: SSP0: Modem, SSP1: Audio Codec, SSP2: Bluetooth */
+
+	/* LPE */
+	{ 0xff340000, 0x4000, 0, 13, 0, "LPE SHIM" },
+	{ 0xff344000, 0x1000, 0, 13, 0, "MAILBOX RAM" },
+	{ 0xff2c0000, 0x14000, 0, 13, 0, "ICCM" },
+	{ 0xff300000, 0x28000, 0, 13, 0, "DCCM" },
+	{ 0xff298000, 0x4000, 0, 14, 0, "LPE DMA0" },
+	/* invisible to IA: { 0xff29c000, 0x4000, -1, -1, -1, "LPE DMA1" }, */
+
+
+	/* SSP SC: SSP4: used by SCU for SPI Debug Card */
+	/* invisible to IA: { 0xff00e000, 0x1000, -1, -1, -1, "SSP SC" }, */
+
+	/* SSP General Purpose */
+	{ 0xff188000, 0x1000, 0, 7, 0, "SSP3" },
+	{ 0xff189000, 0x1000, 0, 7, 1, "SSP5" },
+	{ 0xff18a000, 0x1000, 0, 7, 2, "SSP6" },
+
+	/* UART */
+	{ 0xff010080, 0x80, 0, 4, 1, "UART0" },
+	{ 0xff011000, 0x80, 0, 4, 2, "UART1" },
+	{ 0xff011080, 0x80, 0, 4, 3, "UART2" },
+	{ 0xff011400, 0x400, 0, 5, 0, "UART DMA" },
+
+	/* HSI */
+	{ 0xff3f8000, 0x1000, 0, 10, 0, "HSI" },
+
+	/* USB */
+	{ 0xf9040000, 0x20000, 0, 15, 0, "USB2 OTG" },
+	{ 0xf9060000, 0x20000, 0, 16, 0, "USB2 MPH/HSIC" },
+	{ 0xf9100000, 0x100000, 0, 17, 0, "USB3 OTG" },
+	/* { 0xf90f0000, 0x1000, -1, -1, -1, "USB3 PHY" }, */
+	/* { 0xf90a0000, 0x10000, -1, -1, -1, "USB3 DMA FETCH" }, */
+
+	/* Security/Chaabi */
+	{ 0xf9030000, 0x1000, 0, 11, 0, "SEP SECURITY" },
+
+	/* Graphics/Display */
+	{ 0xc0000000, 0x2000000, 0, 2, 0, "GVD BAR0" },
+	{ 0x80000000, 0x10000000, 0, 2, 0, "GVD BAR2" },
+
+	/* ISP */
+	{ 0xc2000000, 0x400000, 0, 3, 0, "ISP" },
+
+	/* PTI */
+	{ 0xf9009000, 0x1000, 0, 18, 0, "PTI STM" },
+	{ 0xf90a0000, 0x10000, 0, 18, 0, "PTI USB3 DMA FETCH" },
+	{ 0xfa000000, 0x1000000, 0, 18, 0, "PTI APERTURE A" },
+
+	{ 0xff009000, 0x1000, 0, 19, 0, "SCU-IA IPC" },
+	{ 0xff00b000, 0x1000, 0, 20, 0, "PMU" },
+};
+
+static struct pci_dev *mmio_to_pci(u32 addr, char **name)
+{
+	int i, count;
+	struct mmio_pci_map *map;
+
+	if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_PENWELL) {
+		count = ARRAY_SIZE(soc_pnw_map);
+		map = (struct mmio_pci_map *) &soc_pnw_map[0];
+	} else if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_CLOVERVIEW) {
+		count = ARRAY_SIZE(soc_clv_map);
+		map = (struct mmio_pci_map *) &soc_clv_map[0];
+	} else if (intel_mid_identify_cpu() == INTEL_MID_CPU_CHIP_TANGIER) {
+		count = ARRAY_SIZE(soc_tng_map);
+		map = (struct mmio_pci_map *) &soc_tng_map[0];
+	} else {
+		return NULL;
+	}
+
+	for (i = 0; i < count; i++) {
+		if (ADDR_RANGE(map[i].start, map[i].size, addr))
+			break;
+	}
+
+	if (i >= count)
+		return NULL;
+
+	*name = &map[i].name[0];
+	return pci_get_bus_and_slot(map[i].pci_bus,
+		PCI_DEVFN(map[i].pci_dev, map[i].pci_func));
+}
+
+static int parse_argument(char *input, char **args)
+{
+	int count, located;
+	char *p = input;
+	int input_len = strlen(input);
+
+	count = 0;
+	located = 0;
+	while (*p != 0) {
+		if (p - input >= input_len)
+			break;
+
+		/* Locate the first character of a argument */
+		if (!IS_WHITESPACE(*p)) {
+			if (!located) {
+				located = 1;
+				args[count++] = p;
+				if (count > MAX_ARGS_NUM)
+					break;
+			}
+		} else {
+			if (located) {
+				*p = 0;
+				located = 0;
+			}
+		}
+		p++;
+	}
+
+	return count;
+}
+
+static int dump_cmd_show(struct seq_file *s, void *unused)
+{
+	seq_printf(s, dump_cmd_buf);
+	return 0;
+}
+
+static int dump_cmd_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dump_cmd_show, NULL);
+}
+
+static int parse_mmio_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 3) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[1|2|4] <mmio> <addr> [<len>]\n"
+			"       w[1|2|4] <mmio> <addr> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	ret = kstrtou32(arg_list[2], 0, &mmio_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid mmio address %s\n",
+							 arg_list[2]);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_32BIT) &&
+		(mmio_addr % 4)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"addr %x is not 4 bytes aligned!\n",
+						mmio_addr);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_16BIT) &&
+		(mmio_addr % 2)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"addr %x is not 2 bytes aligned!\n",
+						mmio_addr);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num == 4) {
+			ret = kstrtou32(arg_list[3], 0, &access_len);
+			if (ret) {
+				snprintf(err_buf, MAX_ERRLEN,
+					"invalid mmio read length %s\n",
+							arg_list[3]);
+				goto failed;
+			}
+		} else if (arg_num > 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: r[1|2|4] mmio <addr> "
+						"[<len>]\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"need exact 4 arguments for "
+					"mmio write.\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[3], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid mmio address %s\n",
+						arg_list[3]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_port_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 2) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[1|2|4] port <port>\n"
+			"       w[1|2|4] port <port> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_8BIT;
+
+	ret = kstrtou16(arg_list[2], 0, (u16 *)&port_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid port address %s\n",
+							 arg_list[2]);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_32BIT) &&
+		(port_addr % ACCESS_WIDTH_32BIT)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"port %x is not 4 bytes aligned!\n", port_addr);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_16BIT) &&
+		(port_addr % ACCESS_WIDTH_16BIT)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"port %x is not 2 bytes aligned!\n", port_addr);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num != 3) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: r[1|2|4] port <port>\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"need exact 4 arguments for port write.\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[3], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value %s\n", arg_list[3]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_msg_bus_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 4) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r msg_bus <port> <addr> [<len>]\n"
+			"       w msg_bus <port> <addr> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	if (access_width != ACCESS_WIDTH_32BIT) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"only 32bit read/write are supported.\n");
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[2], 0, &msg_bus_port);
+	if (ret || msg_bus_port > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid msg_bus port %s\n",
+								arg_list[2]);
+		goto failed;
+	}
+
+	ret = kstrtou32(arg_list[3], 0, &msg_bus_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid msg_bus address %s\n",
+								arg_list[3]);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num == 5) {
+			ret = kstrtou32(arg_list[4], 0, &access_len);
+			if (ret) {
+				snprintf(err_buf, MAX_ERRLEN,
+					"invalid msg_bus read length %s\n",
+								arg_list[4]);
+				goto failed;
+			}
+		} else if (arg_num > 5) {
+			snprintf(err_buf, MAX_ERRLEN, "too many arguments\n"
+						"usage: r[1|2|4] msg_bus "
+						"<port> <addr> [<len>]\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 5) {
+			snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+				"usage: w msg_bus <port> <addr> <val>]\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[4], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value for msg_bus write %s\n",
+							 arg_list[4]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_pci_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (arg_num < 6) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[1|2|4] pci <bus> <dev> <func> <reg> [<len>]\n"
+			"       w[1|2|4] pci <bus> <dev> <func> <reg> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	ret = kstrtou8(arg_list[2], 0, &pci_bus);
+	if (ret || pci_bus > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci bus %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[3], 0, &pci_dev);
+	if (ret || pci_dev > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci device %s\n",
+							arg_list[3]);
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[4], 0, &pci_func);
+	if (ret || pci_func > 255) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci function %s\n",
+							arg_list[4]);
+		goto failed;
+	}
+
+	ret = kstrtou16(arg_list[5], 0, &pci_reg);
+	if (ret || pci_reg > 4 * 1024) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid pci register %s\n",
+							arg_list[5]);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_32BIT) && (pci_reg % 4)) {
+		snprintf(err_buf, MAX_ERRLEN, "reg %x is not 4 bytes aligned!\n"
+							 , (u32) pci_reg);
+		goto failed;
+	}
+
+	if ((access_width == ACCESS_WIDTH_16BIT) && (pci_reg % 2)) {
+		snprintf(err_buf, MAX_ERRLEN, "reg %x is not 2 bytes aligned\n",
+								pci_reg);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num == 7) {
+			ret = kstrtou32(arg_list[6], 0, &access_len);
+			if (ret || access_len > 4 * 1024) {
+				snprintf(err_buf, MAX_ERRLEN,
+					"invalid pci read length %s\n",
+							arg_list[6]);
+				return ret;
+			}
+		} else if (arg_num > 7) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"max 7 args are allowed for pci read\n"
+				"usage: r[1|2|4] pci <bus> <dev> <func> "
+							"<reg> [<len>]\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 7) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"need exact 7 args for pci write.\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[6], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value for pci write %s\n",
+							 arg_list[6]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_msr_args(char **arg_list, int arg_num)
+{
+	int ret, arg_reg, arg_val;
+
+	if (((access_dir == ACCESS_DIR_READ) && (arg_num < 3)) ||
+		((access_dir == ACCESS_DIR_WRITE) && (arg_num < 4))) {
+		snprintf(err_buf, MAX_ERRLEN, "too few arguments\n"
+			"usage: r[4|8] msr [<cpu> | all] <reg>]\n"
+			"       w[4|8] msr [<cpu> | all] <reg> <val>]\n");
+		goto failed;
+	}
+
+	if (((access_dir == ACCESS_DIR_READ) && (arg_num > 4)) ||
+		((access_dir == ACCESS_DIR_WRITE) && (arg_num > 5))) {
+		snprintf(err_buf, MAX_ERRLEN, "too many arguments\n"
+			"usage: r[4|8] msr [<cpu> | all] <reg>]\n"
+			"       w[4|8] msr [<cpu> | all] <reg> <val>]\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_64BIT;
+
+	if (!strncmp(arg_list[2], "all", 3)) {
+		msr_cpu = -1;
+		arg_reg = 3;
+		arg_val = 4;
+	} else if ((access_dir == ACCESS_DIR_READ && arg_num == 4) ||
+		(access_dir == ACCESS_DIR_WRITE && arg_num == 5)) {
+		ret = kstrtou32(arg_list[2], 0, &msr_cpu);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN, "invalid cpu: %s\n",
+							arg_list[2]);
+			goto failed;
+		}
+		arg_reg = 3;
+		arg_val = 4;
+	} else {
+		/* Default cpu for msr read is all, for msr write is 0 */
+		if (access_dir == ACCESS_DIR_READ)
+			msr_cpu = -1;
+		else
+			msr_cpu = 0;
+		arg_reg = 2;
+		arg_val = 3;
+	}
+
+
+	ret = kstrtou32(arg_list[arg_reg], 0, &msr_reg);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid msr reg: %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (access_width == ACCESS_WIDTH_32BIT)
+			ret = kstrtou32(arg_list[arg_val], 0, &access_value);
+		else
+			ret = kstrtou64(arg_list[arg_val], 0, &access_value_64);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN, "invalid value: %s\n",
+							arg_list[arg_val]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_i2c_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if ((access_dir == ACCESS_DIR_READ && arg_num != 4) ||
+		(access_dir == ACCESS_DIR_WRITE && arg_num != 5)) {
+		snprintf(err_buf, MAX_ERRLEN, "usage: r i2c <bus> <addr>\n"
+			"       w i2c <bus> <addr> <val>\n");
+		goto failed;
+	}
+
+	if (access_width == ACCESS_WIDTH_DEFAULT)
+		access_width = ACCESS_WIDTH_8BIT;
+
+	if (access_width != ACCESS_WIDTH_8BIT) {
+		snprintf(err_buf, MAX_ERRLEN, "only 8bit access is allowed\n");
+		goto failed;
+	}
+
+	ret = kstrtou8(arg_list[2], 0, &i2c_bus);
+	if (ret || i2c_bus > 9) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid i2c bus %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+
+	ret = kstrtou32(arg_list[3], 0, &i2c_addr);
+
+	pr_err("ret = %d, i2c_addr is 0x%x\n", ret, i2c_addr);
+	if (ret || (i2c_addr > 1024)) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid i2c address %s\n",
+							arg_list[3]);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		ret = kstrtou32(arg_list[4], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid value for i2c write %s\n",
+							 arg_list[4]);
+			goto failed;
+		}
+	}
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static int parse_scu_args(char **arg_list, int arg_num)
+{
+	int ret;
+
+	if (access_width != ACCESS_WIDTH_32BIT)
+		access_width = ACCESS_WIDTH_32BIT;
+
+	ret = kstrtou32(arg_list[2], 0, &scu_addr);
+	if (ret) {
+		snprintf(err_buf, MAX_ERRLEN, "invalid scu address %s\n",
+							arg_list[2]);
+		goto failed;
+	}
+
+	if (scu_addr % 4) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"addr %x is not 4 bytes aligned!\n",
+						scu_addr);
+		goto failed;
+	}
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (arg_num != 3) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: r[4] scu <addr>\n");
+			goto failed;
+		}
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		if (arg_num != 4) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"usage: w[4] scu <addr> <val>\n");
+			goto failed;
+		}
+		ret = kstrtou32(arg_list[3], 0, &access_value);
+		if (ret) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"invalid scu write value %s\n",
+						arg_list[3]);
+			goto failed;
+		}
+	}
+
+	return 0;
+
+failed:
+	return -EINVAL;
+}
+
+static ssize_t dump_cmd_write(struct file *file, const char __user *buf,
+				size_t len, loff_t *offset)
+{
+	char cmd[MAX_CMDLEN];
+	char *arg_list[MAX_ARGS_NUM];
+	int arg_num, ret = -EINVAL;
+
+	err_buf[0] = 0;
+
+	if (len >= MAX_CMDLEN) {
+		snprintf(err_buf, MAX_ERRLEN, "input command is too long.\n"
+					"max allowed input length is %d\n",
+							MAX_CMDLEN);
+		goto done;
+	}
+
+	if (copy_from_user(cmd, buf, len)) {
+		snprintf(err_buf, MAX_ERRLEN, "copy_from_user() failed.\n");
+		goto done;
+	}
+	cmd[len] = 0;
+
+	dump_cmd_buf[0] = 0;
+	strncpy(dump_cmd_buf, cmd, len);
+	dump_cmd_buf[len] = 0;
+
+	arg_num = parse_argument(cmd, arg_list);
+	if (arg_num < MIN_ARGS_NUM) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"invalid command(too few arguments): "
+					"%s\n", dump_cmd_buf);
+		goto done;
+	}
+	if (arg_num > MAX_ARGS_NUM) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"invalid command(too many arguments): "
+					"%s\n", dump_cmd_buf);
+		goto done;
+	}
+
+	/* arg 1: direction(read/write) and mode (8/16/32/64 bit) */
+	if (!strncmp(arg_list[0], "r8", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_64BIT;
+	} else if (!strncmp(arg_list[0], "r4", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_32BIT;
+	} else if (!strncmp(arg_list[0], "r2", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_16BIT;
+	} else if (!strncmp(arg_list[0], "r1", 2)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_8BIT;
+	} else if (!strncmp(arg_list[0], "r", 1)) {
+		access_dir = ACCESS_DIR_READ;
+		access_width = ACCESS_WIDTH_DEFAULT;
+	} else if (!strncmp(arg_list[0], "w8", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_64BIT;
+	} else if (!strncmp(arg_list[0], "w4", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_32BIT;
+	} else if (!strncmp(arg_list[0], "w2", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_16BIT;
+	} else if (!strncmp(arg_list[0], "w1", 2)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_8BIT;
+	} else if (!strncmp(arg_list[0], "w", 1)) {
+		access_dir = ACCESS_DIR_WRITE;
+		access_width = ACCESS_WIDTH_DEFAULT;
+	} else {
+		snprintf(err_buf, MAX_ERRLEN, "unknown argument: %s\n",
+							arg_list[0]);
+		goto done;
+	}
+
+	/* arg2: bus type(mmio, msg_bus, pci or i2c) */
+	access_len = 1;
+	if (!strncmp(arg_list[1], "mmio", 4)) {
+		access_bus = ACCESS_BUS_MMIO;
+		ret = parse_mmio_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "port", 4)) {
+		access_bus = ACCESS_BUS_PORT;
+		ret = parse_port_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "msg_bus", 7)) {
+		access_bus = ACCESS_BUS_MSG_BUS;
+		ret = parse_msg_bus_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "pci", 3)) {
+		access_bus = ACCESS_BUS_PCI;
+		ret = parse_pci_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "msr", 3)) {
+		access_bus = ACCESS_BUS_MSR;
+		ret = parse_msr_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "i2c", 3)) {
+		access_bus = ACCESS_BUS_I2C;
+		ret = parse_i2c_args(arg_list, arg_num);
+	} else if (!strncmp(arg_list[1], "scu", 3)) {
+		access_bus = ACCESS_BUS_SCU_INDRW;
+		ret = parse_scu_args(arg_list, arg_num);
+	} else {
+		snprintf(err_buf, MAX_ERRLEN, "unknown argument: %s\n",
+							arg_list[1]);
+	}
+
+	if (access_len == 0) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"access length must be larger than 0\n");
+		ret = -EINVAL;
+		goto done;
+	}
+
+	if ((access_bus == ACCESS_BUS_MMIO || access_bus == ACCESS_BUS_PCI) &&
+					 (access_len > MAX_MMIO_PCI_LEN)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"%d exceeds max mmio/pci read length(%d)\n",
+					access_len, MAX_MMIO_PCI_LEN);
+		ret = -EINVAL;
+		goto done;
+	}
+
+	if ((access_bus == ACCESS_BUS_MSG_BUS) &&
+		(access_len > MAX_MSG_BUS_LEN)) {
+		snprintf(err_buf, MAX_ERRLEN,
+			"%d exceeds max msg_bus read length(%d)\n",
+					access_len, MAX_MSG_BUS_LEN);
+		ret = -EINVAL;
+	}
+
+	if (access_bus == ACCESS_BUS_MSR) {
+		if ((access_width != ACCESS_WIDTH_32BIT) &&
+			(access_width != ACCESS_WIDTH_64BIT) &&
+			(access_width != ACCESS_WIDTH_DEFAULT)) {
+			snprintf(err_buf, MAX_ERRLEN,
+				"only 32bit or 64bit is allowed for msr\n");
+			ret = -EINVAL;
+		}
+	}
+
+done:
+	dump_cmd_was_set = ret ? 0 : 1;
+	return ret ? ret : len;
+}
+
+static int dump_output_show_mmio(struct seq_file *s)
+{
+	void __iomem *base;
+	int i, comp1, comp2;
+	u32 start, end, end_natural;
+	struct pci_dev *pdev;
+	char *name;
+
+	pdev = mmio_to_pci(mmio_addr, &name);
+	if (pdev && pm_runtime_get_sync(&pdev->dev) < 0) {
+		seq_printf(s, "can't put device %s into D0i0 state\n", name);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		base = ioremap_nocache(mmio_addr, access_width);
+		if (!base) {
+			seq_printf(s, "can't map physical address: %x\n",
+				mmio_addr);
+			if (pdev)
+				pm_runtime_put_sync(&pdev->dev);
+			return 0;
+		}
+		switch (access_width) {
+		case ACCESS_WIDTH_8BIT:
+			iowrite8((u8) access_value, base);
+			break;
+		case ACCESS_WIDTH_16BIT:
+			iowrite16((u16) access_value, base);
+			break;
+		case ACCESS_WIDTH_32BIT:
+		case ACCESS_WIDTH_DEFAULT:
+			iowrite32(access_value, base);
+			break;
+		default:
+			break; /* never happen */
+		}
+		seq_printf(s, "write succeeded\n");
+	} else {
+		start = (mmio_addr / LINE_WIDTH) * LINE_WIDTH;
+		end_natural = mmio_addr + (access_len - 1) * access_width;
+		end = (end_natural / LINE_WIDTH + 1) * LINE_WIDTH -
+						access_width;
+		comp1 = (mmio_addr - start) / access_width;
+		comp2 = (end - end_natural) / access_width;
+
+		base = ioremap_nocache(start, (comp1 + comp2 +
+			access_len) * access_width);
+		if (!base) {
+			seq_printf(s, "can't map physical address: %x\n",
+				mmio_addr);
+			if (pdev)
+				pm_runtime_put_sync(&pdev->dev);
+			return 0;
+		}
+
+		for (i = 0; i < comp1 + comp2 + access_len; i++) {
+			if ((i % SHOW_NUM_PER_LINE) == 0)
+					seq_printf(s, "[%08x]", start + i * 4);
+
+			if (i < comp1 || i >= access_len + comp1) {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					seq_printf(s, "         ");
+					break;
+				case ACCESS_WIDTH_16BIT:
+					seq_printf(s, "     ");
+					break;
+				case ACCESS_WIDTH_8BIT:
+					seq_printf(s, "   ");
+					break;
+				}
+
+			} else {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					seq_printf(s, " %08x",
+						ioread32(base + i * 4));
+					break;
+				case ACCESS_WIDTH_16BIT:
+					seq_printf(s, " %04x",
+						(u16) ioread16(base + i * 2));
+					break;
+				case ACCESS_WIDTH_8BIT:
+					seq_printf(s, " %02x",
+						(u8) ioread8(base + i));
+					break;
+				}
+			}
+
+			if ((i + 1) % SHOW_NUM_PER_LINE == 0)
+				seq_printf(s, "\n");
+		}
+	}
+
+	iounmap(base);
+	if (pdev)
+		pm_runtime_put_sync(&pdev->dev);
+	return 0;
+}
+
+static int dump_output_show_port(struct seq_file *s)
+{
+	if (access_dir == ACCESS_DIR_WRITE) {
+		switch (access_width) {
+		case ACCESS_WIDTH_8BIT:
+		case ACCESS_WIDTH_DEFAULT:
+			outb((u8) access_value, port_addr);
+			break;
+		case ACCESS_WIDTH_16BIT:
+			outw((u16) access_value, port_addr);
+			break;
+		case ACCESS_WIDTH_32BIT:
+			outl(access_value, port_addr);
+			break;
+		default:
+			break; /* never happen */
+		}
+		seq_printf(s, "write succeeded\n");
+	} else {
+		switch (access_width) {
+		case ACCESS_WIDTH_32BIT:
+			seq_printf(s, " %08x\n", inl(port_addr));
+			break;
+		case ACCESS_WIDTH_16BIT:
+			seq_printf(s, " %04x\n", (u16) inw(port_addr));
+			break;
+		case ACCESS_WIDTH_8BIT:
+			seq_printf(s, " %02x\n", (u8) inb(port_addr));
+			break;
+		default:
+			break;
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_msg_bus(struct seq_file *s)
+{
+	int i, comp1, comp2;
+	u32 start, end, end_natural;
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		intel_mid_msgbus_write32(msg_bus_port,
+			msg_bus_addr, access_value);
+		seq_printf(s, "write succeeded\n");
+	} else {
+		start = (msg_bus_addr / LINE_WIDTH) * LINE_WIDTH;
+		end_natural = msg_bus_addr + (access_len - 1) * access_width;
+		end = (end_natural / LINE_WIDTH + 1) * LINE_WIDTH -
+						access_width;
+		comp1 = (msg_bus_addr - start) / access_width;
+		comp2 = (end - end_natural) / access_width;
+
+	for (i = 0; i < comp1 + comp2 + access_len; i++) {
+			if ((i % SHOW_NUM_PER_LINE) == 0)
+					seq_printf(s, "[%08x]", start + i * 4);
+
+			if (i < comp1 || i >= access_len + comp1)
+				seq_printf(s, "         ");
+
+			else
+				seq_printf(s, " %08x", intel_mid_msgbus_read32(
+					msg_bus_port, msg_bus_addr + i));
+
+			if ((i + 1) % SHOW_NUM_PER_LINE == 0)
+				seq_printf(s, "\n");
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_pci(struct seq_file *s)
+{
+	int i, comp1, comp2;
+	u32 start, end, end_natural, val;
+	struct pci_dev *pdev;
+
+	pdev = pci_get_bus_and_slot(pci_bus, PCI_DEVFN(pci_dev, pci_func));
+	if (!pdev) {
+		seq_printf(s, "pci bus %d:%d:%d doesn't exist\n",
+			pci_bus, pci_dev, pci_func);
+		return 0;
+	}
+
+	if (pm_runtime_get_sync(&pdev->dev) < 0) {
+		seq_printf(s, "can't put pci device %d:%d:%d into D0i0 state\n",
+			pci_bus, pci_dev, pci_func);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		switch (access_width) {
+		case ACCESS_WIDTH_8BIT:
+			pci_write_config_byte(pdev, (int)pci_reg,
+					(u8)access_value);
+			break;
+		case ACCESS_WIDTH_16BIT:
+			pci_write_config_word(pdev, (int)pci_reg,
+				(u16)access_value);
+			break;
+		case ACCESS_WIDTH_32BIT:
+		case ACCESS_WIDTH_DEFAULT:
+			pci_write_config_dword(pdev, (int)pci_reg,
+				access_value);
+			break;
+		default:
+			break; /* never happen */
+		}
+		seq_printf(s, "write succeeded\n");
+	} else {
+		start = (pci_reg / LINE_WIDTH) * LINE_WIDTH;
+		end_natural = pci_reg + (access_len - 1) * access_width;
+		end = (end_natural / LINE_WIDTH + 1) * LINE_WIDTH -
+						access_width;
+		comp1 = (pci_reg - start) / access_width;
+		comp2 = (end - end_natural) / access_width;
+
+		for (i = 0; i < comp1 + comp2 + access_len; i++) {
+			if ((i % SHOW_NUM_PER_LINE) == 0)
+					seq_printf(s, "[%08x]", start + i * 4);
+
+			if (i < comp1 || i >= access_len + comp1) {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					seq_printf(s, "         ");
+					break;
+				case ACCESS_WIDTH_16BIT:
+					seq_printf(s, "     ");
+					break;
+				case ACCESS_WIDTH_8BIT:
+					seq_printf(s, "   ");
+					break;
+				}
+
+			} else {
+				switch (access_width) {
+				case ACCESS_WIDTH_32BIT:
+					pci_read_config_dword(pdev,
+						start + i * 4, &val);
+					seq_printf(s, " %08x", val);
+					break;
+				case ACCESS_WIDTH_16BIT:
+					pci_read_config_word(pdev,
+						start + i * 2, (u16 *) &val);
+					seq_printf(s, " %04x", (u16)val);
+					break;
+				case ACCESS_WIDTH_8BIT:
+					pci_read_config_byte(pdev,
+						start + i, (u8 *) &val);
+					seq_printf(s, " %04x", (u8)val);
+					break;
+				}
+			}
+
+			if ((i + 1) % SHOW_NUM_PER_LINE == 0)
+				seq_printf(s, "\n");
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_msr(struct seq_file *s)
+{
+	int ret, i, count;
+	u32 data[2];
+
+	if (access_dir == ACCESS_DIR_READ) {
+		if (msr_cpu < 0) {
+			/* loop for all cpus */
+			i = 0;
+			count = nr_cpu_ids;
+		} else if (msr_cpu >= nr_cpu_ids || msr_cpu < 0) {
+			seq_printf(s, "cpu should be between 0 - %d\n",
+							nr_cpu_ids - 1);
+			return 0;
+		} else {
+			/* loop for one cpu */
+			i = msr_cpu;
+			count = msr_cpu + 1;
+		}
+		for (; i < count; i++) {
+			ret = rdmsr_safe_on_cpu(i, msr_reg, &data[0], &data[1]);
+			if (ret) {
+				seq_printf(s, "msr read error: %d\n", ret);
+				return 0;
+			} else {
+				if (access_width == ACCESS_WIDTH_32BIT)
+					seq_printf(s, "[cpu %1d] %08x\n",
+							i, data[0]);
+				else
+					seq_printf(s, "[cpu %1d] %08x%08x\n",
+						 i, data[1], data[0]);
+			}
+		}
+	} else {
+		if (access_width == ACCESS_WIDTH_32BIT) {
+			ret = rdmsr_safe_on_cpu(msr_cpu, msr_reg,
+					&data[0], &data[1]);
+			if (ret) {
+				seq_printf(s, "msr write error: %d\n", ret);
+				return 0;
+			}
+			data[0] = access_value;
+		} else {
+			data[0] = (u32)access_value_64;
+			data[1] = (u32)(access_value_64 >> 32);
+		}
+		if (msr_cpu < 0) {
+			/* loop for all cpus */
+			i = 0;
+			count = nr_cpu_ids;
+		} else {
+			if (msr_cpu >= nr_cpu_ids || msr_cpu < 0) {
+				seq_printf(s, "cpu should be between 0 - %d\n",
+						nr_cpu_ids - 1);
+				return 0;
+			}
+			/* loop for one cpu */
+			i = msr_cpu;
+			count = msr_cpu + 1;
+		}
+		for (; i < count; i++) {
+			ret = wrmsr_safe_on_cpu(i, msr_reg, data[0], data[1]);
+			if (ret) {
+				seq_printf(s, "msr write error: %d\n", ret);
+				return 0;
+			} else {
+				seq_printf(s, "write succeeded.\n");
+			}
+		}
+	}
+
+	return 0;
+}
+
+static int dump_output_show_i2c(struct seq_file *s)
+{
+	int ret;
+	struct i2c_adapter *adap;
+	struct i2c_msg msg;
+	u8 val;
+
+	adap = i2c_get_adapter(i2c_bus);
+	if (!adap) {
+		seq_printf(s, "can't find bus adapter for i2c bus %d\n",
+							i2c_bus);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		msg.addr = i2c_addr;
+		msg.len = 1;
+		msg.buf = (u8 *) &access_value;
+		ret = i2c_transfer(adap, &msg, 1);
+		if (ret != 1)
+			seq_printf(s, "i2c write error: %d\n", ret);
+		else
+			seq_printf(s, "write succeeded.\n");
+	} else {
+		msg.flags |= I2C_M_RD;
+		msg.addr = i2c_addr;
+		msg.len = 1;
+		msg.buf = &val;
+		ret = i2c_transfer(adap, &msg, 1);
+		if (ret != 1)
+			seq_printf(s, "i2c read error: %d\n", ret);
+		else
+			seq_printf(s, "%02x\n", val);
+	}
+
+	return 0;
+}
+
+static int dump_output_show_scu(struct seq_file *s)
+{
+	struct pci_dev *pdev;
+	char *name;
+	int ret;
+	u32 cmd, sub = 0, dptr = 0, sptr = 0;
+	u8 wbuflen = 4, rbuflen = 4;
+	u8 wbuf[16];
+	u8 rbuf[16];
+
+	memset(wbuf, 0, 16);
+	memset(rbuf, 0, 16);
+
+	pdev = mmio_to_pci(scu_addr, &name);
+	if (pdev && pm_runtime_get_sync(&pdev->dev) < 0) {
+		seq_printf(s, "can't put device %s into D0i0 state\n", name);
+		return 0;
+	}
+
+	if (access_dir == ACCESS_DIR_WRITE) {
+		cmd = RP_INDIRECT_WRITE;
+		dptr = scu_addr;
+		wbuf[0] = (u8) (access_value & 0xff);
+		wbuf[1] = (u8) ((access_value >> 8) & 0xff);
+		wbuf[2] = (u8) ((access_value >> 16) & 0xff);
+		wbuf[3] = (u8) ((access_value >> 24) & 0xff);
+
+		ret = rpmsg_send_generic_raw_command(cmd, sub, wbuf, wbuflen,
+			(u32 *)rbuf, rbuflen, dptr, sptr);
+
+		if (ret) {
+			seq_printf(s,
+				"Indirect write failed (check dmesg): "
+						"[%08x]\n", scu_addr);
+		} else {
+			seq_printf(s, "write succeeded\n");
+		}
+	} else if (access_dir == ACCESS_DIR_READ) {
+		cmd = RP_INDIRECT_READ;
+		sptr = scu_addr;
+
+		ret = rpmsg_send_generic_raw_command(cmd, sub, wbuf, wbuflen,
+			(u32 *)rbuf, rbuflen, dptr, sptr);
+
+		if (ret) {
+			seq_printf(s,
+				"Indirect read failed (check dmesg): "
+						"[%08x]\n", scu_addr);
+		} else {
+			access_value = (rbuf[3] << 24) | (rbuf[2] << 16) |
+				(rbuf[1] << 8) | (rbuf[0]);
+			seq_printf(s, "[%08x] %08x\n", scu_addr, access_value);
+		}
+	}
+
+	if (pdev)
+		pm_runtime_put_sync(&pdev->dev);
+
+	return 0;
+}
+
+static int dump_output_show(struct seq_file *s, void *unused)
+{
+	int ret = 0;
+
+	if (!dump_cmd_was_set) {
+		seq_printf(s, "%s", err_buf);
+		return 0;
+	}
+
+	switch (access_bus) {
+	case ACCESS_BUS_MMIO:
+		ret = dump_output_show_mmio(s);
+		break;
+	case ACCESS_BUS_PORT:
+		ret = dump_output_show_port(s);
+		break;
+	case ACCESS_BUS_MSG_BUS:
+		ret = dump_output_show_msg_bus(s);
+		break;
+	case ACCESS_BUS_PCI:
+		ret = dump_output_show_pci(s);
+		break;
+	case ACCESS_BUS_MSR:
+		ret = dump_output_show_msr(s);
+		break;
+	case ACCESS_BUS_I2C:
+		ret = dump_output_show_i2c(s);
+		break;
+	case ACCESS_BUS_SCU_INDRW:
+		ret = dump_output_show_scu(s);
+		break;
+	default:
+		seq_printf(s, "unknow bus type: %d\n", access_bus);
+		break;
+
+	}
+
+	return ret;
+}
+
+static const struct file_operations dump_cmd_fops = {
+	.owner		= THIS_MODULE,
+	.open		= dump_cmd_open,
+	.read		= seq_read,
+	.write		= dump_cmd_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int dump_output_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, dump_output_show, NULL);
+}
+
+static const struct file_operations dump_output_fops = {
+	.owner		= THIS_MODULE,
+	.open		= dump_output_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int __init intel_mid_dump_init(void)
+{
+	dump_cmd_dentry = debugfs_create_file("dump_cmd",
+		S_IFREG | S_IRUGO | S_IWUSR, NULL, NULL, &dump_cmd_fops);
+	dump_output_dentry = debugfs_create_file("dump_output",
+		S_IFREG | S_IRUGO, NULL, NULL, &dump_output_fops);
+	if (!dump_cmd_dentry || !dump_output_dentry) {
+		pr_err("intel_mid_dump: can't create debugfs node\n");
+		return -EFAULT;
+	}
+	return 0;
+}
+module_init(intel_mid_dump_init);
+
+static void __exit intel_mid_dump_exit(void)
+{
+	if (dump_cmd_dentry)
+		debugfs_remove(dump_cmd_dentry);
+	if (dump_output_dentry)
+		debugfs_remove(dump_output_dentry);
+}
+module_exit(intel_mid_dump_exit);
+
+MODULE_DESCRIPTION("Intel Atom SoC register dump driver");
+MODULE_VERSION("1.0");
+MODULE_AUTHOR("Bin Gao <bin.gao@intel.com>");
+MODULE_LICENSE("GPL v2");
diff --git a/arch/x86/platform/intel-mid/intel_soc_mdfld.c b/arch/x86/platform/intel-mid/intel_soc_mdfld.c
new file mode 100644
index 000000000000..7ccc504a3b1b
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mdfld.c
@@ -0,0 +1,177 @@
+/*
+ * intel_soc_mdfld.c - This driver provides utility api's for medfield
+ * platform
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+
+/* To CLEAR C6 offload Bit(LSB) in MSR 120 */
+static inline void clear_c6offload_bit(void)
+{
+	u32 msr_low, msr_high;
+
+	rdmsr(MSR_C6OFFLOAD_CTL_REG, msr_low, msr_high);
+	msr_low = msr_low & ~MSR_C6OFFLOAD_SET_LOW;
+	msr_high = msr_high & ~MSR_C6OFFLOAD_SET_HIGH;
+	wrmsr(MSR_C6OFFLOAD_CTL_REG, msr_low, msr_high);
+}
+
+/* To SET C6 offload Bit(LSB) in MSR 120 */
+static inline void set_c6offload_bit(void)
+{
+	u32 msr_low, msr_high;
+
+	rdmsr(MSR_C6OFFLOAD_CTL_REG, msr_low, msr_high);
+	msr_low = msr_low | MSR_C6OFFLOAD_SET_LOW;
+	msr_high = msr_high | MSR_C6OFFLOAD_SET_HIGH;
+	wrmsr(MSR_C6OFFLOAD_CTL_REG, msr_low, msr_high);
+}
+
+static bool mfld_pmu_enter(int s0ix_state)
+{
+	u32 s0ix_value;
+	u32 ssw_val;
+	int num_retry = PMU_MISC_SET_TIMEOUT;
+
+	s0ix_value = get_s0ix_val_set_pm_ssc(s0ix_state);
+
+	clear_c6offload_bit();
+
+	/* issue a command to SCU */
+	writel(s0ix_value, &mid_pmu_cxt->pmu_reg->pm_cmd);
+
+	pmu_log_command(s0ix_value, NULL);
+
+	do {
+		if (readl(&mid_pmu_cxt->pmu_reg->pm_msic))
+			break;
+		udelay(1);
+	} while (--num_retry);
+
+	if (!num_retry && !readl(&mid_pmu_cxt->pmu_reg->pm_msic))
+		WARN(1, "%s: pm_msic not set.\n", __func__);
+
+	num_retry = PMU_C6OFFLOAD_ACCESS_TIMEOUT;
+
+	/* At this point we have committed an S0ix command
+	 * will have to wait for the SCU s0ix complete
+	 * intertupt to proceed further.
+	 */
+	mid_pmu_cxt->s0ix_entered = s0ix_state;
+
+	if (s0ix_value == S0I3_VALUE) {
+		do {
+			ssw_val = readl(mid_pmu_cxt->base_addr.offload_reg);
+			if ((ssw_val & C6OFFLOAD_BIT_MASK) ==  C6OFFLOAD_BIT) {
+				set_c6offload_bit();
+				break;
+			}
+
+			udelay(1);
+		} while (--num_retry);
+
+		if (unlikely(!num_retry)) {
+			WARN(1, "mid_pmu: error cpu offload bit not set.\n");
+			pmu_stat_clear();
+			return false;
+		}
+	}
+
+	return true;
+}
+
+static void mfld_pmu_wakeup(void)
+{
+
+	/* Wakeup allother CPU's */
+	if (mid_pmu_cxt->s0ix_entered)
+		apic->send_IPI_allbutself(RESCHEDULE_VECTOR);
+
+	clear_c6offload_bit();
+}
+
+static void mfld_pmu_remove(void)
+{
+	/* Freeing up memory allocated for PMU1 & PMU2 */
+	iounmap(mid_pmu_cxt->base_addr.offload_reg);
+	mid_pmu_cxt->base_addr.offload_reg = NULL;
+
+}
+
+static pci_power_t mfld_pmu_choose_state(int device_lss)
+{
+	pci_power_t state;
+
+	switch (device_lss) {
+	case PMU_SECURITY_LSS_04:
+		state = PCI_D2;
+		break;
+
+	case PMU_USB_OTG_LSS_06:
+	case PMU_USB_HSIC_LSS_07:
+	case PMU_UART2_LSS_41:
+		state = PCI_D1;
+		break;
+
+	default:
+		state = PCI_D3hot;
+		break;
+	}
+
+	return state;
+}
+
+static int mfld_pmu_init(void)
+{
+	int ret = PMU_SUCCESS;
+
+	/* Map the memory of offload_reg */
+	mid_pmu_cxt->base_addr.offload_reg =
+				ioremap_nocache(C6_OFFLOAD_REG_ADDR, 4);
+	if (mid_pmu_cxt->base_addr.offload_reg == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+		"Unable to map the offload_reg address space\n");
+		ret = PMU_FAILED;
+		goto out_err;
+	}
+
+	mid_pmu_cxt->s3_hint = C6_HINT;
+
+out_err:
+	return ret;
+}
+
+/**
+ *      platform_set_pmu_ops - Set the global pmu method table.
+ *      @ops:   Pointer to ops structure.
+ */
+void platform_set_pmu_ops(void)
+{
+	pmu_ops = &mfld_pmu_ops;
+}
+
+struct platform_pmu_ops mfld_pmu_ops = {
+	.init	 = mfld_pmu_init,
+	.enter	 = mfld_pmu_enter,
+	.wakeup = mfld_pmu_wakeup,
+	.remove = mfld_pmu_remove,
+	.pci_choose_state = mfld_pmu_choose_state,
+	.set_power_state_ops = pmu_set_s0ix_possible,
+	.set_s0ix_complete = s0ix_complete,
+	.nc_set_power_state = mdfld_clv_nc_set_power_state,
+};
diff --git a/arch/x86/platform/intel-mid/intel_soc_mdfld.h b/arch/x86/platform/intel-mid/intel_soc_mdfld.h
new file mode 100644
index 000000000000..85c25b5622a0
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mdfld.h
@@ -0,0 +1,353 @@
+/*
+ * intel_soc_mdfld.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifdef CONFIG_REMOVEME_INTEL_REMOVEME_ATOM_MDFLD_POWER
+
+#define   PM_SUPPORT				0x21
+
+#define ISP_POS			7
+#define ISP_SUB_CLASS		0x80
+#define C6_OFFLOAD_REG_ADDR	0xffd01ffc
+#define PMU_MISC_SET_TIMEOUT	50 /* 50usec timeout */
+#define PMU_C6OFFLOAD_ACCESS_TIMEOUT 1500 /* 1.5msecs timeout */
+
+#define PMU1_MAX_DEVS   8
+#define PMU2_MAX_DEVS   55
+
+#define GFX_LSS_INDEX			1
+#define PMU_SDIO0_LSS_00		0
+#define PMU_EMMC0_LSS_01		1
+#define PMU_AONT_LSS_02			2
+#define PMU_HSI_LSS_03			3
+#define PMU_SECURITY_LSS_04		4
+#define PMU_EMMC1_LSS_05		5
+#define PMU_USB_OTG_LSS_06		6
+#define PMU_USB_HSIC_LSS_07		7
+#define PMU_AUDIO_ENGINE_LSS_08		8
+#define PMU_AUDIO_DMA_LSS_09		9
+#define PMU_SRAM_LSS_10			10
+#define PMU_SRAM_LSS_11			11
+#define PMU_SRAM_LSS_12			12
+#define PMU_SRAM_LSS_13			13
+#define PMU_SDIO2_LSS_14		14
+#define PMU_PTI_DAFCA_LSS_15		15
+#define PMU_SC_DMA_LSS_16		16
+#define PMU_SPIO_LSS_17			17
+#define PMU_SPI1_LSS_18			18
+#define PMU_SPI2_LSS_19			19
+#define PMU_I2C0_LSS_20			20
+#define PMU_I2C1_LSS_21			21
+#define PMU_MAIN_FABRIC_LSS_22		22
+#define PMU_SEC_FABRIC_LSS_23		23
+#define PMU_SC_FABRIC_LSS_24		24
+#define PMU_AUDIO_RAM_LSS_25		25
+#define PMU_SCU_ROM_LSS_26		26
+#define PMU_I2C2_LSS_27			27
+#define PMU_SSC_LSS_28			28
+#define PMU_SECURITY_LSS_29		29
+#define PMU_SDIO1_LSS_30		30
+#define PMU_SCU_RAM0_LSS_31		31
+#define PMU_SCU_RAM1_LSS_32		32
+#define PMU_I2C3_LSS_33			33
+#define PMU_I2C4_LSS_34			34
+#define PMU_I2C5_LSS_35			35
+#define PMU_SPI3_LSS_36			36
+#define PMU_GPIO1_LSS_37		37
+#define PMU_PWR_BUTTON_LSS_38		38
+#define PMU_GPIO0_LSS_39		39
+#define PMU_KEYBRD_LSS_40		40
+#define PMU_UART2_LSS_41		41
+#define PMU_ADC_LSS_42			42
+#define PMU_CHARGER_LSS_43		43
+#define PMU_SEC_TAPC_LSS_44		44
+#define PMU_RTC_LSS_45			45
+#define PMU_GPI_LSS_46			46
+#define PMU_HDMI_VREG_LSS_47		47
+#define PMU_RESERVED_LSS_48		48
+#define PMU_AUDIO_SLIM1_LSS_49		49
+#define PMU_RESET_LSS_50		50
+#define PMU_AUDIO_SSP0_LSS_51		51
+#define PMU_AUDIO_SSP1_LSS_52		52
+#define PMU_IOSF_OCP_BRG_LSS_53		53
+#define PMU_GP_DMA_LSS_54		54
+#define PMU_SVID_LSS_55			55
+#define PMU_SOC_FUSE_LSS_56		56
+#define PMU_RSVD3_LSS_57		57
+#define PMU_RSVD4_LSS_58		58
+#define PMU_RSVD5_LSS_59		59
+#define PMU_RSVD6_LSS_60		60
+#define PMU_RSVD7_LSS_61		61
+#define PMU_RSVD8_LSS_62		62
+#define PMU_RSVD9_LSS_63		63
+
+#define PMU_MAX_LSS			63
+#define PMU_LSS_IN_FIRST_DWORD		32
+
+#define EMMC0_LSS			PMU_EMMC0_LSS_01
+
+#define S0IX_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+#define S0IX_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define S0IX_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0IX_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0IX_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0IX_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1_MASK ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2_MASK ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3_MASK ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define LPMP3_TARGET_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I0_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_TARGET_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_TARGET_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_TARGET_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48))
+
+#define IGNORE_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_10) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_11) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_12) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_13) | \
+	SSMSK(D0I3_MASK, PMU_PTI_DAFCA_LSS_15))
+
+#define IGNORE_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SC_DMA_LSS_16-16) | \
+	SSMSK(D0I3_MASK, PMU_SPIO_LSS_17-16) | \
+	SSMSK(D0I3_MASK, PMU_MAIN_FABRIC_LSS_22-16) | \
+	SSMSK(D0I3_MASK, PMU_SEC_FABRIC_LSS_23-16) | \
+	SSMSK(D0I3_MASK, PMU_SC_FABRIC_LSS_24-16) | \
+	SSMSK(D0I3_MASK, PMU_SCU_ROM_LSS_26-16) | \
+	SSMSK(D0I3_MASK, PMU_SSC_LSS_28-16) | \
+	SSMSK(D0I3_MASK, PMU_SECURITY_LSS_29-16) | \
+	SSMSK(D0I3_MASK, PMU_SCU_RAM0_LSS_31-16))
+
+#define IGNORE_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_SCU_RAM1_LSS_32-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO0_LSS_39-32) | \
+	SSMSK(D0I3_MASK, PMU_ADC_LSS_42-32) | \
+	SSMSK(D0I3_MASK, PMU_CHARGER_LSS_43-32) | \
+	SSMSK(D0I3_MASK, PMU_SEC_TAPC_LSS_44-32) | \
+	SSMSK(D0I3_MASK, PMU_RTC_LSS_45-32) | \
+	SSMSK(D0I3_MASK, PMU_GPI_LSS_46-32) | \
+	SSMSK(D0I3_MASK, PMU_HDMI_VREG_LSS_47-32))
+
+#define IGNORE_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_IOSF_OCP_BRG_LSS_53-48) | \
+	SSMSK(D0I3_MASK, PMU_SVID_LSS_55-48) | \
+	SSMSK(D0I3_MASK, PMU_SOC_FUSE_LSS_56-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD3_LSS_57-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD4_LSS_58-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD5_LSS_59-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD6_LSS_60-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD7_LSS_61-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD8_LSS_62-48) | \
+	SSMSK(D0I3_MASK, PMU_RSVD9_LSS_63-48))
+
+#define IGNORE_S3_WKC0 SSWKC(PMU_AONT_LSS_02)
+#define IGNORE_S3_WKC1 SSWKC(PMU_ADC_LSS_42-32)
+
+#define S0I3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_ENGINE_LSS_08) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_DMA_LSS_09) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_12) | \
+	SSMSK(D0I3_MASK, PMU_SRAM_LSS_13) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define S0I3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_RAM_LSS_25-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define S0I3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define S0I3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_RESET_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+#define S0I1_SSS0 S0I3_SSS0
+#define S0I1_SSS1 S0I3_SSS1
+#define S0I1_SSS2 S0I3_SSS2
+#define S0I1_SSS3 S0I3_SSS3
+
+#define LPMP3_SSS0 ( \
+	SSMSK(D0I3_MASK, PMU_SDIO0_LSS_00) | \
+	SSMSK(D0I3_MASK, PMU_EMMC0_LSS_01) | \
+	SSMSK(D0I3_MASK, PMU_AONT_LSS_02) | \
+	SSMSK(D0I3_MASK, PMU_HSI_LSS_03) | \
+	SSMSK(D0I2_MASK, PMU_SECURITY_LSS_04) | \
+	SSMSK(D0I3_MASK, PMU_EMMC1_LSS_05) | \
+	SSMSK(D0I1_MASK, PMU_USB_OTG_LSS_06) | \
+	SSMSK(D0I1_MASK, PMU_USB_HSIC_LSS_07) | \
+	SSMSK(D0I3_MASK, PMU_SDIO2_LSS_14))
+
+#define LPMP3_SSS1 ( \
+	SSMSK(D0I3_MASK, PMU_SPI1_LSS_18-16) | \
+	SSMSK(D0I3_MASK, PMU_SPI2_LSS_19-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C0_LSS_20-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C1_LSS_21-16) | \
+	SSMSK(D0I3_MASK, PMU_I2C2_LSS_27-16) | \
+	SSMSK(D0I3_MASK, PMU_SDIO1_LSS_30-16))
+
+#define LPMP3_SSS2 ( \
+	SSMSK(D0I3_MASK, PMU_I2C3_LSS_33-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C4_LSS_34-32) | \
+	SSMSK(D0I3_MASK, PMU_I2C5_LSS_35-32) | \
+	SSMSK(D0I3_MASK, PMU_SPI3_LSS_36-32) | \
+	SSMSK(D0I3_MASK, PMU_GPIO1_LSS_37-32) | \
+	SSMSK(D0I3_MASK, PMU_PWR_BUTTON_LSS_38-32) | \
+	SSMSK(D0I3_MASK, PMU_KEYBRD_LSS_40-32) | \
+	SSMSK(D0I1_MASK, PMU_UART2_LSS_41-32))
+
+#define LPMP3_SSS3 ( \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SLIM1_LSS_49-48) | \
+	SSMSK(D0I3_MASK, PMU_RESET_LSS_50-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP0_LSS_51-48) | \
+	SSMSK(D0I3_MASK, PMU_AUDIO_SSP1_LSS_52-48) | \
+	SSMSK(D0I3_MASK, PMU_GP_DMA_LSS_54-48))
+
+extern void pmu_set_s0ix_possible(int state);
+extern void log_wakeup_irq(void);
+extern void s0ix_complete(void);
+extern int mdfld_clv_nc_set_power_state(int, int, int, int *);
+
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_mdfld_clv_common.c b/arch/x86/platform/intel-mid/intel_soc_mdfld_clv_common.c
new file mode 100644
index 000000000000..8ae0930782ff
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mdfld_clv_common.c
@@ -0,0 +1,451 @@
+/*
+ * intel_soc_mdfld_clv_common.c - This driver provides utility api's common for
+ * mdfld and clv platforms
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+
+static int extended_cstate_mode = MID_S0IX_STATE;
+int set_extended_cstate_mode(const char *val, struct kernel_param *kp)
+{
+	char valcp[5];
+	int cstate_mode;
+
+	memcpy(valcp, val, 5);
+	valcp[4] = '\0';
+
+	if (strcmp(valcp, "s0i1") == 0)
+		cstate_mode = MID_S0I1_STATE;
+	else if (strcmp(valcp, "lmp3") == 0)
+		cstate_mode = MID_LPMP3_STATE;
+	else if (strcmp(valcp, "s0i3") == 0)
+		cstate_mode = MID_S0I3_STATE;
+	else if (strcmp(valcp, "i1i3") == 0)
+		cstate_mode = MID_I1I3_STATE;
+	else if (strcmp(valcp, "lpi1") == 0)
+		cstate_mode = MID_LPI1_STATE;
+	else if (strcmp(valcp, "lpi3") == 0)
+		cstate_mode = MID_LPI3_STATE;
+	else if (strcmp(valcp, "s0ix") == 0)
+		cstate_mode = MID_S0IX_STATE;
+	else {
+		cstate_mode = 0;
+		strncpy(valcp, "none", 5);
+	}
+	memcpy(s0ix, valcp, 5);
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+	extended_cstate_mode = cstate_mode;
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return 0;
+}
+
+int get_extended_cstate_mode(char *buffer, struct kernel_param *kp)
+{
+	strcpy(buffer, s0ix);
+	return 4;
+}
+
+/*
+ *Decide which state the platfrom can go to based on user and
+ *platfrom inputs
+*/
+static int get_final_state(unsigned long *eax)
+{
+	int ret = 0;
+	int possible = mid_pmu_cxt->s0ix_possible;
+
+	switch (extended_cstate_mode) {
+	case MID_S0I1_STATE:
+	case MID_S0I3_STATE:
+	case MID_I1I3_STATE:
+		/* user asks s0i1/s0i3 then only
+		 * do s0i1/s0i3, dont do lpmp3
+		 */
+		if (possible == MID_S0IX_STATE)
+			ret = extended_cstate_mode & possible;
+		break;
+
+	case MID_LPMP3_STATE:
+		/* user asks lpmp3 then only
+		 * do lpmp3
+		 */
+		if (possible == MID_LPMP3_STATE)
+			ret = MID_LPMP3_STATE;
+		break;
+
+	case MID_LPI1_STATE:
+	case MID_LPI3_STATE:
+		/* user asks lpmp3/i1/i3 then only
+		 * do lpmp3/i1/i3
+		 */
+		if (possible == MID_LPMP3_STATE)
+			ret = MID_LPMP3_STATE;
+		else if (possible == MID_S0IX_STATE)
+			ret = extended_cstate_mode >> REMOVE_LP_FROM_LPIX;
+		break;
+
+	case MID_S0IX_STATE:
+		ret = possible;
+		break;
+	}
+
+	if ((ret == MID_S0IX_STATE) &&
+			(*eax == MID_LPMP3_STATE))
+		ret = MID_S0I1_STATE;
+	else if ((ret <= *eax ||
+			(ret == MID_S0IX_STATE)))
+		ret = ret & *eax;
+	else
+		ret = 0;
+
+	return ret;
+}
+
+static bool check_s0ix_possible(struct pmu_ss_states *pmsss)
+{
+	if (((pmsss->pmu2_states[0] & S0IX_TARGET_SSS0_MASK) ==
+					S0IX_TARGET_SSS0) &&
+		((pmsss->pmu2_states[1] & S0IX_TARGET_SSS1_MASK) ==
+					S0IX_TARGET_SSS1) &&
+		((pmsss->pmu2_states[2] & S0IX_TARGET_SSS2_MASK) ==
+					S0IX_TARGET_SSS2) &&
+		((pmsss->pmu2_states[3] & S0IX_TARGET_SSS3_MASK) ==
+					S0IX_TARGET_SSS3))
+		return true;
+
+	return false;
+}
+
+static bool check_lpmp3_possible(struct pmu_ss_states *pmsss)
+{
+	if (((pmsss->pmu2_states[0] & LPMP3_TARGET_SSS0_MASK) ==
+					LPMP3_TARGET_SSS0) &&
+		((pmsss->pmu2_states[1] & LPMP3_TARGET_SSS1_MASK) ==
+					LPMP3_TARGET_SSS1) &&
+		((pmsss->pmu2_states[2] & LPMP3_TARGET_SSS2_MASK) ==
+					LPMP3_TARGET_SSS2) &&
+		((pmsss->pmu2_states[3] & LPMP3_TARGET_SSS3_MASK) ==
+					LPMP3_TARGET_SSS3))
+		return true;
+
+	return false;
+}
+
+void pmu_set_s0ix_possible(int state)
+{
+	/* assume S0ix not possible */
+	mid_pmu_cxt->s0ix_possible = 0;
+
+	if (state != PCI_D0) {
+		struct pmu_ss_states cur_pmsss;
+
+		pmu_read_sss(&cur_pmsss);
+
+		if (likely(check_s0ix_possible(&cur_pmsss)))
+			mid_pmu_cxt->s0ix_possible = MID_S0IX_STATE;
+		else if (check_lpmp3_possible(&cur_pmsss))
+			mid_pmu_cxt->s0ix_possible = MID_LPMP3_STATE;
+	}
+}
+
+int get_target_platform_state(unsigned long *eax)
+{
+	int ret = 0;
+
+	if (unlikely(!pmu_initialized))
+		goto ret;
+
+	/* dont do s0ix if suspend in progress */
+	if (unlikely(mid_pmu_cxt->suspend_started))
+		goto ret;
+
+	/* dont do s0ix if shutdown in progress */
+	if (unlikely(mid_pmu_cxt->shutdown_started))
+		goto ret;
+
+	if (nc_device_state())
+		goto ret;
+
+	ret = get_final_state(eax);
+
+ret:
+	*eax = C6_HINT;
+	return ret;
+}
+EXPORT_SYMBOL(get_target_platform_state);
+
+u32 get_s0ix_val_set_pm_ssc(int s0ix_state)
+{
+	u32 s0ix_value = 0;
+
+	switch (s0ix_state) {
+	case MID_S0I1_STATE:
+		writel(S0I1_SSS0, &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+		writel(S0I1_SSS1, &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+		writel(S0I1_SSS2, &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+		writel(S0I1_SSS3, &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+		pmu_stat_start(SYS_STATE_S0I1);
+		s0ix_value = S0I1_VALUE;
+		break;
+	case MID_LPMP3_STATE:
+		writel(LPMP3_SSS0, &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+		writel(LPMP3_SSS1, &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+		writel(LPMP3_SSS2, &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+		writel(LPMP3_SSS3, &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+		pmu_stat_start(SYS_STATE_S0I2);
+		s0ix_value = LPMP3_VALUE;
+		break;
+	case MID_S0I3_STATE:
+		writel(S0I3_SSS0, &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+		writel(S0I3_SSS1, &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+		writel(S0I3_SSS2, &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+		writel(S0I3_SSS3, &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+		pmu_stat_start(SYS_STATE_S0I3);
+		s0ix_value = S0I3_VALUE;
+		break;
+	case MID_S3_STATE:
+		writel(S0I3_SSS0, &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+		writel(S0I3_SSS1, &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+		writel(S0I3_SSS2, &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+		writel(S0I3_SSS3, &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+		pmu_stat_start(SYS_STATE_S3);
+		s0ix_value = S0I3_VALUE;
+		break;
+	case MID_FAST_ON_OFF_STATE:
+		writel(S0I3_SSS0, &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+		writel(S0I3_SSS1, &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+		writel(S0I3_SSS2, &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+		writel(S0I3_SSS3, &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+		pmu_stat_start(SYS_STATE_S3);
+		s0ix_value = FAST_ON_OFF_VALUE;
+		break;
+	default:
+		pmu_dump_logs();
+		BUG_ON(1);
+	}
+	return s0ix_value;
+}
+
+void platform_update_all_lss_states(struct pmu_ss_states *pmu_config,
+					int *PCIALLDEV_CFG)
+{
+	/* We shutdown devices that are in the target config, and that are
+	   not in the pci table, some devices are indeed not advertised in pci
+	   table for certain firmwares. This is the case for HSI firmwares,
+	   SPI3 device is not advertised, and would then prevent s0i3. */
+	/* Also take IGNORE_CFG in account (for e.g. GPIO1)*/
+	pmu_config->pmu2_states[0] |= S0IX_TARGET_SSS0_MASK & ~PCIALLDEV_CFG[0];
+	pmu_config->pmu2_states[0] &= ~IGNORE_SSS0;
+	pmu_config->pmu2_states[1] |= S0IX_TARGET_SSS1_MASK & ~PCIALLDEV_CFG[1];
+	pmu_config->pmu2_states[1] &= ~IGNORE_SSS1;
+	pmu_config->pmu2_states[2] |= S0IX_TARGET_SSS2_MASK & ~PCIALLDEV_CFG[2];
+	pmu_config->pmu2_states[2] &= ~IGNORE_SSS2;
+	pmu_config->pmu2_states[3] |= S0IX_TARGET_SSS3_MASK & ~PCIALLDEV_CFG[3];
+	pmu_config->pmu2_states[3] &= ~IGNORE_SSS3;
+}
+
+void s0ix_complete(void)
+{
+	if (unlikely(mid_pmu_cxt->s0ix_entered))
+		writel(0, &mid_pmu_cxt->pmu_reg->pm_msic);
+}
+
+/*
+ * Valid wake source: lss_number 0 to 63
+ * Returns true if 'lss_number' is wake source
+ * else false
+ */
+bool mid_pmu_is_wake_source(u32 lss_number)
+{
+	u32 wake = 0;
+	bool ret = false;
+
+	if (lss_number > PMU_MAX_LSS)
+		return ret;
+
+	if (lss_number < PMU_LSS_IN_FIRST_DWORD) {
+		wake = readl(&mid_pmu_cxt->pmu_reg->pm_wks[0]);
+		wake &= (1 << lss_number);
+	} else {
+		wake = readl(&mid_pmu_cxt->pmu_reg->pm_wks[1]);
+		wake &= (1 << (lss_number - PMU_LSS_IN_FIRST_DWORD));
+	}
+
+	if (wake)
+		ret = true;
+
+	return ret;
+}
+
+static void log_wakeup_source(int source)
+{
+	enum sys_state type = mid_pmu_cxt->pmu_current_state;
+
+	mid_pmu_cxt->num_wakes[source][type]++;
+
+	trace_printk("wake_from_lss%d\n",
+		     source - mid_pmu_cxt->pmu1_max_devs);
+
+	if ((mid_pmu_cxt->pmu_current_state != SYS_STATE_S3)
+	    || !mid_pmu_cxt->suspend_started)
+		return;
+
+	switch (source - mid_pmu_cxt->pmu1_max_devs) {
+	case PMU_USB_OTG_LSS_06:
+		pr_info("wakeup from USB.\n");
+		break;
+	case PMU_GPIO0_LSS_39:
+		pr_info("wakeup from GPIO.\n");
+		break;
+	case PMU_HSI_LSS_03:
+		pr_info("wakeup from HSI.\n");
+		break;
+	default:
+		pr_info("wakeup from LSS%02d.\n",
+			source - mid_pmu_cxt->pmu1_max_devs);
+		break;
+	}
+}
+
+/* return the last wake source id, and make statistics about wake sources */
+int pmu_get_wake_source(void)
+{
+	u32 wake0, wake1;
+	int i;
+	int source = INVALID_WAKE_SRC;
+
+	wake0 = readl(&mid_pmu_cxt->pmu_reg->pm_wks[0]);
+	wake1 = readl(&mid_pmu_cxt->pmu_reg->pm_wks[1]);
+
+	if (!wake0 && !wake1) {
+		log_wakeup_irq();
+		goto out;
+	}
+
+	while (wake0) {
+		i = fls(wake0) - 1;
+		source = i + mid_pmu_cxt->pmu1_max_devs;
+		log_wakeup_source(source);
+		wake0 &= ~(1<<i);
+	}
+
+	while (wake1) {
+		i = fls(wake1) - 1;
+		source = i + 32 + mid_pmu_cxt->pmu1_max_devs;
+		log_wakeup_source(source);
+		wake1 &= ~(1<<i);
+	}
+out:
+	return source;
+}
+
+static int wait_for_nc_pmcmd_complete(int verify_mask, int state_type
+					, int reg_type)
+{
+	int pwr_sts;
+	int count = 0;
+	u32 addr;
+
+	switch (reg_type) {
+	case APM_REG_TYPE:
+		addr = mid_pmu_cxt->apm_base + APM_STS;
+		break;
+	case OSPM_REG_TYPE:
+		addr = mid_pmu_cxt->ospm_base + OSPM_PM_SSS;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	while (true) {
+		pwr_sts = inl(addr);
+		if (state_type == OSPM_ISLAND_DOWN) {
+			if ((pwr_sts & verify_mask) == verify_mask)
+				break;
+			else
+				udelay(10);
+		} else if (state_type == OSPM_ISLAND_UP) {
+			if (pwr_sts  == verify_mask)
+				break;
+			else
+				udelay(10);
+		}
+		count++;
+		if (WARN_ONCE(count > 500000, "Timed out waiting for P-Unit"))
+			return -EBUSY;
+	}
+	return 0;
+}
+
+int mdfld_clv_nc_set_power_state(int islands, int state_type,
+					int reg_type, int *change)
+{
+	u32 pwr_cnt = 0;
+	u32 pwr_mask = 0;
+	int i, lss, mask;
+	int ret = 0;
+
+	*change = 0;
+
+	switch (reg_type) {
+	case APM_REG_TYPE:
+		pwr_cnt = inl(mid_pmu_cxt->apm_base + APM_STS);
+		break;
+	case OSPM_REG_TYPE:
+		pwr_cnt = inl(mid_pmu_cxt->ospm_base + OSPM_PM_SSS);
+		break;
+	default:
+		ret = -EINVAL;
+		goto unlock;
+	}
+
+	pwr_mask = pwr_cnt;
+	for (i = 0; i < OSPM_MAX_POWER_ISLANDS; i++) {
+		lss = islands & (0x1 << i);
+		if (lss) {
+			mask = D0I3_MASK << (BITS_PER_LSS * i);
+			if (state_type == OSPM_ISLAND_DOWN)
+				pwr_mask |= mask;
+			else if (state_type == OSPM_ISLAND_UP)
+				pwr_mask &= ~mask;
+		}
+	}
+
+	if (pwr_mask != pwr_cnt) {
+		switch (reg_type) {
+		case APM_REG_TYPE:
+			outl(pwr_mask, mid_pmu_cxt->apm_base + APM_CMD);
+			break;
+		case OSPM_REG_TYPE:
+			outl(pwr_mask, mid_pmu_cxt->ospm_base + OSPM_PM_SSC);
+			break;
+		}
+
+		ret =
+		wait_for_nc_pmcmd_complete(pwr_mask, state_type, reg_type);
+		if (!ret)
+			*change = 1;
+		if (nc_report_power_state)
+			nc_report_power_state(pwr_mask, reg_type);
+	}
+
+unlock:
+	return ret;
+}
diff --git a/arch/x86/platform/intel-mid/intel_soc_mrfld.c b/arch/x86/platform/intel-mid/intel_soc_mrfld.c
new file mode 100644
index 000000000000..433e0e0bf9dc
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mrfld.c
@@ -0,0 +1,328 @@
+/*
+ * intel_soc_mrfld.c - This driver provides utility api's for merrifield
+ * platform
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+
+u32 __iomem *residency[SYS_STATE_MAX];
+u32 __iomem *s0ix_counter[SYS_STATE_MAX];
+
+static int mrfld_pmu_init(void)
+{
+	mid_pmu_cxt->s3_hint = MRFLD_S3_HINT;
+
+
+	/* Put all unused LSS in D0i3 */
+	mid_pmu_cxt->os_sss[0] = (SSMSK(D0I3_MASK, PMU_RESERVED_LSS_03)	|
+				SSMSK(D0I3_MASK, PMU_HSI_LSS_05)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_07)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_12)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_13)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_14)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_15));
+
+	/* Put LSS8 and LSS11 as unused on  PRh */
+	if (INTEL_MID_BOARD(3, PHONE, MRFL, BB, PRO, PRH)) {
+		mid_pmu_cxt->os_sss[0] |= \
+			(SSMSK(D0I3_MASK, PMU_USB_MPH_LSS_08)|
+			SSMSK(D0I3_MASK, PMU_AUDIO_DMA0_11));
+	}
+
+	mid_pmu_cxt->os_sss[1] = (SSMSK(D0I3_MASK, PMU_RESERVED_LSS_16-16)|
+				SSMSK(D0I3_MASK, PMU_SSP3_LSS_17-16)|
+				SSMSK(D0I3_MASK, PMU_SSP6_LSS_19-16)|
+				SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_28-16)|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_29-16)|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_30-16));
+
+	/* Excpet for LSS 35 keep all in D0i3 */
+	mid_pmu_cxt->os_sss[2] = 0xFFFFFFFF;
+	mid_pmu_cxt->os_sss[3] = 0xFFFFFFFF;
+
+	mid_pmu_cxt->os_sss[2] &= ~SSMSK(D0I3_MASK, PMU_SSP4_LSS_35-32);
+
+	/* Map S0ix residency counters */
+	residency[SYS_STATE_S0I1] = ioremap_nocache(S0I1_RES_ADDR, sizeof(u64));
+	if (residency[SYS_STATE_S0I1] == NULL)
+		goto err1;
+	residency[SYS_STATE_S0I2] = ioremap_nocache(S0I2_RES_ADDR, sizeof(u64));
+	if (residency[SYS_STATE_S0I2] == NULL)
+		goto err2;
+	residency[SYS_STATE_S0I3] = ioremap_nocache(S0I3_RES_ADDR, sizeof(u64));
+	if (residency[SYS_STATE_S0I3] == NULL)
+		goto err3;
+
+	/* Map S0ix iteration counters */
+	s0ix_counter[SYS_STATE_S0I1] = ioremap_nocache(S0I1_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_S0I1] == NULL)
+		goto err4;
+	s0ix_counter[SYS_STATE_S0I2] = ioremap_nocache(S0I2_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_S0I2] == NULL)
+		goto err5;
+	s0ix_counter[SYS_STATE_S0I3] = ioremap_nocache(S0I3_COUNT_ADDR,
+								sizeof(u32));
+	if (s0ix_counter[SYS_STATE_S0I3] == NULL)
+		goto err6;
+	/* Keep PSH LSS's 00, 33, 34 in D0i0 if PM is disabled */
+	if (!enable_s0ix && !enable_s3) {
+		mid_pmu_cxt->os_sss[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C8_LSS_33-32);
+		mid_pmu_cxt->os_sss[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C9_LSS_34-32);
+	} else {
+		mid_pmu_cxt->os_sss[0] |= SSMSK(D0I3_MASK, PMU_PSH_LSS_00);
+	}
+
+	return PMU_SUCCESS;
+
+err3:
+	iounmap(residency[SYS_STATE_S0I3]);
+	residency[SYS_STATE_S0I3] = NULL;
+err2:
+	iounmap(residency[SYS_STATE_S0I2]);
+	residency[SYS_STATE_S0I2] = NULL;
+err1:
+	iounmap(residency[SYS_STATE_S0I1]);
+	residency[SYS_STATE_S0I1] = NULL;
+
+	pr_err("Cannot map memory to read S0ix residency and count\n");
+	return PMU_FAILED;
+
+err6:
+	iounmap(s0ix_counter[SYS_STATE_S0I3]);
+	s0ix_counter[SYS_STATE_S0I3] = NULL;
+err5:
+	iounmap(s0ix_counter[SYS_STATE_S0I2]);
+	s0ix_counter[SYS_STATE_S0I2] = NULL;
+err4:
+	iounmap(s0ix_counter[SYS_STATE_S0I1]);
+	s0ix_counter[SYS_STATE_S0I1] = NULL;
+
+	pr_err("Cannot map memory to read S0ix count\n");
+	return PMU_FAILED;
+}
+
+/* FIXME: Need to start the counter only if debug is
+ * needed. This will save SCU cycles if debug is
+ * disabled
+ */
+static int __init start_scu_s0ix_res_counters(void)
+{
+	int ret;
+
+	ret = intel_scu_ipc_simple_command(START_RES_COUNTER, 0);
+	if (ret) {
+		pr_err("IPC command to start res counter failed\n");
+		BUG();
+		return ret;
+	}
+	return 0;
+}
+late_initcall(start_scu_s0ix_res_counters);
+
+void platform_update_all_lss_states(struct pmu_ss_states *pmu_config,
+					int *PCIALLDEV_CFG)
+{
+	/* Overwrite the pmu_config values that we get */
+	pmu_config->pmu2_states[0] =
+				(SSMSK(D0I3_MASK, PMU_RESERVED_LSS_03)	|
+				SSMSK(D0I3_MASK, PMU_HSI_LSS_05)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_07)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_12)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_13)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_14)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_15));
+
+	/* Put LSS8 and LSS11 as unused on  PRh */
+	if (INTEL_MID_BOARD(3, PHONE, MRFL, BB, PRO, PRH)) {
+		pmu_config->pmu2_states[0] |= \
+			(SSMSK(D0I3_MASK, PMU_USB_MPH_LSS_08)|
+			SSMSK(D0I3_MASK, PMU_AUDIO_DMA0_11));
+	}
+
+	pmu_config->pmu2_states[1] =
+				(SSMSK(D0I3_MASK, PMU_RESERVED_LSS_16-16)|
+				SSMSK(D0I3_MASK, PMU_SSP3_LSS_17-16)|
+				SSMSK(D0I3_MASK, PMU_SSP6_LSS_19-16)|
+				SSMSK(D0I3_MASK, PMU_USB_OTG_LSS_28-16)	|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_29-16)|
+				SSMSK(D0I3_MASK, PMU_RESERVED_LSS_30-16));
+
+	pmu_config->pmu2_states[0] &= ~IGNORE_SSS0;
+	pmu_config->pmu2_states[1] &= ~IGNORE_SSS1;
+	pmu_config->pmu2_states[2] = ~IGNORE_SSS2;
+	pmu_config->pmu2_states[3] = ~IGNORE_SSS3;
+
+	/* Excpet for LSS 35 keep all in D0i3 */
+	pmu_config->pmu2_states[2] &= ~SSMSK(D0I3_MASK, PMU_SSP4_LSS_35-32);
+
+	/* Keep PSH LSS's 00, 33, 34 in D0i0 if PM is disabled */
+	if (!enable_s0ix && !enable_s3) {
+		pmu_config->pmu2_states[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C8_LSS_33-32);
+		pmu_config->pmu2_states[2] &=
+				~SSMSK(D0I3_MASK, PMU_I2C9_LSS_34-32);
+	} else {
+		pmu_config->pmu2_states[0] |= SSMSK(D0I3_MASK, PMU_PSH_LSS_00);
+	}
+}
+
+/*
+ * In MDFLD and CLV this callback is used to issue
+ * PM_CMD which is not required in MRFLD
+ */
+static bool mrfld_pmu_enter(int s0ix_state)
+{
+	mid_pmu_cxt->s0ix_entered = s0ix_state;
+	if (s0ix_state == MID_S3_STATE)
+		mid_pmu_cxt->pmu_current_state = SYS_STATE_S3;
+
+	return true;
+}
+
+/**
+ *      platform_set_pmu_ops - Set the global pmu method table.
+ *      @ops:   Pointer to ops structure.
+ */
+void platform_set_pmu_ops(void)
+{
+	pmu_ops = &mrfld_pmu_ops;
+}
+
+/*
+ * As of now since there is no sequential mapping between
+ * LSS abd WKS bits the following two calls are dummy
+ */
+
+bool mid_pmu_is_wake_source(u32 lss_number)
+{
+	return false;
+}
+
+/* return the last wake source id, and make statistics about wake sources */
+int pmu_get_wake_source(void)
+{
+	return INVALID_WAKE_SRC;
+}
+
+
+int set_extended_cstate_mode(const char *val, struct kernel_param *kp)
+{
+	return 0;
+}
+
+int get_extended_cstate_mode(char *buffer, struct kernel_param *kp)
+{
+	const char *default_string = "not supported";
+	strcpy(buffer, default_string);
+	return strlen(default_string);
+}
+
+static int wait_for_nc_pmcmd_complete(int verify_mask,
+				int status_mask, int state_type , int reg)
+{
+	int pwr_sts;
+	int count = 0;
+
+	while (true) {
+		pwr_sts = intel_mid_msgbus_read32(PUNIT_PORT, reg);
+		pwr_sts = pwr_sts >> SSS_SHIFT;
+		if (state_type == OSPM_ISLAND_DOWN ||
+					state_type == OSPM_ISLAND_SR) {
+			if ((pwr_sts & status_mask) ==
+						(verify_mask & status_mask))
+				break;
+			else
+				udelay(10);
+		} else if (state_type == OSPM_ISLAND_UP) {
+			if ((~pwr_sts & status_mask)  ==
+						(~verify_mask & status_mask))
+				break;
+			else
+				udelay(10);
+		}
+
+		count++;
+		if (WARN_ONCE(count > 500000, "Timed out waiting for P-Unit"))
+			return -EBUSY;
+	}
+	return 0;
+}
+
+static int mrfld_nc_set_power_state(int islands, int state_type,
+							int reg, int *change)
+{
+	u32 pwr_sts = 0;
+	u32 pwr_mask = 0;
+	int i, lss, mask;
+	int ret = 0;
+	int status_mask = 0;
+
+	*change = 0;
+	pwr_sts = intel_mid_msgbus_read32(PUNIT_PORT, reg);
+	pwr_mask = pwr_sts;
+
+	for (i = 0; i < OSPM_MAX_POWER_ISLANDS; i++) {
+		lss = islands & (0x1 << i);
+		if (lss) {
+			mask = D0I3_MASK << (BITS_PER_LSS * i);
+			status_mask = status_mask | mask;
+			if (state_type == OSPM_ISLAND_DOWN)
+				pwr_mask |= mask;
+			else if (state_type == OSPM_ISLAND_UP)
+				pwr_mask &= ~mask;
+			/* Soft reset case */
+			else if (state_type == OSPM_ISLAND_SR) {
+				pwr_mask &= ~mask;
+				mask = SR_MASK << (BITS_PER_LSS * i);
+				pwr_mask |= mask;
+			}
+		}
+	}
+
+	if (pwr_mask != pwr_sts) {
+		intel_mid_msgbus_write32(PUNIT_PORT, reg, pwr_mask);
+		ret = wait_for_nc_pmcmd_complete(pwr_mask,
+					status_mask, state_type, reg);
+		if (!ret)
+			*change = 1;
+		if (nc_report_power_state)
+			nc_report_power_state(pwr_mask, reg);
+	}
+
+	return ret;
+}
+
+void s0ix_complete(void)
+{
+	if (mid_pmu_cxt->s0ix_entered) {
+		log_wakeup_irq();
+		mid_pmu_cxt->pmu_current_state	=
+		mid_pmu_cxt->s0ix_entered	= 0;
+	}
+}
+
+struct platform_pmu_ops mrfld_pmu_ops = {
+	.init	 = mrfld_pmu_init,
+	.enter	 = mrfld_pmu_enter,
+	.set_s0ix_complete = s0ix_complete,
+	.nc_set_power_state = mrfld_nc_set_power_state,
+};
diff --git a/arch/x86/platform/intel-mid/intel_soc_mrfld.h b/arch/x86/platform/intel-mid/intel_soc_mrfld.h
new file mode 100644
index 000000000000..ee7f19f72d9a
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_mrfld.h
@@ -0,0 +1,156 @@
+/*
+ * intel_soc_mrfld.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#ifdef CONFIG_REMOVEME_INTEL_REMOVEME_ATOM_MRFLD_POWER
+
+#define PM_SUPPORT		0x21
+
+#define ISP_POS			7
+#define ISP_SUB_CLASS		0x80
+
+#define PUNIT_PORT		0x04
+#define SSS_SHIFT		24
+
+/* Soft reset mask */
+#define SR_MASK			0x2
+
+#define PMU1_MAX_DEVS			8
+#define PMU2_MAX_DEVS			55
+
+#define MRFLD_S3_HINT			0x64
+
+#define PUNIT_PORT			0x04
+#define NC_PM_SSS			0x3F
+
+/* SRAM locations to get S0ix residency */
+#define S0I1_RES_ADDR		0xFFFFFDE0
+#define S0I2_RES_ADDR		0xFFFFFDE8
+#define S0I3_RES_ADDR		0xFFFFFDF0
+
+/* SRAM locations to get S0ix count */
+#define S0I1_COUNT_ADDR		0xFFFFF420
+#define S0I2_COUNT_ADDR		0xFFFFF424
+#define S0I3_COUNT_ADDR		0xFFFFF428
+
+/* IPC commands to start, stop and
+ * dump S0ix residency counters */
+#define START_RES_COUNTER	0x00EB
+#define STOP_RES_COUNTER	0x10EB
+#define DUMP_RES_COUNTER	0x20EB
+
+/* IPC commands to start/reset and
+ * dump S0ix count */
+#define START_S0IX_COUNT	0x00E1
+#define DUMP_S0IX_COUNT		0x10E1
+
+#define GFX_LSS_INDEX			1
+
+#define PMU_PSH_LSS_00			0
+#define PMU_SDIO0_LSS_01		1
+#define PMU_EMMC0_LSS_02		2
+#define PMU_RESERVED_LSS_03		3
+#define PMU_SDIO1_LSS_04		4
+#define PMU_HSI_LSS_05			5
+#define PMU_SECURITY_LSS_06		6
+#define PMU_RESERVED_LSS_07		7
+#define PMU_USB_MPH_LSS_08		8
+#define PMU_USB3_LSS_09			9
+#define PMU_AUDIO_LSS_10		10
+#define PMU_AUDIO_DMA0_11		11
+#define PMU_RESERVED_LSS_12		12
+#define PMU_RESERVED_LSS_13		13
+#define PMU_RESERVED_LSS_14		14
+#define PMU_RESERVED_LSS_15		15
+#define PMU_RESERVED_LSS_16		16
+#define PMU_SSP3_LSS_17			17
+#define PMU_SSP5_LSS_18			18
+#define PMU_SSP6_LSS_19			19
+#define PMU_I2C1_LSS_20			20
+#define PMU_I2C2_LSS_21			21
+#define PMU_I2C3_LSS_22			22
+#define PMU_I2C4_LSS_23			23
+#define PMU_I2C5_LSS_24			24
+#define PMU_GP_DMA_LSS_25		25
+#define PMU_I2C6_LSS_26			26
+#define PMU_I2C7_LSS_27			27
+#define PMU_USB_OTG_LSS_28		28
+#define PMU_RESERVED_LSS_29		29
+#define PMU_RESERVED_LSS_30		30
+#define PMU_UART0_LSS_31		31
+#define PMU_UART1_LSS_31		31
+#define PMU_UART2_LSS_31		31
+
+#define PMU_I2C8_LSS_33			33
+#define PMU_I2C9_LSS_34			34
+#define PMU_SSP4_LSS_35			35
+#define PMU_PMW_LSS_36			36
+
+#define EMMC0_LSS			PMU_EMMC0_LSS_02
+
+#define IGNORE_SSS0			0
+#define IGNORE_SSS1			0
+#define IGNORE_SSS2			0
+#define IGNORE_SSS3			0
+
+#define PMU_WAKE_GPIO0      (1 << 0)
+#define PMU_WAKE_GPIO1      (1 << 1)
+#define PMU_WAKE_GPIO2      (1 << 2)
+#define PMU_WAKE_GPIO3      (1 << 3)
+#define PMU_WAKE_GPIO4      (1 << 4)
+#define PMU_WAKE_GPIO5      (1 << 5)
+#define PMU_WAKE_TIMERS     (1 << 6)
+#define PMU_WAKE_SECURITY   (1 << 7)
+#define PMU_WAKE_AONT32K    (1 << 8)
+#define PMU_WAKE_AONT       (1 << 9)
+#define PMU_WAKE_SVID_ALERT (1 << 10)
+#define PMU_WAKE_AUDIO      (1 << 11)
+#define PMU_WAKE_USB2       (1 << 12)
+#define PMU_WAKE_USB3       (1 << 13)
+#define PMU_WAKE_ILB        (1 << 14)
+#define PMU_WAKE_TAP        (1 << 15)
+#define PMU_WAKE_WATCHDOG   (1 << 16)
+#define PMU_WAKE_HSIC       (1 << 17)
+#define PMU_WAKE_PSH        (1 << 18)
+#define PMU_WAKE_PSH_GPIO   (1 << 19)
+#define PMU_WAKE_PSH_AONT   (1 << 20)
+#define PMU_WAKE_PSH_HALT   (1 << 21)
+#define PMU_GLBL_WAKE_MASK  (1 << 31)
+
+/* Ignore AONT WAKES and ALL from WKC1 */
+#define IGNORE_S3_WKC0 (PMU_WAKE_AONT32K | PMU_WAKE_AONT)
+#define IGNORE_S3_WKC1 (~0)
+
+#define S0IX_TARGET_SSS0_MASK (0xFFF3FFFF)
+#define S0IX_TARGET_SSS1_MASK (0xFFFFFFFF)
+#define S0IX_TARGET_SSS2_MASK (0xFFFFFFFF)
+#define S0IX_TARGET_SSS3_MASK (0xFFFFFFFF)
+
+#define S0IX_TARGET_SSS0 (0xFFF3FFFF)
+#define S0IX_TARGET_SSS1 (0xFFFFFFFF)
+#define S0IX_TARGET_SSS2 (0xFFFFFF3F)
+#define S0IX_TARGET_SSS3 (0xFFFFFFFF)
+
+#define LPMP3_TARGET_SSS0_MASK (0xFFF3FFFF)
+#define LPMP3_TARGET_SSS0 (0xFFC3FFFF)
+
+extern int intel_scu_ipc_simple_command(int, int);
+extern void log_wakeup_irq(void);
+extern void s0ix_complete(void);
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_pm_debug.c b/arch/x86/platform/intel-mid/intel_soc_pm_debug.c
new file mode 100644
index 000000000000..dd1ecda50acd
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pm_debug.c
@@ -0,0 +1,2479 @@
+/*
+ * intel_soc_pm_debug.c - This driver provides debug utilities across
+ * multiple platforms
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#include <linux/time.h>
+#include <asm/intel_mid_rpmsg.h>
+#include <asm/mwait.h>
+#include "intel_soc_pm_debug.h"
+#include <asm-generic/io-64-nonatomic-hi-lo.h>
+
+#ifdef CONFIG_PM_DEBUG
+#define MAX_CSTATES_POSSIBLE	32
+
+u32 prev_s0ix_cnt[SYS_STATE_MAX];
+unsigned long long prev_s0ix_res[SYS_STATE_MAX];
+u32 S3_count;
+unsigned long long S3_res;
+
+
+static struct latency_stat *lat_stat;
+
+static void latency_measure_enable_disable(bool enable_measure)
+{
+	int err;
+	u32 sub;
+
+	if (enable_measure == lat_stat->latency_measure)
+		return;
+
+	if (enable_measure)
+		sub = IPC_SUB_MEASURE_START_CLVP;
+	else
+		sub = IPC_SUB_MEASURE_STOP_CLVP;
+
+	err = rpmsg_send_generic_command(IPC_CMD_S0IX_LATENCY_CLVP,
+						sub, NULL, 0, NULL, 0);
+	if (unlikely(err)) {
+		pr_err("IPC to %s S0IX Latency Measurement failed!\n",
+					enable_measure ? "start" : "stop");
+		return;
+	}
+
+	if (enable_measure) {
+		memset(lat_stat->scu_latency, 0, sizeof(lat_stat->scu_latency));
+		memset(lat_stat->os_latency, 0, sizeof(lat_stat->os_latency));
+		memset(lat_stat->s3_parts_lat, 0,
+				sizeof(lat_stat->s3_parts_lat));
+		memset(lat_stat->count, 0, sizeof(lat_stat->count));
+	}
+
+	lat_stat->latency_measure = enable_measure;
+}
+
+static void print_simple_stat(struct seq_file *s, int divisor, int rem_div,
+					int count, struct simple_stat stat)
+{
+	unsigned long long min, avg, max;
+	unsigned long min_rem = 0, avg_rem = 0, max_rem = 0;
+
+	min = stat.min;
+	max = stat.max;
+	avg = stat.total;
+
+	if (count)
+		do_div(avg, count);
+
+	if (divisor > 1) {
+		min_rem = do_div(min, divisor);
+		max_rem = do_div(max, divisor);
+		avg_rem = do_div(avg, divisor);
+	}
+
+	if (rem_div > 1) {
+		min_rem /= rem_div;
+		max_rem /= rem_div;
+		avg_rem /= rem_div;
+	}
+
+	seq_printf(s, " %5llu.%03lu/%5llu.%03lu/%5llu.%03lu",
+			min, min_rem, avg, avg_rem, max, max_rem);
+}
+
+static int show_pmu_s0ix_lat(struct seq_file *s, void *unused)
+{
+	int i = 0;
+
+	char *states[] = {
+		"S0I1",
+		"LPMP3",
+		"S0I3",
+		"S3"
+	};
+
+	char *s3_parts_names[] = {
+		"PROC_FRZ",
+		"DEV_SUS",
+		"NB_CPU_OFF",
+		"NB_CPU_ON",
+		"DEV_RES",
+		"PROC_UNFRZ"
+	};
+
+	seq_printf(s, "%29s %35s\n", "SCU Latency", "OS Latency");
+	seq_printf(s, "%33s %35s\n", "min/avg/max(msec)", "min/avg/max(msec)");
+
+	for (i = SYS_STATE_S0I1; i <= SYS_STATE_S3; i++) {
+		seq_printf(s, "\n%s(%llu)", states[i - SYS_STATE_S0I1],
+							lat_stat->count[i]);
+
+		seq_printf(s, "\n%5s", "entry");
+		print_simple_stat(s, USEC_PER_MSEC, 1, lat_stat->count[i],
+						lat_stat->scu_latency[i].entry);
+		seq_printf(s, "      ");
+		print_simple_stat(s, NSEC_PER_MSEC, NSEC_PER_USEC,
+			lat_stat->count[i], lat_stat->os_latency[i].entry);
+
+		seq_printf(s, "\n%5s", "exit");
+		print_simple_stat(s, USEC_PER_MSEC, 1, lat_stat->count[i],
+						lat_stat->scu_latency[i].exit);
+		seq_printf(s, "      ");
+		print_simple_stat(s, NSEC_PER_MSEC, NSEC_PER_USEC,
+			lat_stat->count[i], lat_stat->os_latency[i].exit);
+
+	}
+
+	seq_printf(s, "\n\n");
+
+	if (!lat_stat->count[SYS_STATE_S3])
+		return 0;
+
+	seq_printf(s, "S3 Latency dissection:\n");
+	seq_printf(s, "%38s\n", "min/avg/max(msec)");
+
+	for (i = 0; i < MAX_S3_PARTS; i++) {
+		seq_printf(s, "%10s\t", s3_parts_names[i]);
+		print_simple_stat(s, NSEC_PER_MSEC, NSEC_PER_USEC,
+					lat_stat->count[SYS_STATE_S3],
+					lat_stat->s3_parts_lat[i]);
+		seq_printf(s, "\n");
+	}
+
+	return 0;
+}
+
+static int pmu_s0ix_lat_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_s0ix_lat, NULL);
+}
+
+static ssize_t pmu_s0ix_lat_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+
+	buf[buf_size] = 0;
+
+	if (((strlen("start") + 1) == buf_size) &&
+		!strncmp(buf, "start", strlen("start"))) {
+		latency_measure_enable_disable(true);
+	} else if (((strlen("stop") + 1) == buf_size) &&
+		!strncmp(buf, "stop", strlen("stop"))) {
+		latency_measure_enable_disable(false);
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations s0ix_latency_ops = {
+	.open		= pmu_s0ix_lat_open,
+	.read		= seq_read,
+	.write		= pmu_s0ix_lat_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static void update_simple_stat(struct simple_stat *simple_stat, int count)
+{
+	u64 duration = simple_stat->curr;
+
+	if (!count) {
+		simple_stat->min =
+		simple_stat->max =
+		simple_stat->total = duration;
+	} else {
+		if (duration < simple_stat->min)
+			simple_stat->min = duration;
+		else if (duration > simple_stat->max)
+			simple_stat->max = duration;
+		simple_stat->total += duration;
+	}
+}
+
+void s0ix_scu_latency_stat(int type)
+{
+	if (!lat_stat || !lat_stat->latency_measure)
+		return;
+
+	if (type < SYS_STATE_S0I1 || type > SYS_STATE_S3)
+		return;
+
+	lat_stat->scu_latency[type].entry.curr =
+			readl(lat_stat->scu_s0ix_lat_addr);
+	lat_stat->scu_latency[type].exit.curr =
+			readl(lat_stat->scu_s0ix_lat_addr + 1);
+
+	update_simple_stat(&lat_stat->scu_latency[type].entry,
+					lat_stat->count[type]);
+	update_simple_stat(&lat_stat->scu_latency[type].exit,
+					lat_stat->count[type]);
+}
+
+void s0ix_lat_stat_init(void)
+{
+	if (!platform_is(INTEL_ATOM_CLV))
+		return;
+
+	lat_stat = kzalloc(sizeof(struct latency_stat), GFP_KERNEL);
+	if (unlikely(!lat_stat)) {
+		pr_err("Failed to allocate memory for s0ix latency!\n");
+		goto out_err0;
+	}
+
+	lat_stat->scu_s0ix_lat_addr =
+		ioremap_nocache(S0IX_LAT_SRAM_ADDR_CLVP,
+					S0IX_LAT_SRAM_SIZE_CLVP);
+	if (unlikely(!lat_stat->scu_s0ix_lat_addr)) {
+		pr_err("Failed to map SCU_S0IX_LAT_ADDR!\n");
+		goto out_err1;
+	}
+
+	lat_stat->dentry = debugfs_create_file("s0ix_latency",
+			S_IFREG | S_IRUGO, NULL, NULL, &s0ix_latency_ops);
+	if (unlikely(!lat_stat->dentry)) {
+		pr_err("Failed to create debugfs for s0ix latency!\n");
+		goto out_err2;
+	}
+
+	return;
+
+out_err2:
+	iounmap(lat_stat->scu_s0ix_lat_addr);
+out_err1:
+	kfree(lat_stat);
+	lat_stat = NULL;
+out_err0:
+	pr_err("%s: Initialization failed\n", __func__);
+}
+
+void s0ix_lat_stat_finish(void)
+{
+	if (!platform_is(INTEL_ATOM_CLV))
+		return;
+
+	if (unlikely(!lat_stat))
+		return;
+
+	if (likely(lat_stat->scu_s0ix_lat_addr))
+		iounmap(lat_stat->scu_s0ix_lat_addr);
+
+	if (likely(lat_stat->dentry))
+		debugfs_remove(lat_stat->dentry);
+
+	kfree(lat_stat);
+	lat_stat = NULL;
+}
+
+void time_stamp_in_suspend_flow(int mark, bool start)
+{
+	if (!lat_stat || !lat_stat->latency_measure)
+		return;
+
+	if (start) {
+		lat_stat->s3_parts_lat[mark].curr = cpu_clock(0);
+		return;
+	}
+
+	lat_stat->s3_parts_lat[mark].curr = cpu_clock(0) -
+				lat_stat->s3_parts_lat[mark].curr;
+}
+
+static void collect_sleep_state_latency_stat(int sleep_state)
+{
+	int i;
+	if (sleep_state == SYS_STATE_S3)
+		for (i = 0; i < MAX_S3_PARTS; i++)
+			update_simple_stat(&lat_stat->s3_parts_lat[i],
+						lat_stat->count[sleep_state]);
+
+	update_simple_stat(&lat_stat->os_latency[sleep_state].entry,
+						lat_stat->count[sleep_state]);
+	update_simple_stat(&lat_stat->os_latency[sleep_state].exit,
+						lat_stat->count[sleep_state]);
+	lat_stat->count[sleep_state]++;
+}
+
+void time_stamp_for_sleep_state_latency(int sleep_state, bool start, bool entry)
+{
+	if (!lat_stat || !lat_stat->latency_measure)
+		return;
+
+	if (start) {
+		if (entry)
+			lat_stat->os_latency[sleep_state].entry.curr =
+								cpu_clock(0);
+		else
+			lat_stat->os_latency[sleep_state].exit.curr =
+								cpu_clock(0);
+		return;
+	}
+
+	if (entry)
+		lat_stat->os_latency[sleep_state].entry.curr = cpu_clock(0) -
+				lat_stat->os_latency[sleep_state].entry.curr;
+	else {
+		lat_stat->os_latency[sleep_state].exit.curr = cpu_clock(0) -
+				lat_stat->os_latency[sleep_state].exit.curr;
+		collect_sleep_state_latency_stat(sleep_state);
+	}
+}
+#else /* CONFIG_PM_DEBUG */
+void s0ix_scu_latency_stat(int type) {}
+void s0ix_lat_stat_init(void) {}
+void s0ix_lat_stat_finish(void) {}
+void time_stamp_for_sleep_state_latency(int sleep_state, bool start,
+							bool entry) {}
+void time_stamp_in_suspend_flow(int mark, bool start) {}
+inline unsigned int pmu_get_new_cstate
+		(unsigned int cstate, int *index) { return cstate; };
+#endif /* CONFIG_PM_DEBUG */
+
+static char *dstates[] = {"D0", "D0i1", "D0i2", "D0i3"};
+
+/* This can be used to report NC power transitions */
+void (*nc_report_power_state) (u32, int);
+
+#if defined(CONFIG_INTEL_REMOVEME_ATOM_MDFLD_POWER)			\
+			|| defined(CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER)
+
+#define PMU_DEBUG_PRINT_STATS	(1U << 0)
+static int debug_mask;
+module_param_named(debug_mask, debug_mask, int, S_IRUGO | S_IWUSR | S_IWGRP);
+
+#define DEBUG_PRINT(logging_type, s, debug_level_mask, args...)		\
+	do {								\
+		if (logging_type)					\
+			seq_printf(s, args);				\
+		else if (debug_mask &					\
+			PMU_DEBUG_PRINT_##debug_level_mask)		\
+			pr_info(args);					\
+	} while (0)
+
+static struct island display_islands[] = {
+	{APM_REG_TYPE, APM_GRAPHICS_ISLAND, "GFX"},
+	{APM_REG_TYPE, APM_VIDEO_DEC_ISLAND, "Video Decoder"},
+	{APM_REG_TYPE, APM_VIDEO_ENC_ISLAND, "Video Encoder"},
+	{APM_REG_TYPE, APM_GL3_CACHE_ISLAND, "GL3 Cache"},
+	{OSPM_REG_TYPE, OSPM_DISPLAY_A_ISLAND, "Display A"},
+	{OSPM_REG_TYPE, OSPM_DISPLAY_B_ISLAND, "Display B"},
+	{OSPM_REG_TYPE, OSPM_DISPLAY_C_ISLAND, "Display C"},
+	{OSPM_REG_TYPE, OSPM_MIPI_ISLAND, "MIPI-DSI"}
+};
+
+static struct island camera_islands[] = {
+	{APM_REG_TYPE, APM_ISP_ISLAND, "ISP"},
+	{APM_REG_TYPE, APM_IPH_ISLAND, "Iunit PHY"}
+};
+
+static char *lss_device_status[4] = { "D0i0", "D0i1", "D0i2", "D0i3" };
+
+static int lsses_num =
+			sizeof(lsses)/sizeof(lsses[0]);
+
+#ifdef LOG_PMU_EVENTS
+static void pmu_log_timestamp(struct timespec *ts)
+{
+	if (timekeeping_suspended) {
+		ts->tv_sec = 0;
+		ts->tv_nsec = 0;
+	} else {
+		ktime_get_ts(ts);
+	}
+}
+
+void pmu_log_pmu_irq(int status)
+{
+	struct mid_pmu_pmu_irq_log *log =
+		&mid_pmu_cxt->pmu_irq_log[mid_pmu_cxt->pmu_irq_log_idx];
+
+	log->status = status;
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->pmu_irq_log_idx =
+		(mid_pmu_cxt->pmu_irq_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_pmu_irq_log(void)
+{
+	struct mid_pmu_pmu_irq_log *log;
+	int i = mid_pmu_cxt->pmu_irq_log_idx, j;
+
+	printk(KERN_ERR"%d last pmu irqs:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->pmu_irq_log[i];
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		printk(KERN_ERR"Status = 0x%02x", log->status);
+		printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_log_ipc_irq(void)
+{
+	struct mid_pmu_ipc_irq_log *log =
+		&mid_pmu_cxt->ipc_irq_log[mid_pmu_cxt->ipc_irq_log_idx];
+
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->ipc_irq_log_idx =
+	(mid_pmu_cxt->ipc_irq_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_ipc_irq_log(void)
+{
+	struct mid_pmu_ipc_irq_log *log;
+	int i = mid_pmu_cxt->ipc_irq_log_idx, j;
+
+	printk(KERN_ERR"%d last ipc irqs:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->ipc_irq_log[i];
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_log_ipc(u32 command)
+{
+	struct mid_pmu_ipc_log *log =
+	&mid_pmu_cxt->ipc_log[mid_pmu_cxt->ipc_log_idx];
+
+	log->command = command;
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->ipc_log_idx = (mid_pmu_cxt->ipc_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_ipc_log(void)
+{
+	struct mid_pmu_ipc_log *log;
+	int i = mid_pmu_cxt->ipc_log_idx, j;
+
+	printk(KERN_ERR"%d last ipc commands:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i  ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->ipc_log[i];
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		printk(KERN_ERR"Command: 0x%08x", log->command);
+		printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc)
+{
+	struct mid_pmu_cmd_log *log =
+		&mid_pmu_cxt->cmd_log[mid_pmu_cxt->cmd_log_idx];
+
+	if (pm_ssc != NULL)
+		memcpy(&log->pm_ssc, pm_ssc, sizeof(struct pmu_ss_states));
+	else
+		memset(&log->pm_ssc, 0, sizeof(struct pmu_ss_states));
+	log->command = command;
+	pmu_log_timestamp(&log->ts);
+	mid_pmu_cxt->cmd_log_idx = (mid_pmu_cxt->cmd_log_idx + 1) % LOG_SIZE;
+}
+
+static void pmu_dump_command_log(void)
+{
+	struct mid_pmu_cmd_log *log;
+	int i = mid_pmu_cxt->cmd_log_idx, j, k;
+	u32 cmd_state;
+	printk(KERN_ERR"%d last pmu commands:\n", LOG_SIZE);
+
+	for (j = 0; j  < LOG_SIZE; j++) {
+		i ? i-- : (i = LOG_SIZE - 1);
+		log = &mid_pmu_cxt->cmd_log[i];
+		cmd_state = log->command;
+		printk(KERN_ERR"Timestamp: %lu.%09lu\n",
+			log->ts.tv_sec, log->ts.tv_nsec);
+		switch (cmd_state) {
+		case INTERACTIVE_VALUE:
+			printk(KERN_ERR"PM_CMD = Interactive_CMD IOC bit not set.\n");
+			break;
+		case INTERACTIVE_IOC_VALUE:
+			printk(KERN_ERR"PM_CMD = Interactive_CMD IOC bit set.\n");
+			break;
+		case S0I1_VALUE:
+			printk(KERN_ERR"PM_CMD = S0i1_CMD\n");
+			break;
+		case S0I3_VALUE:
+			printk(KERN_ERR"PM_CMD = S0i3_CMD\n");
+			break;
+		case LPMP3_VALUE:
+			printk(KERN_ERR"PM_CMD = LPMP3_CMD\n");
+			break;
+		default:
+			printk(KERN_ERR "Invalid PM_CMD\n");
+			break;
+		}
+		for (k = 0; k < 4; k++)
+			printk(KERN_ERR"pmu2_states[%d]: 0x%08lx\n",
+				k, log->pm_ssc.pmu2_states[k]);
+			printk(KERN_ERR"\n");
+	}
+}
+
+void pmu_dump_logs(void)
+{
+	struct timespec ts;
+
+	pmu_log_timestamp(&ts);
+	printk(KERN_ERR"Dumping out pmu logs\n");
+	printk(KERN_ERR"Timestamp: %lu.%09lu\n\n", ts.tv_sec, ts.tv_nsec);
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_command_log();
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_pmu_irq_log();
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_ipc_log();
+	printk(KERN_ERR"---------------------------------------\n\n");
+	pmu_dump_ipc_irq_log();
+}
+#else
+void pmu_log_pmu_irq(int status) {}
+void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc) {}
+void pmu_dump_logs(void) {}
+#endif /* LOG_PMU_EVENTS */
+
+void pmu_stat_start(enum sys_state type)
+{
+	mid_pmu_cxt->pmu_current_state = type;
+	mid_pmu_cxt->pmu_stats[type].last_try = cpu_clock(smp_processor_id());
+}
+
+void pmu_stat_end(void)
+{
+	enum sys_state type = mid_pmu_cxt->pmu_current_state;
+
+	if (type > SYS_STATE_S0I0 && type < SYS_STATE_MAX) {
+		mid_pmu_cxt->pmu_stats[type].last_entry =
+			mid_pmu_cxt->pmu_stats[type].last_try;
+
+		if (!mid_pmu_cxt->pmu_stats[type].count)
+			mid_pmu_cxt->pmu_stats[type].first_entry =
+				mid_pmu_cxt->pmu_stats[type].last_entry;
+
+		mid_pmu_cxt->pmu_stats[type].time +=
+			cpu_clock(smp_processor_id())
+			- mid_pmu_cxt->pmu_stats[type].last_entry;
+
+		mid_pmu_cxt->pmu_stats[type].count++;
+
+		s0ix_scu_latency_stat(type);
+		if (type >= SYS_STATE_S0I1 && type <= SYS_STATE_S0I3)
+			/* time stamp for end of s0ix exit */
+			time_stamp_for_sleep_state_latency(type, false, false);
+	}
+
+	mid_pmu_cxt->pmu_current_state = SYS_STATE_S0I0;
+}
+
+void pmu_stat_error(u8 err_type)
+{
+	enum sys_state type = mid_pmu_cxt->pmu_current_state;
+	u8 err_index;
+
+	if (type > SYS_STATE_S0I0 && type < SYS_STATE_MAX) {
+		switch (err_type) {
+		case SUBSYS_POW_ERR_INT:
+			trace_printk("S0ix_POW_ERR_INT\n");
+			err_index = 0;
+			break;
+		case S0ix_MISS_INT:
+			trace_printk("S0ix_MISS_INT\n");
+			err_index = 1;
+			break;
+		case NO_ACKC6_INT:
+			trace_printk("S0ix_NO_ACKC6_INT\n");
+			err_index = 2;
+			break;
+		default:
+			err_index = 3;
+			break;
+		}
+
+		if (err_index < 3)
+			mid_pmu_cxt->pmu_stats[type].err_count[err_index]++;
+	}
+}
+
+static void pmu_stat_seq_printf(struct seq_file *s, int type, char *typestr)
+{
+	unsigned long long t;
+	unsigned long nanosec_rem, remainder;
+	unsigned long time, init_2_now_time;
+
+	seq_printf(s, "%s\t%5llu\t%10llu\t%9llu\t%9llu\t", typestr,
+		 mid_pmu_cxt->pmu_stats[type].count,
+		 mid_pmu_cxt->pmu_stats[type].err_count[0],
+		 mid_pmu_cxt->pmu_stats[type].err_count[1],
+		 mid_pmu_cxt->pmu_stats[type].err_count[2]);
+
+	t = mid_pmu_cxt->pmu_stats[type].time;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	/* convert time in secs */
+	time = (unsigned long)t;
+
+	seq_printf(s, "%5lu.%06lu\t",
+	   (unsigned long) t, nanosec_rem / 1000);
+
+	t = mid_pmu_cxt->pmu_stats[type].last_entry;
+	nanosec_rem = do_div(t, NANO_SEC);
+	seq_printf(s, "%5lu.%06lu\t",
+	   (unsigned long) t, nanosec_rem / 1000);
+
+	t = mid_pmu_cxt->pmu_stats[type].first_entry;
+	nanosec_rem = do_div(t, NANO_SEC);
+	seq_printf(s, "%5lu.%06lu\t",
+	   (unsigned long) t, nanosec_rem / 1000);
+
+	t =  cpu_clock(raw_smp_processor_id());
+	t -= mid_pmu_cxt->pmu_init_time;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	init_2_now_time =  (unsigned long) t;
+
+	/* for calculating percentage residency */
+	time = time * 100;
+	t = (u64) time;
+
+	/* take care of divide by zero */
+	if (init_2_now_time) {
+		remainder = do_div(t, init_2_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		 * decimal dot */
+		remainder *= 1000;
+		t = (u64) remainder;
+		remainder = do_div(t, init_2_now_time);
+	} else
+		time = t = 0;
+
+	seq_printf(s, "%5lu.%03lu\n", time, (unsigned long) t);
+}
+
+static unsigned long pmu_dev_res_print(int index, unsigned long *precision,
+				unsigned long *sampled_time, bool dev_state)
+{
+	unsigned long long t, delta_time = 0;
+	unsigned long nanosec_rem, remainder;
+	unsigned long time, init_to_now_time;
+
+	t =  cpu_clock(raw_smp_processor_id());
+
+	if (dev_state) {
+		/* print for d0ix */
+		if ((mid_pmu_cxt->pmu_dev_res[index].state != PCI_D0))
+			delta_time = t -
+				mid_pmu_cxt->pmu_dev_res[index].d0i3_entry;
+
+			delta_time += mid_pmu_cxt->pmu_dev_res[index].d0i3_acc;
+	} else {
+		/* print for d0i0 */
+		if ((mid_pmu_cxt->pmu_dev_res[index].state == PCI_D0))
+			delta_time = t -
+				mid_pmu_cxt->pmu_dev_res[index].d0i0_entry;
+
+		delta_time += mid_pmu_cxt->pmu_dev_res[index].d0i0_acc;
+	}
+
+	t -= mid_pmu_cxt->pmu_dev_res[index].start;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	init_to_now_time =  (unsigned long) t;
+
+	t = delta_time;
+	nanosec_rem = do_div(t, NANO_SEC);
+
+	/* convert time in secs */
+	time = (unsigned long)t;
+	*sampled_time = time;
+
+	/* for calculating percentage residency */
+	time = time * 100;
+	t = (u64) time;
+
+	/* take care of divide by zero */
+	if (init_to_now_time) {
+		remainder = do_div(t, init_to_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		* decimal dot */
+		remainder *= 1000;
+		t = (u64) remainder;
+		remainder = do_div(t, init_to_now_time);
+	} else
+		time = t = 0;
+
+	*precision = (unsigned long)t;
+
+	return time;
+}
+
+static void nc_device_state_show(struct seq_file *s, struct pci_dev *pdev)
+{
+	int off, i, islands_num, state;
+	struct island *islands;
+
+	if (PCI_SLOT(pdev->devfn) == DEV_GFX &&
+			PCI_FUNC(pdev->devfn) == FUNC_GFX) {
+		off = mid_pmu_cxt->display_off;
+		islands_num = ISLANDS_GFX;
+		islands = &display_islands[0];
+	} else if (PCI_SLOT(pdev->devfn) == DEV_ISP &&
+			PCI_FUNC(pdev->devfn) == FUNC_ISP) {
+		off = mid_pmu_cxt->camera_off;
+		islands_num = ISLANDS_ISP;
+		islands = &camera_islands[0];
+	} else {
+		return;
+	}
+
+	seq_printf(s, "pci %04x %04X %s %20s: %41s %s\n",
+		pdev->vendor, pdev->device, dev_name(&pdev->dev),
+		dev_driver_string(&pdev->dev),
+		"", off ? "" : "blocking s0ix");
+	for (i = 0; i < islands_num; i++) {
+		state = pmu_nc_get_power_state(islands[i].index,
+				islands[i].type);
+		seq_printf(s, "%52s %15s %17s %s\n",
+				 "|------->", islands[i].name, "",
+				(state >= 0) ? dstates[state & 3] : "ERR");
+	}
+}
+
+static int pmu_devices_state_show(struct seq_file *s, void *unused)
+{
+	struct pci_dev *pdev = NULL;
+	int index, i, pmu_num, ss_idx, ss_pos;
+	unsigned int base_class;
+	u32 target_mask, mask, val, needed;
+	struct pmu_ss_states cur_pmsss;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	pmu_read_sss(&cur_pmsss);
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	seq_printf(s, "TARGET_CFG: ");
+	seq_printf(s, "SSS0:%08X ", S0IX_TARGET_SSS0_MASK);
+	seq_printf(s, "SSS1:%08X ", S0IX_TARGET_SSS1_MASK);
+	seq_printf(s, "SSS2:%08X ", S0IX_TARGET_SSS2_MASK);
+	seq_printf(s, "SSS3:%08X ", S0IX_TARGET_SSS3_MASK);
+
+	seq_printf(s, "\n");
+	seq_printf(s, "CONDITION FOR S0I3: ");
+	seq_printf(s, "SSS0:%08X ", S0IX_TARGET_SSS0);
+	seq_printf(s, "SSS1:%08X ", S0IX_TARGET_SSS1);
+	seq_printf(s, "SSS2:%08X ", S0IX_TARGET_SSS2);
+	seq_printf(s, "SSS3:%08X ", S0IX_TARGET_SSS3);
+
+	seq_printf(s, "\n");
+	seq_printf(s, "SSS: ");
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "%08lX ", cur_pmsss.pmu2_states[i]);
+
+	if (!mid_pmu_cxt->display_off)
+		seq_printf(s, "display not suspended: blocking s0ix\n");
+	else if (!mid_pmu_cxt->camera_off)
+		seq_printf(s, "camera not suspended: blocking s0ix\n");
+	else if (mid_pmu_cxt->s0ix_possible & MID_S0IX_STATE)
+		seq_printf(s, "can enter s0i1 or s0i3\n");
+	else if (mid_pmu_cxt->s0ix_possible & MID_LPMP3_STATE)
+		seq_printf(s, "can enter lpmp3\n");
+	else
+		seq_printf(s, "blocking s0ix\n");
+
+	seq_printf(s, "cmd_error_int count: %d\n", mid_pmu_cxt->cmd_error_int);
+
+	seq_printf(s,
+	"\tcount\tsybsys_pow\ts0ix_miss\tno_ack_c6\ttime (secs)\tlast_entry");
+	seq_printf(s, "\tfirst_entry\tresidency(%%)\n");
+
+	pmu_stat_seq_printf(s, SYS_STATE_S0I1, "s0i1");
+	pmu_stat_seq_printf(s, SYS_STATE_S0I2, "lpmp3");
+	pmu_stat_seq_printf(s, SYS_STATE_S0I3, "s0i3");
+	pmu_stat_seq_printf(s, SYS_STATE_S3, "s3");
+
+	while ((pdev = pci_get_device(PCI_ID_ANY, PCI_ID_ANY, pdev)) != NULL) {
+
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		if (pmu_pci_to_indexes(pdev, &index, &pmu_num, &ss_idx,
+								  &ss_pos))
+			continue;
+
+		if (pmu_num == PMU_NUM_1) {
+			nc_device_state_show(s, pdev);
+			continue;
+		}
+
+		mask	= (D0I3_MASK << (ss_pos * BITS_PER_LSS));
+		val	= (cur_pmsss.pmu2_states[ss_idx] & mask) >>
+						(ss_pos * BITS_PER_LSS);
+		switch (ss_idx) {
+		case 0:
+			target_mask = S0IX_TARGET_SSS0_MASK;
+			break;
+		case 1:
+			target_mask = S0IX_TARGET_SSS1_MASK;
+			break;
+		case 2:
+			target_mask = S0IX_TARGET_SSS2_MASK;
+			break;
+		case 3:
+			target_mask = S0IX_TARGET_SSS3_MASK;
+			break;
+		default:
+			target_mask = 0;
+			break;
+		}
+		needed	= ((target_mask &  mask) != 0);
+
+		seq_printf(s, "pci %04x %04X %s %20s: lss:%02d reg:%d"
+			"mask:%08X wk:%02d:%02d:%02d:%03d %s  %s\n",
+			pdev->vendor, pdev->device, dev_name(&pdev->dev),
+			dev_driver_string(&pdev->dev),
+			index - mid_pmu_cxt->pmu1_max_devs, ss_idx, mask,
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S0I1],
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S0I2],
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S0I3],
+			mid_pmu_cxt->num_wakes[index][SYS_STATE_S3],
+			dstates[val & 3],
+			(needed && !val) ? "blocking s0ix" : "");
+
+	}
+
+	return 0;
+}
+
+static int devices_state_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_devices_state_show, NULL);
+}
+
+static ssize_t devices_state_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+
+	buf[buf_size] = 0;
+
+	if (((strlen("clear")+1) == buf_size) &&
+		!strncmp(buf, "clear", strlen("clear"))) {
+		down(&mid_pmu_cxt->scu_ready_sem);
+		memset(mid_pmu_cxt->pmu_stats, 0,
+					sizeof(mid_pmu_cxt->pmu_stats));
+		memset(mid_pmu_cxt->num_wakes, 0,
+					sizeof(mid_pmu_cxt->num_wakes));
+		mid_pmu_cxt->pmu_current_state = SYS_STATE_S0I0;
+		mid_pmu_cxt->pmu_init_time =
+			cpu_clock(raw_smp_processor_id());
+		clear_d0ix_stats();
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations devices_state_operations = {
+	.open		= devices_state_open,
+	.read		= seq_read,
+	.write		= devices_state_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int show_pmu_lss_status(struct seq_file *s, void *unused)
+{
+	int sss_reg_index;
+	int offset;
+	int lss;
+	unsigned long status;
+	unsigned long sub_status;
+	unsigned long lss_status[4];
+	struct lss_definition *entry;
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	lss_status[0] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[0]);
+	lss_status[1] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[1]);
+	lss_status[2] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[2]);
+	lss_status[3] = readl(&mid_pmu_cxt->pmu_reg->pm_sss[3]);
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	lss = 0;
+	seq_printf(s, "%5s\t%12s %35s %5s %4s %4s %4s %4s\n",
+			"lss", "block", "subsystem", "state", "D0i0", "D0i1",
+			"D0i2", "D0i3");
+	seq_printf(s, "====================================================="
+		      "=====================\n");
+	for (sss_reg_index = 0; sss_reg_index < 4; sss_reg_index++) {
+		status = lss_status[sss_reg_index];
+		for (offset = 0; offset < sizeof(unsigned long) * 8 / 2;
+								offset++) {
+			sub_status = status & 3;
+			if (lss >= lsses_num)
+				entry = &lsses[lsses_num - 1];
+			else
+				entry = &lsses[lss];
+			seq_printf(s, "%5s\t%12s %35s %4s %4d %4d %4d %4d\n",
+					entry->lss_name, entry->block,
+					entry->subsystem,
+					lss_device_status[sub_status],
+					get_d0ix_stat(lss, SS_STATE_D0I0),
+					get_d0ix_stat(lss, SS_STATE_D0I1),
+					get_d0ix_stat(lss, SS_STATE_D0I2),
+					get_d0ix_stat(lss, SS_STATE_D0I3));
+
+			status >>= 2;
+			lss++;
+		}
+	}
+
+	return 0;
+}
+
+static int pmu_sss_state_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_lss_status, NULL);
+}
+
+static const struct file_operations pmu_sss_state_operations = {
+	.open		= pmu_sss_state_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int show_pmu_dev_stats(struct seq_file *s, void *unused)
+{
+	struct pci_dev *pdev = NULL;
+	unsigned long sampled_time, precision;
+	int index, pmu_num, ss_idx, ss_pos;
+	unsigned int base_class;
+
+	seq_printf(s, "%5s\t%20s\t%10s\t%10s\t%s\n",
+		"lss", "Name", "D0_res", "D0ix_res", "Sampled_Time");
+	seq_printf(s,
+	"==================================================================\n");
+
+	while ((pdev = pci_get_device(PCI_ID_ANY, PCI_ID_ANY, pdev)) != NULL) {
+
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		if (pmu_pci_to_indexes(pdev, &index, &pmu_num, &ss_idx,
+							&ss_pos))
+			continue;
+
+		if (pmu_num == PMU_NUM_1) {
+			seq_printf(s,
+			"%5s%20s\t%5lu.%03lu%%\t%5lu.%03lu%%\t%lu\n",
+			"NC", dev_driver_string(&pdev->dev),
+			pmu_dev_res_print(index, &precision,
+				 &sampled_time, false),
+			precision,
+			pmu_dev_res_print(index, &precision,
+				 &sampled_time, true),
+			precision, sampled_time);
+			continue;
+		}
+
+		/* Print for South Complex devices */
+		seq_printf(s, "%5d\t%20s\t%5lu.%03lu%%\t%5lu.%03lu%%\t%lu\n",
+		index - mid_pmu_cxt->pmu1_max_devs,
+		dev_driver_string(&pdev->dev),
+		pmu_dev_res_print(index, &precision, &sampled_time, false),
+		precision,
+		pmu_dev_res_print(index, &precision, &sampled_time, true),
+		precision, sampled_time);
+	}
+	return 0;
+}
+
+static int pmu_dev_stat_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_dev_stats, NULL);
+}
+
+static const struct file_operations pmu_dev_stat_operations = {
+	.open		= pmu_dev_stat_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+#ifdef CONFIG_PM_DEBUG
+static int pmu_stats_interval = PMU_LOG_INTERVAL_SECS;
+module_param_named(pmu_stats_interval, pmu_stats_interval,
+				int, S_IRUGO | S_IWUSR | S_IWGRP);
+
+void pmu_s0ix_demotion_stat(int req_state, int grant_state)
+{
+	struct pmu_ss_states cur_pmsss;
+	int i, req_sys_state, offset;
+	unsigned long status, sub_status;
+	unsigned long s0ix_target_sss_mask[4] = {
+				S0IX_TARGET_SSS0_MASK,
+				S0IX_TARGET_SSS1_MASK,
+				S0IX_TARGET_SSS2_MASK,
+				S0IX_TARGET_SSS3_MASK};
+
+	unsigned long s0ix_target_sss[4] = {
+				S0IX_TARGET_SSS0,
+				S0IX_TARGET_SSS1,
+				S0IX_TARGET_SSS2,
+				S0IX_TARGET_SSS3};
+
+	unsigned long lpmp3_target_sss_mask[4] = {
+				LPMP3_TARGET_SSS0_MASK,
+				LPMP3_TARGET_SSS1_MASK,
+				LPMP3_TARGET_SSS2_MASK,
+				LPMP3_TARGET_SSS3_MASK};
+
+	unsigned long lpmp3_target_sss[4] = {
+				LPMP3_TARGET_SSS0,
+				LPMP3_TARGET_SSS1,
+				LPMP3_TARGET_SSS2,
+				LPMP3_TARGET_SSS3};
+
+	req_sys_state = mid_state_to_sys_state(req_state);
+	if ((grant_state >= C4_STATE_IDX) && (grant_state <= S0I3_STATE_IDX))
+		mid_pmu_cxt->pmu_stats
+			[req_sys_state].demote_count
+				[grant_state-C4_STATE_IDX]++;
+
+	if (down_trylock(&mid_pmu_cxt->scu_ready_sem))
+		return;
+
+	pmu_read_sss(&cur_pmsss);
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	if (!mid_pmu_cxt->camera_off)
+		mid_pmu_cxt->pmu_stats[req_sys_state].camera_blocker_count++;
+
+	if (!mid_pmu_cxt->display_off)
+		mid_pmu_cxt->pmu_stats[req_sys_state].display_blocker_count++;
+
+	if (!mid_pmu_cxt->s0ix_possible) {
+		for (i = 0; i < 4; i++) {
+			unsigned int lss_per_register;
+			if (req_state == MID_LPMP3_STATE)
+				status = lpmp3_target_sss[i] ^
+					(cur_pmsss.pmu2_states[i] &
+						lpmp3_target_sss_mask[i]);
+			else
+				status = s0ix_target_sss[i] ^
+					(cur_pmsss.pmu2_states[i] &
+						s0ix_target_sss_mask[i]);
+			if (!status)
+				continue;
+
+			lss_per_register =
+				(sizeof(unsigned long)*8)/BITS_PER_LSS;
+
+			for (offset = 0; offset < lss_per_register; offset++) {
+				sub_status = status & SS_IDX_MASK;
+				if (sub_status) {
+					mid_pmu_cxt->pmu_stats[req_sys_state].
+						blocker_count
+						[offset + lss_per_register*i]++;
+				}
+
+				status >>= BITS_PER_LSS;
+			}
+		}
+	}
+}
+EXPORT_SYMBOL(pmu_s0ix_demotion_stat);
+
+static void pmu_log_s0ix_status(int type, char *typestr,
+		struct seq_file *s, bool logging_type)
+{
+	unsigned long long t;
+	unsigned long time, remainder, init_2_now_time;
+
+	t = mid_pmu_cxt->pmu_stats[type].time;
+	remainder = do_div(t, NANO_SEC);
+
+	/* convert time in secs */
+	time = (unsigned long)t;
+
+	t =  cpu_clock(0);
+	t -= mid_pmu_cxt->pmu_init_time;
+	remainder = do_div(t, NANO_SEC);
+
+	init_2_now_time =  (unsigned long) t;
+
+	/* for calculating percentage residency */
+	t = (u64) time * 100;
+
+	/* take care of divide by zero */
+	if (init_2_now_time) {
+		remainder = do_div(t, init_2_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		 * decimal dot */
+		remainder *= 1000;
+		t = (u64) remainder;
+		remainder = do_div(t, init_2_now_time);
+	} else
+		time = t = 0;
+	DEBUG_PRINT(logging_type, s, STATS,
+			"%s\t%5llu\t%9llu\t%9llu\t%5lu.%03lu\n"
+			, typestr, mid_pmu_cxt->pmu_stats[type].count,
+			mid_pmu_cxt->pmu_stats[type].err_count[1],
+			mid_pmu_cxt->pmu_stats[type].err_count[2],
+			time, (unsigned long) t);
+}
+
+static void pmu_log_s0ix_demotion(int type, char *typestr,
+		struct seq_file *s, bool logging_type)
+{
+	DEBUG_PRINT(logging_type, s, STATS, "%s:\t%6d\t%6d\t%6d\t%6d\t%6d\n",
+		typestr,
+		mid_pmu_cxt->pmu_stats[type].demote_count[0],
+		mid_pmu_cxt->pmu_stats[type].demote_count[1],
+		mid_pmu_cxt->pmu_stats[type].demote_count[2],
+		mid_pmu_cxt->pmu_stats[type].demote_count[3],
+		mid_pmu_cxt->pmu_stats[type].demote_count[4]);
+}
+
+static void pmu_log_s0ix_lss_blocked(int type, char *typestr,
+		struct seq_file *s, bool logging_type)
+{
+	int i, block_count;
+
+	DEBUG_PRINT(logging_type, s, STATS, "%s: Block Count\n", typestr);
+
+	block_count = mid_pmu_cxt->pmu_stats[type].display_blocker_count;
+
+	if (block_count)
+		DEBUG_PRINT(logging_type, s, STATS,
+			 "\tDisplay blocked: %d times\n", block_count);
+
+	block_count = mid_pmu_cxt->pmu_stats[type].camera_blocker_count;
+
+	if (block_count)
+		DEBUG_PRINT(logging_type, s, STATS,
+			"\tCamera blocked: %d times\n", block_count);
+
+	DEBUG_PRINT(logging_type, s, STATS, "\tLSS\t #blocked\n");
+
+	for  (i = 0; i < MAX_LSS_POSSIBLE; i++) {
+		block_count = mid_pmu_cxt->pmu_stats[type].blocker_count[i];
+		if (block_count)
+			DEBUG_PRINT(logging_type, s, STATS, "\t%02d\t %6d\n", i,
+						block_count);
+	}
+	DEBUG_PRINT(logging_type, s, STATS, "\n");
+}
+
+static void pmu_stats_logger(bool logging_type, struct seq_file *s)
+{
+
+	if (!logging_type)
+		DEBUG_PRINT(logging_type, s, STATS,
+			"\n----MID_PMU_STATS_LOG_BEGIN----\n");
+
+	DEBUG_PRINT(logging_type, s, STATS,
+			"\tcount\ts0ix_miss\tno_ack_c6\tresidency(%%)\n");
+	pmu_log_s0ix_status(SYS_STATE_S0I1, "s0i1", s, logging_type);
+	pmu_log_s0ix_status(SYS_STATE_S0I2, "lpmp3", s, logging_type);
+	pmu_log_s0ix_status(SYS_STATE_S0I3, "s0i3", s, logging_type);
+	pmu_log_s0ix_status(SYS_STATE_S3, "s3", s, logging_type);
+
+	DEBUG_PRINT(logging_type, s, STATS, "\nFrom:\tTo\n");
+	DEBUG_PRINT(logging_type, s, STATS,
+		"\t    C4\t   C6\t  S0i1\t  Lpmp3\t  S0i3\n");
+
+	/* storing C6 demotion info in S0I0 */
+	pmu_log_s0ix_demotion(SYS_STATE_S0I0, "  C6", s, logging_type);
+
+	pmu_log_s0ix_demotion(SYS_STATE_S0I1, "s0i1", s, logging_type);
+	pmu_log_s0ix_demotion(SYS_STATE_S0I2, "lpmp3", s, logging_type);
+	pmu_log_s0ix_demotion(SYS_STATE_S0I3, "s0i3", s, logging_type);
+
+	DEBUG_PRINT(logging_type, s, STATS, "\n");
+	pmu_log_s0ix_lss_blocked(SYS_STATE_S0I1, "s0i1", s, logging_type);
+	pmu_log_s0ix_lss_blocked(SYS_STATE_S0I2, "lpmp3", s, logging_type);
+	pmu_log_s0ix_lss_blocked(SYS_STATE_S0I3, "s0i3", s, logging_type);
+
+	if (!logging_type)
+		DEBUG_PRINT(logging_type, s, STATS,
+				"\n----MID_PMU_STATS_LOG_END----\n");
+}
+
+static void pmu_log_stat(struct work_struct *work)
+{
+
+	pmu_stats_logger(false, NULL);
+
+	schedule_delayed_work(&mid_pmu_cxt->log_work,
+			msecs_to_jiffies(pmu_stats_interval*1000));
+}
+
+static int show_pmu_stats_log(struct seq_file *s, void *unused)
+{
+	pmu_stats_logger(true, s);
+	return 0;
+}
+
+static int pmu_stats_log_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, show_pmu_stats_log, NULL);
+}
+
+static const struct file_operations pmu_stats_log_operations = {
+	.open		= pmu_stats_log_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+#else
+void pmu_s0ix_demotion_stat(int req_state, int grant_state) {}
+EXPORT_SYMBOL(pmu_s0ix_demotion_stat);
+#endif
+
+void pmu_stats_init(void)
+{
+	struct dentry *fentry;
+
+	/* /sys/kernel/debug/mid_pmu_states */
+	(void) debugfs_create_file("mid_pmu_states", S_IFREG | S_IRUGO,
+				NULL, NULL, &devices_state_operations);
+
+	/* /sys/kernel/debug/pmu_sss_states */
+	(void) debugfs_create_file("pmu_sss_states", S_IFREG | S_IRUGO,
+				NULL, NULL, &pmu_sss_state_operations);
+
+	/* /sys/kernel/debug/pmu_dev_stats */
+	(void) debugfs_create_file("pmu_dev_stats", S_IFREG | S_IRUGO,
+				NULL, NULL, &pmu_dev_stat_operations);
+
+	s0ix_lat_stat_init();
+
+#ifdef CONFIG_PM_DEBUG
+	/* dynamic debug tracing in every 5 mins */
+	INIT_DEFERRABLE_WORK(&mid_pmu_cxt->log_work, pmu_log_stat);
+	schedule_delayed_work(&mid_pmu_cxt->log_work,
+				msecs_to_jiffies(pmu_stats_interval*1000));
+
+	debug_mask = PMU_DEBUG_PRINT_STATS;
+
+	/* /sys/kernel/debug/pmu_stats_log */
+	fentry = debugfs_create_file("pmu_stats_log", S_IFREG | S_IRUGO,
+				NULL, NULL, &pmu_stats_log_operations);
+	if (fentry == NULL)
+		printk(KERN_ERR "Failed to create pmu_stats_log debugfs\n");
+#endif
+}
+
+void pmu_s3_stats_update(int enter)
+{
+
+}
+
+void pmu_stats_finish(void)
+{
+#ifdef CONFIG_PM_DEBUG
+	cancel_delayed_work_sync(&mid_pmu_cxt->log_work);
+#endif
+	s0ix_lat_stat_finish();
+}
+
+#endif /*if CONFIG_X86_MDFLD_POWER || CONFIG_X86_CLV_POWER*/
+
+#ifdef CONFIG_INTEL_REMOVEME_ATOM_MRFLD_POWER
+static char *nc_devices[] = {
+	"GFXSLC",
+	"GSDKCK",
+	"GRSCD",
+	"VED",
+	"VEC",
+	"DPA",
+	"DPB",
+	"DPC",
+	"VSP",
+	"ISP",
+	"MIO",
+	"HDMIO",
+	"GFXSLCLDO"
+};
+
+static int no_of_nc_devices = sizeof(nc_devices)/sizeof(nc_devices[0]);
+
+static void pmu_stat_seq_printf(struct seq_file *s, int type, char *typestr)
+{
+	unsigned long long t;
+	u32 scu_val, time;
+	u32 micro_sec_rem, remainder;
+	unsigned long init_2_now_time;
+
+	/* Print S0ix residency counter */
+	if (type < SYS_STATE_S3) {
+		t = readq(residency[type]);
+		if (t < prev_s0ix_res[type-1])
+			t += (((unsigned long long)~0) - prev_s0ix_res[type-1]);
+		else
+			t -= prev_s0ix_res[type-1];
+
+		if (type == SYS_STATE_S0I3)
+			t -= prev_s0ix_res[SYS_STATE_S3-1];
+	} else
+		t = prev_s0ix_res[SYS_STATE_S3-1];
+
+	micro_sec_rem = do_div(t, MICRO_SEC);
+	time = (unsigned int)t;
+
+	seq_printf(s, "%s\t%5lu.%03lu\t",
+		typestr, (unsigned long)(t),
+			(unsigned long) micro_sec_rem / 1000);
+
+	t =  cpu_clock(0);
+	t -= mid_pmu_cxt->pmu_init_time;
+	do_div(t, NANO_SEC);
+	init_2_now_time =  (unsigned long) t;
+
+	/* for calculating percentage residency */
+	time = time * 100;
+	t = (u64) time;
+
+	/* take care of divide by zero */
+	if (init_2_now_time) {
+		remainder = do_div(t, init_2_now_time);
+		time = (unsigned long) t;
+
+		/* for getting 3 digit precision after
+		 * decimal dot */
+		remainder *= 1000;
+		t = (u64) remainder;
+		remainder = do_div(t, init_2_now_time);
+	} else
+		time = t = 0;
+
+	seq_printf(s, "%5lu.%03lu\t", (unsigned long) time, (unsigned long) t);
+
+	/* Print number of interations of S0ix */
+	if (type < SYS_STATE_S3) {
+		scu_val = readl(s0ix_counter[type]);
+		if (scu_val < prev_s0ix_cnt[type-1])
+			scu_val += (((u32)~0) - prev_s0ix_cnt[type-1]);
+		else
+			scu_val -= prev_s0ix_cnt[type-1];
+
+		if (type == SYS_STATE_S0I3)
+			scu_val -= prev_s0ix_cnt[SYS_STATE_S3-1];
+	} else
+			scu_val = prev_s0ix_cnt[SYS_STATE_S3-1];
+
+	seq_printf(s, "%lu\n", (unsigned long) scu_val);
+}
+
+static int pmu_devices_state_show(struct seq_file *s, void *unused)
+{
+	struct pci_dev *pdev = NULL;
+	int index, i, pmu_num, ss_idx, ss_pos;
+	unsigned int base_class;
+	u32 mask, val, nc_pwr_sts;
+	struct pmu_ss_states cur_pmsss;
+	int ret;
+
+	if (!pmu_initialized)
+		return 0;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	pmu_read_sss(&cur_pmsss);
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	seq_printf(s, "SSS: ");
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "%08lX ", cur_pmsss.pmu2_states[i]);
+
+	seq_printf(s, "cmd_error_int count: %d\n", mid_pmu_cxt->cmd_error_int);
+
+	seq_printf(s, "\ttime(secs)\tresidency(%%)\tcount\n");
+
+	/* Dump S0ix residency counters */
+	ret = intel_scu_ipc_simple_command(DUMP_RES_COUNTER, 0);
+	if (ret) {
+		seq_printf(s, "IPC command to DUMP S0ix residency failed\n");
+		return 0;
+	}
+
+	/* Dump number of interations of S0ix */
+	ret = intel_scu_ipc_simple_command(DUMP_S0IX_COUNT, 0);
+	if (ret)
+		seq_printf(s, "IPC command to DUMP S0ix count failed\n");
+
+	pmu_stat_seq_printf(s, SYS_STATE_S0I1, "s0i1");
+	pmu_stat_seq_printf(s, SYS_STATE_S0I2, "S0i2");
+	pmu_stat_seq_printf(s, SYS_STATE_S0I3, "s0i3");
+	pmu_stat_seq_printf(s, SYS_STATE_S3, "s3");
+
+	seq_printf(s, "\nNORTH COMPLEX DEVICES :\n\n");
+
+	nc_pwr_sts = intel_mid_msgbus_read32(PUNIT_PORT, NC_PM_SSS);
+	for (i = 0; i < no_of_nc_devices; i++) {
+		val = nc_pwr_sts & 3;
+		nc_pwr_sts >>= BITS_PER_LSS;
+		seq_printf(s, "%9s : %s\n", nc_devices[i], dstates[val]);
+	}
+
+	seq_printf(s, "\nSOUTH COMPLEX DEVICES :\n\n");
+
+	while ((pdev = pci_get_device(PCI_ID_ANY, PCI_ID_ANY, pdev)) != NULL) {
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		if (pmu_pci_to_indexes(pdev, &index, &pmu_num, &ss_idx,
+								  &ss_pos))
+			continue;
+
+		if (pmu_num == PMU_NUM_1)
+			continue;
+
+		mask	= (D0I3_MASK << (ss_pos * BITS_PER_LSS));
+		val	= (cur_pmsss.pmu2_states[ss_idx] & mask) >>
+						(ss_pos * BITS_PER_LSS);
+
+		seq_printf(s, "pci %04x %04X %s %20.20s: lss:%02d reg:%d ",
+			pdev->vendor, pdev->device, dev_name(&pdev->dev),
+			dev_driver_string(&pdev->dev),
+			index - mid_pmu_cxt->pmu1_max_devs, ss_idx);
+		seq_printf(s, "mask:%08X  %s\n",  mask, dstates[val & 3]);
+	}
+
+	return 0;
+}
+
+static int devices_state_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_devices_state_show, NULL);
+}
+
+static ssize_t devices_state_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int ret;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+	buf[buf_size] = 0;
+
+	if (((strlen("clear")+1) == buf_size) &&
+		!strncmp(buf, "clear", strlen("clear"))) {
+		down(&mid_pmu_cxt->scu_ready_sem);
+
+		/* Dump S0ix residency counters */
+		ret = intel_scu_ipc_simple_command(DUMP_RES_COUNTER, 0);
+		if (ret)
+			printk(KERN_ERR "IPC command to DUMP S0ix residency failed\n");
+
+		/* Dump number of interations of S0ix */
+		ret = intel_scu_ipc_simple_command(DUMP_S0IX_COUNT, 0);
+		if (ret)
+			printk(KERN_ERR "IPC command to DUMP S0ix count failed\n");
+
+		mid_pmu_cxt->pmu_init_time = cpu_clock(0);
+		prev_s0ix_cnt[0] = readl(s0ix_counter[SYS_STATE_S0I1]);
+		prev_s0ix_cnt[1] = readl(s0ix_counter[SYS_STATE_S0I2]);
+		prev_s0ix_cnt[2] = readl(s0ix_counter[SYS_STATE_S0I3]);
+		prev_s0ix_cnt[3] = 0;
+		prev_s0ix_res[0] = readq(residency[SYS_STATE_S0I1]);
+		prev_s0ix_res[1] = readq(residency[SYS_STATE_S0I2]);
+		prev_s0ix_res[2] = readq(residency[SYS_STATE_S0I3]);
+		prev_s0ix_res[3] = 0 ;
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+	return buf_size;
+}
+
+
+static const struct file_operations devices_state_operations = {
+	.open		= devices_state_open,
+	.read		= seq_read,
+	.write		= devices_state_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+#ifdef CONFIG_PM_DEBUG
+static int ignore_lss_show(struct seq_file *s, void *unused)
+{
+	u32 local_ignore_lss[4];
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(local_ignore_lss, mid_pmu_cxt->ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	seq_printf(s, "IGNORE_LSS[0]: %08X\n", local_ignore_lss[0]);
+	seq_printf(s, "IGNORE_LSS[1]: %08X\n", local_ignore_lss[1]);
+	seq_printf(s, "IGNORE_LSS[2]: %08X\n", local_ignore_lss[2]);
+	seq_printf(s, "IGNORE_LSS[3]: %08X\n", local_ignore_lss[3]);
+
+	return 0;
+}
+
+static int ignore_add_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, ignore_lss_show, NULL);
+}
+
+static ssize_t ignore_add_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	int sub_sys_pos, sub_sys_index;
+	u32 lss, local_ignore_lss[4];
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(local_ignore_lss, mid_pmu_cxt->ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	/* If set to MAX_LSS_POSSIBLE it means
+	 * ignore all.
+	 */
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_ignore_lss[0] = 0xFFFFFFFF;
+		local_ignore_lss[1] = 0xFFFFFFFF;
+		local_ignore_lss[2] = 0xFFFFFFFF;
+		local_ignore_lss[3] = 0xFFFFFFFF;
+	} else {
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+		local_ignore_lss[sub_sys_index] |= pm_cmd_val;
+	}
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(mid_pmu_cxt->ignore_lss, local_ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations ignore_add_ops = {
+	.open		= ignore_add_open,
+	.read		= seq_read,
+	.write		= ignore_add_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int ignore_remove_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, ignore_lss_show, NULL);
+}
+
+static ssize_t ignore_remove_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	int sub_sys_pos, sub_sys_index;
+	u32 lss, local_ignore_lss[4];
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(local_ignore_lss, mid_pmu_cxt->ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	/* If set to MAX_LSS_POSSIBLE it means
+	 * remove all from ignore list.
+	 */
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_ignore_lss[0] = 0;
+		local_ignore_lss[1] = 0;
+		local_ignore_lss[2] = 0;
+		local_ignore_lss[3] = 0;
+	} else {
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+		local_ignore_lss[sub_sys_index] &= ~pm_cmd_val;
+	}
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	memcpy(mid_pmu_cxt->ignore_lss, local_ignore_lss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations ignore_remove_ops = {
+	.open		= ignore_remove_open,
+	.read		= seq_read,
+	.write		= ignore_remove_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int pmu_sync_d0ix_show(struct seq_file *s, void *unused)
+{
+	int i;
+	u32 local_os_sss[4];
+	struct pmu_ss_states cur_pmsss;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	/* Read SCU SSS */
+	pmu_read_sss(&cur_pmsss);
+	/* Read OS SSS */
+	memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "OS_SSS[%d]: %08X\tSSS[%d]: %08lX\n", i,
+				local_os_sss[i], i, cur_pmsss.pmu2_states[i]);
+
+	return 0;
+}
+
+static int pmu_sync_d0ix_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_sync_d0ix_show, NULL);
+}
+
+static ssize_t pmu_sync_d0ix_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res, i;
+	bool send_cmd;
+	int buf_size = min(count, sizeof(buf)-1);
+	u32 lss, local_os_sss[4];
+	int sub_sys_pos, sub_sys_index;
+	u32 pm_cmd_val;
+	u32 temp_sss;
+
+	struct pmu_ss_states cur_pmsss;
+
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	_pmu2_wait_not_busy();
+	/* Read SCU SSS */
+	pmu_read_sss(&cur_pmsss);
+
+	for (i = 0; i < 4; i++)
+		local_os_sss[i] = mid_pmu_cxt->os_sss[i] &
+				~mid_pmu_cxt->ignore_lss[i];
+
+	send_cmd = false;
+	for (i = 0; i < 4; i++) {
+		if (local_os_sss[i] != cur_pmsss.pmu2_states[i]) {
+			send_cmd = true;
+			break;
+		}
+	}
+
+	if (send_cmd) {
+		int status;
+
+		if (lss == MAX_LSS_POSSIBLE) {
+			memcpy(cur_pmsss.pmu2_states, local_os_sss,
+							 (sizeof(u32)*4));
+		} else {
+			bool same;
+			sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+			sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+			pm_cmd_val =
+				(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+			/* dont send d0ix request if its same */
+			same =
+			((cur_pmsss.pmu2_states[sub_sys_index] & pm_cmd_val)
+			== (mid_pmu_cxt->os_sss[sub_sys_index] & pm_cmd_val));
+
+			if (same)
+				goto unlock;
+
+			cur_pmsss.pmu2_states[sub_sys_index] &= ~pm_cmd_val;
+			temp_sss =
+				mid_pmu_cxt->os_sss[sub_sys_index] & pm_cmd_val;
+			cur_pmsss.pmu2_states[sub_sys_index] |= temp_sss;
+		}
+
+		/* Issue the pmu command to PMU 2
+		 * flag is needed to distinguish between
+		 * S0ix vs interactive command in pmu_sc_irq()
+		 */
+		status = pmu_issue_interactive_command(&cur_pmsss, false,
+							false);
+
+		if (unlikely(status != PMU_SUCCESS)) {
+			dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				 "Failed to Issue a PM command to PMU2\n");
+			goto unlock;
+		}
+
+		/*
+		 * Wait for interactive command to complete.
+		 * If we dont wait, there is a possibility that
+		 * the driver may access the device before its
+		 * powered on in SCU.
+		 *
+		 */
+		status = _pmu2_wait_not_busy();
+		if (unlikely(status)) {
+			printk(KERN_CRIT "%s: D0ix transition failure\n",
+				__func__);
+		}
+	}
+
+unlock:
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations pmu_sync_d0ix_ops = {
+	.open		= pmu_sync_d0ix_open,
+	.read		= seq_read,
+	.write		= pmu_sync_d0ix_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int pmu_force_d0ix_show(struct seq_file *s, void *unused)
+{
+	int i;
+	u32 local_os_sss[4];
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+	/* Read OS SSS */
+	memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	for (i = 0; i < 4; i++)
+		seq_printf(s, "OS_SSS[%d]: %08X\n", i, local_os_sss[i]);
+
+	return 0;
+}
+
+static int pmu_force_d0ix_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, pmu_force_d0ix_show, NULL);
+}
+
+static ssize_t pmu_force_d0i3_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	u32 lss, local_os_sss[4];
+	int sub_sys_pos, sub_sys_index;
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_os_sss[0] =
+		local_os_sss[1] =
+		local_os_sss[2] =
+		local_os_sss[3] = 0xFFFFFFFF;
+	} else {
+		memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+		local_os_sss[sub_sys_index] |= pm_cmd_val;
+	}
+
+	memcpy(mid_pmu_cxt->os_sss, local_os_sss, (sizeof(u32)*4));
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations pmu_force_d0i3_ops = {
+	.open		= pmu_force_d0ix_open,
+	.read		= seq_read,
+	.write		= pmu_force_d0i3_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static ssize_t pmu_force_d0i0_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int buf_size = min(count, sizeof(buf)-1);
+	u32 lss, local_os_sss[4];
+	int sub_sys_pos, sub_sys_index;
+	u32 pm_cmd_val;
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &lss);
+
+	if (res)
+		return -EINVAL;
+
+	if (lss > MAX_LSS_POSSIBLE)
+		return -EINVAL;
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	if (lss == MAX_LSS_POSSIBLE) {
+		local_os_sss[0] =
+		local_os_sss[1] =
+		local_os_sss[2] =
+		local_os_sss[3] = 0;
+	} else {
+		memcpy(local_os_sss, mid_pmu_cxt->os_sss, (sizeof(u32)*4));
+		sub_sys_index	= lss / mid_pmu_cxt->ss_per_reg;
+		sub_sys_pos	= lss % mid_pmu_cxt->ss_per_reg;
+		pm_cmd_val =
+			(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+		local_os_sss[sub_sys_index] &= ~pm_cmd_val;
+	}
+
+	memcpy(mid_pmu_cxt->os_sss, local_os_sss, (sizeof(u32)*4));
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return buf_size;
+}
+
+static const struct file_operations pmu_force_d0i0_ops = {
+	.open		= pmu_force_d0ix_open,
+	.read		= seq_read,
+	.write		= pmu_force_d0i0_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int cstate_ignore_add_show(struct seq_file *s, void *unused)
+{
+	int i;
+	seq_printf(s, "CSTATES IGNORED: ");
+	for (i = 0; i < MWAIT_MAX_NUM_CSTATES; i++)
+		if ((mid_pmu_cxt->cstate_ignore & (1 << i)))
+			seq_printf(s, "%d, ", i+1);
+
+	seq_printf(s, "\n");
+	return 0;
+}
+
+static int cstate_ignore_add_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, cstate_ignore_add_show, NULL);
+}
+
+static ssize_t cstate_ignore_add_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int cstate;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &cstate);
+
+	if (res)
+		return -EINVAL;
+
+	if (cstate > MAX_CSTATES_POSSIBLE)
+		return -EINVAL;
+
+	/* cannot add/remove C0, C1 */
+	if (((cstate == 0) || (cstate == 1))) {
+		printk(KERN_CRIT "C0 C1 state cannot be used.\n");
+		return -EINVAL;
+	}
+
+	if (!mid_pmu_cxt->cstate_qos)
+		return -EINVAL;
+
+	if (cstate == MAX_CSTATES_POSSIBLE) {
+		mid_pmu_cxt->cstate_ignore = ((1 << MWAIT_MAX_NUM_CSTATES) - 1);
+		/* Ignore C2, C3, C4, C5 states */
+		mid_pmu_cxt->cstate_ignore |= (1 << 1);
+		mid_pmu_cxt->cstate_ignore |= (1 << 2);
+		mid_pmu_cxt->cstate_ignore |= (1 << 3);
+		mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+					CSTATE_EXIT_LATENCY_C1 - 1);
+	} else {
+		u32 cstate_exit_latency[MWAIT_MAX_NUM_CSTATES+1];
+		u32 local_cstate_allowed;
+		int max_cstate_allowed;
+
+		/* 0 is C1 state */
+		cstate--;
+		mid_pmu_cxt->cstate_ignore |= (1 << cstate);
+
+		/* by default remove C1 from ignore list */
+		mid_pmu_cxt->cstate_ignore &= ~(1 << 0);
+
+		/* Ignore C2, C3, C4, C5 states */
+		mid_pmu_cxt->cstate_ignore |= (1 << 1);
+		mid_pmu_cxt->cstate_ignore |= (1 << 2);
+		mid_pmu_cxt->cstate_ignore |= (1 << 3);
+		mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+		/* populate cstate latency table */
+		cstate_exit_latency[0] = CSTATE_EXIT_LATENCY_C1;
+		cstate_exit_latency[1] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[2] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[3] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[4] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[5] = CSTATE_EXIT_LATENCY_C6;
+		cstate_exit_latency[6] = CSTATE_EXIT_LATENCY_S0i1;
+		cstate_exit_latency[7] = CSTATE_EXIT_LATENCY_S0i2;
+		cstate_exit_latency[8] = CSTATE_EXIT_LATENCY_S0i3;
+		cstate_exit_latency[9] = PM_QOS_DEFAULT_VALUE;
+		cstate_exit_latency[10] = PM_QOS_DEFAULT_VALUE;
+
+		local_cstate_allowed = ~mid_pmu_cxt->cstate_ignore;
+
+		/* restrict to max c-states */
+		local_cstate_allowed &= ((1<<MWAIT_MAX_NUM_CSTATES)-1);
+
+		/* If no states allowed will return 0 */
+		max_cstate_allowed = fls(local_cstate_allowed);
+
+		printk(KERN_CRIT "max_cstate: %d local_cstate_allowed = %x\n",
+			max_cstate_allowed, local_cstate_allowed);
+		printk(KERN_CRIT "exit latency = %d\n",
+				(cstate_exit_latency[max_cstate_allowed]-1));
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+				(cstate_exit_latency[max_cstate_allowed]-1));
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations cstate_ignore_add_ops = {
+	.open		= cstate_ignore_add_open,
+	.read		= seq_read,
+	.write		= cstate_ignore_add_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int cstate_ignore_remove_show(struct seq_file *s, void *unused)
+{
+	int i;
+	seq_printf(s, "CSTATES ALLOWED: ");
+	for (i = 0; i < MWAIT_MAX_NUM_CSTATES; i++)
+		if (!(mid_pmu_cxt->cstate_ignore & (1 << i)))
+			seq_printf(s, "%d, ", i+1);
+
+	seq_printf(s, "\n");
+
+	return 0;
+}
+
+static int cstate_ignore_remove_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, cstate_ignore_remove_show, NULL);
+}
+
+static ssize_t cstate_ignore_remove_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int cstate;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &cstate);
+
+	if (res)
+		return -EINVAL;
+
+	if (cstate > MAX_CSTATES_POSSIBLE)
+		return -EINVAL;
+
+	/* cannot add/remove C0, C1 */
+	if (((cstate == 0) || (cstate == 1))) {
+		printk(KERN_CRIT "C0 C1 state cannot be used.\n");
+		return -EINVAL;
+	}
+
+	if (!mid_pmu_cxt->cstate_qos)
+		return -EINVAL;
+
+	if (cstate == MAX_CSTATES_POSSIBLE) {
+		mid_pmu_cxt->cstate_ignore =
+				~((1 << MWAIT_MAX_NUM_CSTATES) - 1);
+		/* Ignore C2, C3, C4, C5 states */
+		mid_pmu_cxt->cstate_ignore |= (1 << 1);
+		mid_pmu_cxt->cstate_ignore |= (1 << 2);
+		mid_pmu_cxt->cstate_ignore |= (1 << 3);
+		mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+						PM_QOS_DEFAULT_VALUE);
+	} else {
+		u32 cstate_exit_latency[MWAIT_MAX_NUM_CSTATES+1];
+		u32 local_cstate_allowed;
+		int max_cstate_allowed;
+
+		/* populate cstate latency table */
+		cstate_exit_latency[0] = CSTATE_EXIT_LATENCY_C1;
+		cstate_exit_latency[1] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[2] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[3] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[4] = CSTATE_EXIT_LATENCY_C2;
+		cstate_exit_latency[5] = CSTATE_EXIT_LATENCY_C6;
+		cstate_exit_latency[6] = CSTATE_EXIT_LATENCY_S0i1;
+		cstate_exit_latency[7] = CSTATE_EXIT_LATENCY_S0i2;
+		cstate_exit_latency[8] = CSTATE_EXIT_LATENCY_S0i3;
+		cstate_exit_latency[9] = PM_QOS_DEFAULT_VALUE;
+		cstate_exit_latency[10] = PM_QOS_DEFAULT_VALUE;
+
+		/* 0 is C1 state */
+		cstate--;
+		mid_pmu_cxt->cstate_ignore &= ~(1 << cstate);
+
+		/* by default remove C1 from ignore list */
+		mid_pmu_cxt->cstate_ignore &= ~(1 << 0);
+
+		/* Ignore C2, C3, C4, C5 states */
+		mid_pmu_cxt->cstate_ignore |= (1 << 1);
+		mid_pmu_cxt->cstate_ignore |= (1 << 2);
+		mid_pmu_cxt->cstate_ignore |= (1 << 3);
+		mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+		local_cstate_allowed = ~mid_pmu_cxt->cstate_ignore;
+		/* restrict to max c-states */
+		local_cstate_allowed &= ((1<<MWAIT_MAX_NUM_CSTATES)-1);
+
+		/* If no states allowed will return 0 */
+		max_cstate_allowed = fls(local_cstate_allowed);
+		printk(KERN_CRIT "max_cstate: %d local_cstate_allowed = %x\n",
+			max_cstate_allowed, local_cstate_allowed);
+		printk(KERN_CRIT "exit latency = %d\n",
+				(cstate_exit_latency[max_cstate_allowed]-1));
+		pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+				(cstate_exit_latency[max_cstate_allowed]-1));
+	}
+
+	return buf_size;
+}
+
+static const struct file_operations cstate_ignore_remove_ops = {
+	.open		= cstate_ignore_remove_open,
+	.read		= seq_read,
+	.write		= cstate_ignore_remove_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+static int s3_ctrl_show(struct seq_file *s, void *unused)
+{
+	seq_printf(s, "%d\n", enable_s3);
+	return 0;
+}
+
+static int s3_ctrl_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, s3_ctrl_show, NULL);
+}
+
+static ssize_t s3_ctrl_write(struct file *file,
+		     const char __user *userbuf, size_t count, loff_t *ppos)
+{
+	char buf[32];
+	int res;
+	int local_s3_ctrl;
+	int buf_size = min(count, sizeof(buf)-1);
+
+	if (copy_from_user(buf, userbuf, buf_size))
+		return -EFAULT;
+
+	buf[buf_size] = 0;
+
+	res = kstrtou32(buf, 10, &local_s3_ctrl);
+
+	if (res)
+		return -EINVAL;
+
+	enable_s3 = local_s3_ctrl ? 1 : 0;
+
+	if (enable_s3)
+		__pm_relax(mid_pmu_cxt->pmu_wake_lock);
+	else
+		__pm_stay_awake(mid_pmu_cxt->pmu_wake_lock);
+
+	return buf_size;
+}
+
+static const struct file_operations s3_ctrl_ops = {
+	.open		= s3_ctrl_open,
+	.read		= seq_read,
+	.write		= s3_ctrl_write,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+
+unsigned int pmu_get_new_cstate(unsigned int cstate, int *index)
+{
+	static int cstate_index_table[MWAIT_MAX_NUM_CSTATES] = {
+					1, 1, 1, 1, 1, 2, 3, 4, 5, 6};
+	unsigned int new_cstate = cstate;
+	u32 local_cstate = (u32)(cstate);
+	u32 local_cstate_allowed = ~mid_pmu_cxt->cstate_ignore;
+	u32 cstate_mask;
+
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		/* cstate is 7 for C8 and C9 so correct */
+		if ((local_cstate == 7) && (*index == 4))
+			local_cstate = 8;
+		else if ((local_cstate == 7) && (*index == 5))
+			local_cstate = 9;
+
+		/* get next low cstate allowed */
+		cstate_mask	= (u32)((1 << local_cstate)-1);
+		local_cstate_allowed	&= ((1<<MWAIT_MAX_NUM_CSTATES)-1);
+		local_cstate_allowed	&= cstate_mask;
+		new_cstate	= fls(local_cstate_allowed);
+
+		if (likely(new_cstate))
+			*index	= cstate_index_table[new_cstate-1];
+		else
+			new_cstate = 1;
+	}
+
+	return new_cstate;
+}
+#endif
+
+DEFINE_PER_CPU(u64[NUM_CSTATES_RES_MEASURE], c_states_res);
+
+static int read_c_states_res(void)
+{
+	int cpu, i;
+	u32 lo, hi;
+
+	u32 c_states_res_msr[NUM_CSTATES_RES_MEASURE] = {
+		PUNIT_CR_CORE_C1_RES_MSR,
+		PUNIT_CR_CORE_C4_RES_MSR,
+		PUNIT_CR_CORE_C6_RES_MSR
+	};
+
+	for_each_online_cpu(cpu)
+		for (i = 0; i < NUM_CSTATES_RES_MEASURE; i++) {
+			u64 temp;
+			rdmsr_on_cpu(cpu, c_states_res_msr[i], &lo, &hi);
+			temp = hi;
+			temp <<= 32;
+			temp |= lo;
+			per_cpu(c_states_res, cpu)[i] = temp;
+		}
+
+	return 0;
+}
+
+static int c_states_stat_show(struct seq_file *s, void *unused)
+{
+	char *c_states_name[] = {
+		"C1",
+		"C4",
+		"C6"
+	};
+
+	int i, cpu;
+
+	seq_printf(s, "C STATES: %20s\n", "Residecy");
+	for_each_online_cpu(cpu)
+		seq_printf(s, "%18s %d", "Core", cpu);
+	seq_printf(s, "\n");
+
+	read_c_states_res();
+	for (i = 0; i < NUM_CSTATES_RES_MEASURE; i++) {
+		seq_printf(s, "%s", c_states_name[i]);
+		for_each_online_cpu(cpu)
+			seq_printf(s, "%18llu", per_cpu(c_states_res, cpu)[i]);
+		seq_printf(s, "\n");
+	}
+	return 0;
+}
+
+static int c_states_stat_open(struct inode *inode, struct file *file)
+{
+	return single_open(file, c_states_stat_show, NULL);
+}
+
+static const struct file_operations c_states_stat_ops = {
+	.open		= c_states_stat_open,
+	.read		= seq_read,
+	.llseek		= seq_lseek,
+	.release	= single_release,
+};
+
+/*These are place holders and will be enabled in next patch*/
+
+void pmu_log_pmu_irq(int status) { return; };
+void pmu_log_ipc_irq(void) { return; };
+void pmu_log_ipc(u32 command) { return; };
+void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc) { return; };
+void pmu_dump_logs(void) { return; };
+void pmu_stat_start(enum sys_state type) { return; };
+void pmu_stat_end(void) { return; };
+void pmu_stat_error(u8 err_type) { return; };
+void pmu_s0ix_demotion_stat(int req_state, int grant_state) { return; };
+EXPORT_SYMBOL(pmu_s0ix_demotion_stat);
+
+void pmu_stats_finish(void)
+{
+#ifdef CONFIG_PM_DEBUG
+	if (mid_pmu_cxt->cstate_qos) {
+		pm_qos_remove_request(mid_pmu_cxt->cstate_qos);
+		kfree(mid_pmu_cxt->cstate_qos);
+		mid_pmu_cxt->cstate_qos = NULL;
+	}
+#endif
+
+	return;
+}
+
+void pmu_s3_stats_update(int enter)
+{
+#ifdef CONFIG_PM_DEBUG
+	int ret;
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+	/* Dump S0ix residency counters */
+	ret = intel_scu_ipc_simple_command(DUMP_RES_COUNTER, 0);
+	if (ret)
+		printk(KERN_ERR "IPC command to DUMP S0ix residency failed\n");
+
+	/* Dump number of interations of S0ix */
+	ret = intel_scu_ipc_simple_command(DUMP_S0IX_COUNT, 0);
+	if (ret)
+		printk(KERN_ERR "IPC command to DUMP S0ix count failed\n");
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	if (enter == 1) {
+		S3_count  = readl(s0ix_counter[SYS_STATE_S0I3]);
+		S3_res = readl(residency[SYS_STATE_S0I3]);
+	} else {
+		prev_s0ix_cnt[3] +=
+			(readl(s0ix_counter[SYS_STATE_S0I3])) - S3_count;
+		prev_s0ix_res[3] += (readl(residency[SYS_STATE_S0I3])) - S3_res;
+	}
+
+#endif
+	return;
+}
+
+
+void pmu_stats_init(void)
+{
+	/* /sys/kernel/debug/mid_pmu_states */
+	(void) debugfs_create_file("mid_pmu_states", S_IFREG | S_IRUGO,
+				NULL, NULL, &devices_state_operations);
+
+	/* /sys/kernel/debug/c_p_states_stat */
+	(void) debugfs_create_file("c_states_stat", S_IFREG | S_IRUGO,
+				NULL, NULL, &c_states_stat_ops);
+#ifdef CONFIG_PM_DEBUG
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		/* If s0ix is disabled then restrict to C6 */
+		if (!enable_s0ix) {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << MWAIT_MAX_NUM_CSTATES) - 1);
+
+			/* Ignore C2, C3, C4, C5 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 3);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+			/* For now ignore C7, C8, C9, C10 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 6);
+			mid_pmu_cxt->cstate_ignore |= (1 << 7);
+			mid_pmu_cxt->cstate_ignore |= (1 << 8);
+			mid_pmu_cxt->cstate_ignore |= (1 << 9);
+		}
+
+		mid_pmu_cxt->cstate_qos =
+			kzalloc(sizeof(struct pm_qos_request), GFP_KERNEL);
+		if (mid_pmu_cxt->cstate_qos) {
+			pm_qos_add_request(mid_pmu_cxt->cstate_qos,
+				 PM_QOS_CPU_DMA_LATENCY, PM_QOS_DEFAULT_VALUE);
+		}
+
+		/* If s0ix is disabled then restrict to C6 */
+		if (!enable_s0ix) {
+			/* Restrict platform Cx state to C6 */
+			pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+						(CSTATE_EXIT_LATENCY_S0i1-1));
+		}
+
+		/* /sys/kernel/debug/ignore_add */
+		(void) debugfs_create_file("ignore_add", S_IFREG | S_IRUGO,
+					NULL, NULL, &ignore_add_ops);
+		/* /sys/kernel/debug/ignore_remove */
+		(void) debugfs_create_file("ignore_remove", S_IFREG | S_IRUGO,
+					NULL, NULL, &ignore_remove_ops);
+		/* /sys/kernel/debug/pmu_sync_d0ix */
+		(void) debugfs_create_file("pmu_sync_d0ix", S_IFREG | S_IRUGO,
+					NULL, NULL, &pmu_sync_d0ix_ops);
+		/* /sys/kernel/debug/pmu_force_d0i0 */
+		(void) debugfs_create_file("pmu_force_d0i0", S_IFREG | S_IRUGO,
+					NULL, NULL, &pmu_force_d0i0_ops);
+		/* /sys/kernel/debug/pmu_force_d0i3 */
+		(void) debugfs_create_file("pmu_force_d0i3", S_IFREG | S_IRUGO,
+					NULL, NULL, &pmu_force_d0i3_ops);
+		/* /sys/kernel/debug/cstate_ignore_add */
+		(void) debugfs_create_file("cstate_ignore_add",
+			S_IFREG | S_IRUGO, NULL, NULL, &cstate_ignore_add_ops);
+		/* /sys/kernel/debug/cstate_ignore_remove */
+		(void) debugfs_create_file("cstate_ignore_remove",
+		S_IFREG | S_IRUGO, NULL, NULL, &cstate_ignore_remove_ops);
+		/* /sys/kernel/debug/cstate_ignore_remove */
+		(void) debugfs_create_file("s3_ctrl",
+		S_IFREG | S_IRUGO, NULL, NULL, &s3_ctrl_ops);
+	}
+#endif
+}
+
+#endif /*if CONFIG_INTEL_REMOVEME_ATOM_MRFLD_POWER*/
diff --git a/arch/x86/platform/intel-mid/intel_soc_pm_debug.h b/arch/x86/platform/intel-mid/intel_soc_pm_debug.h
new file mode 100644
index 000000000000..99700a757ed4
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pm_debug.h
@@ -0,0 +1,234 @@
+/*
+ * intel_soc_pm_debug.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#ifndef _INTEL_SOC_PM_DEBUG_H
+#define _INTEL_SOC_PM_DEBUG_H
+#include <linux/intel_mid_pm.h>
+
+#include "intel_soc_pmu.h"
+
+
+#define NANO_SEC		1000000000UL /* 10^9 in sec */
+#define MICRO_SEC		1000000UL /* 10^6 in sec */
+#define PMU_LOG_INTERVAL_SECS	(60*5) /* 5 mins in secs */
+
+#define S0IX_LAT_SRAM_ADDR_CLVP		0xFFFF7FD0
+#define S0IX_LAT_SRAM_SIZE_CLVP		8
+
+#define IPC_CMD_S0IX_LATENCY_CLVP	0xCE
+#define IPC_SUB_MEASURE_START_CLVP	0x00
+#define IPC_SUB_MEASURE_STOP_CLVP	0x01
+
+struct simple_stat {
+	u64 min;
+	u64 max;
+	u64 total;
+	u64 curr;
+};
+
+struct entry_exit_stat {
+	struct simple_stat entry;
+	struct simple_stat exit;
+};
+
+struct latency_stat {
+	struct entry_exit_stat scu_latency[SYS_STATE_MAX];
+	struct entry_exit_stat os_latency[SYS_STATE_MAX];
+	struct simple_stat s3_parts_lat[MAX_S3_PARTS];
+	u64 count[SYS_STATE_MAX];
+	u32 __iomem *scu_s0ix_lat_addr;
+	struct dentry *dentry;
+	bool latency_measure;
+};
+
+struct island {
+	int type;
+	int index;
+	char *name;
+};
+
+struct lss_definition {
+	char *lss_name;
+	char *block;
+	char *subsystem;
+};
+
+#ifdef CONFIG_INTEL_REMOVEME_ATOM_MRFLD_POWER
+#define PUNIT_CR_CORE_C1_RES_MSR	0x660
+#define PUNIT_CR_CORE_C4_RES_MSR	0x3fc
+#define PUNIT_CR_CORE_C6_RES_MSR	0x3fd
+
+#define NUM_CSTATES_RES_MEASURE		3
+
+extern unsigned int enable_s3;
+extern unsigned int enable_s0ix;
+
+extern u32 __iomem *residency[];
+extern u32 __iomem *s0ix_counter[];
+
+#endif
+
+/* platform dependency starts */
+#ifdef CONFIG_INTEL_REMOVEME_ATOM_MDFLD_POWER
+
+#define DEV_GFX		2
+#define FUNC_GFX	0
+#define ISLANDS_GFX	8
+#define DEV_ISP		3
+#define FUNC_ISP	0
+#define ISLANDS_ISP	2
+#define NC_DEVS		2
+
+static struct lss_definition lsses[] = {
+	{"Lss00", "Storage", "SDIO0 (HC2)"},
+	{"Lss01", "Storage", "eMMC0 (HC0a)"},
+	{"NA", "Storage", "ND_CTL (Note 5)"},
+	{"Lss03", "H S I", "H S I DMA"},
+	{"Lss04", "Security", "RNG"},
+	{"Lss05", "Storage", "eMMC1 (HC0b)"},
+	{"Lss06", "USB", "USB OTG (ULPI)"},
+	{"Lss07", "USB", "USB_SPH"},
+	{"Lss08", "Audio", ""},
+	{"Lss09", "Audio", ""},
+	{"Lss10", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss11", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss12", "SRAM", "SRAM BANK (16KB+3x32KBKB)"},
+	{"Lss13", "SRAM", "SRAM BANK(4x32KB)"},
+	{"Lss14", "SDIO COMMS", "SDIO2 (HC1b)"},
+	{"Lss15", "PTI, DAFCA", " DFX Blocks"},
+	{"Lss16", "SC", " DMA"},
+	{"NA", "SC", "SPI0/MSIC"},
+	{"Lss18", "GP", "SPI1"},
+	{"Lss19", "GP", " SPI2"},
+	{"Lss20", "GP", " I2C0"},
+	{"Lss21", "GP", " I2C1"},
+	{"NA", "Fabrics", " Main Fabric"},
+	{"NA", "Fabrics", " Secondary Fabric"},
+	{"NA", "SC", "SC Fabric"},
+	{"Lss25", "Audio", " I-RAM BANK1 (32 + 256KB)"},
+	{"NA", "SCU", " ROM BANK1 (18KB+18KB+18KB)"},
+	{"Lss27", "GP", "I2C2"},
+	{"NA", "SSC", "SSC (serial bus controller to FLIS)"},
+	{"Lss29", "Security", "Chaabi AON Registers"},
+	{"Lss30", "SDIO COMMS", "SDIO1 (HC1a)"},
+	{"NA", "SCU", "I-RAM BANK0 (32KB)"},
+	{"NA", "SCU", "I-RAM BANK1 (32KB)"},
+	{"Lss33", "GP", "I2C3 (HDMI)"},
+	{"Lss34", "GP", "I2C4"},
+	{"Lss35", "GP", "I2C5"},
+	{"Lss36", "GP", "SSP (SPI3)"},
+	{"Lss37", "GP", "GPIO1"},
+	{"NA", "GP", "GP Fabric"},
+	{"Lss39", "SC", "GPIO0"},
+	{"Lss40", "SC", "KBD"},
+	{"Lss41", "SC", "UART2:0"},
+	{"NA", "NA", "NA"},
+	{"NA", "NA", "NA"},
+	{"Lss44", "Security", " Security TAPC"},
+	{"NA", "MISC", "AON Timers"},
+	{"NA", "PLL", "LFHPLL and Spread Spectrum"},
+	{"NA", "PLL", "USB PLL"},
+	{"NA", "NA", "NA"},
+	{"NA", "Audio", "SLIMBUS CTL 1 (note 5)"},
+	{"NA", "Audio", "SLIMBUS CTL 2 (note 5)"},
+	{"Lss51", "Audio", "SSP0"},
+	{"Lss52", "Audio", "SSP1"},
+	{"NA", "Bridge", "IOSF to OCP Bridge"},
+	{"Lss54", "GP", "DMA"},
+	{"NA", "SC", "SVID (Serial Voltage ID)"},
+	{"NA", "SOC Fuse", "SoC Fuse Block (note 3)"},
+	{"NA", "NA", "NA"},
+};
+#endif
+
+
+#ifdef CONFIG_REMOVEME_INTEL_ATOM_CLV_POWER
+
+#define DEV_GFX		2
+#define FUNC_GFX	0
+#define ISLANDS_GFX	8
+#define DEV_ISP		3
+#define FUNC_ISP	0
+#define ISLANDS_ISP	2
+#define NC_DEVS		2
+
+static struct lss_definition lsses[] = {
+	{"Lss00", "Storage", "SDIO0 (HC2)"},
+	{"Lss01", "Storage", "eMMC0 (HC0a)"},
+	{"NA", "Timer", "AONT"},
+	{"Lss03", "H S I", "H S I DMA"},
+	{"Lss04", "Security", "RNG"},
+	{"Lss05", "Storage", "eMMC1 (HC0b)"},
+	{"Lss06", "USB", "USB OTG (ULPI)"},
+	{"Lss07", "USB", "USB_SPH"},
+	{"Lss08", "Audio", "Audio ENGINE"},
+	{"Lss09", "Audio", "Audio DMA"},
+	{"Lss10", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss11", "SRAM", " SRAM CTL+SRAM_16KB"},
+	{"Lss12", "SRAM", "SRAM BANK (16KB+3x32KBKB)"},
+	{"Lss13", "SRAM", "SRAM BANK(4x32KB)"},
+	{"Lss14", "SDIO COMMS", "SDIO2 (HC1b)"},
+	{"Lss15", "PTI, DAFCA", " DFX Blocks"},
+	{"Lss16", "SC", " DMA"},
+	{"NA", "SC", "SPI0/MSIC"},
+	{"Lss18", "GP", "SPI1"},
+	{"Lss19", "GP", " SPI2"},
+	{"Lss20", "GP", " I2C0"},
+	{"Lss21", "GP", " I2C1"},
+	{"NA", "Timer", "HPET"},
+	{"NA", "Timer", "External Timer"},
+	{"NA", "SC", "SC Fabric"},
+	{"Lss25", "Audio", " I-RAM BANK1 (32 + 256KB)"},
+	{"NA", "SCU", " ROM BANK1 (18KB+18KB+18KB)"},
+	{"Lss27", "GP", "I2C2"},
+	{"NA", "SSC", "SSC (serial bus controller to FLIS)"},
+	{"Lss29", "Security", "Chaabi AON Registers"},
+	{"Lss30", "SDIO COMMS", "SDIO1 (HC1a)"},
+	{"NA", "Timer", "vRTC"},
+	{"NA", "Security", "Security Timer"},
+	{"Lss33", "GP", "I2C3 (HDMI)"},
+	{"Lss34", "GP", "I2C4"},
+	{"Lss35", "GP", "I2C5"},
+	{"Lss36", "GP", "SSP (SPI3)"},
+	{"Lss37", "GP", "GPIO1"},
+	{"NA", "MSIC", "Power Button"},
+	{"Lss39", "SC", "GPIO0"},
+	{"Lss40", "SC", "KBD"},
+	{"Lss41", "SC", "UART2:0"},
+	{"NA", "MSIC", "ADC"},
+	{"NA", "MSIC", "Charger"},
+	{"Lss44", "Security", " Security TAPC"},
+	{"NA", "MSIC", "AON Timers"},
+	{"NA", "MSIC", "GPI"},
+	{"NA", "MSIC", "BCU"},
+	{"NA", "NA", "SSP2"},
+	{"NA", "Audio", "SLIMBUS CTL 1 (note 5)"},
+	{"NA", "Audio", "SLIMBUS CTL 2 (note 5)"},
+	{"Lss51", "Audio", "SSP0"},
+	{"Lss52", "Audio", "SSP1"},
+	{"NA", "Bridge", "IOSF to OCP Bridge"},
+	{"Lss54", "GP", "DMA"},
+	{"NA", "MSIC", "RESET"},
+	{"NA", "SOC Fuse", "SoC Fuse Block (note 3)"},
+	{"NA", "NA", "NA"},
+	{"Lss58", "NA", "SSP4"},
+};
+#endif
+/* platform dependency ends */
+
+#endif
diff --git a/arch/x86/platform/intel-mid/intel_soc_pmu.c b/arch/x86/platform/intel-mid/intel_soc_pmu.c
new file mode 100644
index 000000000000..606ab117833c
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pmu.c
@@ -0,0 +1,2010 @@
+/*
+ * intel_soc_pmu.c - This driver provides interface to configure the 2 pmu's
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+
+#include "intel_soc_pmu.h"
+#include <linux/cpuidle.h>
+#include <linux/proc_fs.h>
+#include <asm/intel_mid_rpmsg.h>
+
+#ifdef CONFIG_DRM_INTEL_MID
+#define GFX_ENABLE
+#endif
+
+bool pmu_initialized;
+
+DEFINE_MUTEX(pci_root_lock);
+
+/* mid_pmu context structure */
+struct mid_pmu_dev *mid_pmu_cxt;
+
+struct platform_pmu_ops *pmu_ops;
+/*
+ * Locking strategy::
+ *
+ * one semaphore (scu_ready sem) is used for accessing busy bit,
+ * issuing interactive cmd in the code.
+ * The entry points in pmu driver are pmu_pci_set_power_state()
+ * and PMU interrupt handler contexts, so here is the flow of how
+ * the semaphore is used.
+ *
+ * In D0ix command case::
+ * set_power_state process context:
+ * set_power_state()->acquire_scu_ready_sem()->issue_interactive_cmd->
+ * wait_for_interactive_complete->release scu_ready sem
+ *
+ * PMU Interrupt context:
+ * pmu_interrupt_handler()->release interactive_complete->return
+ *
+ * In Idle handler case::
+ * Idle context:
+ * idle_handler()->try_acquire_scu_ready_sem->if acquired->
+ * issue s0ix command->return
+ *
+ * PMU Interrupt context:
+ * pmu_Interrupt_handler()->release scu_ready_sem->return
+ *
+ */
+
+/* Maps pci power states to SCU D0ix mask */
+static int pci_to_platform_state(pci_power_t pci_state)
+{
+
+	static int mask[]  = {D0I0_MASK, D0I1_MASK,
+				D0I2_MASK, D0I3_MASK, D0I3_MASK};
+
+	int state = D0I0_MASK;
+
+	if (pci_state > 4)
+		WARN(1, "%s: wrong pci_state received.\n", __func__);
+
+	else
+		state = mask[pci_state];
+
+	return state;
+}
+
+/* Maps power states to pmu driver's internal indexes */
+int mid_state_to_sys_state(int mid_state)
+{
+	int sys_state = 0;
+	switch (mid_state) {
+	case MID_S0I1_STATE:
+		sys_state = SYS_STATE_S0I1;
+		break;
+	case MID_LPMP3_STATE:
+		sys_state = SYS_STATE_S0I2;
+		break;
+	case MID_S0I3_STATE:
+		sys_state = SYS_STATE_S0I3;
+		break;
+	case MID_S3_STATE:
+		sys_state = SYS_STATE_S3;
+		break;
+
+	case C6_HINT:
+		sys_state = SYS_STATE_S0I0;
+	}
+
+	return sys_state;
+}
+
+/* PCI Device Id structure */
+static DEFINE_PCI_DEVICE_TABLE(mid_pm_ids) = {
+	{PCI_VDEVICE(INTEL, MID_PMU_MFLD_DRV_DEV_ID), 0},
+	{PCI_VDEVICE(INTEL, MID_PMU_CLV_DRV_DEV_ID), 0},
+	{PCI_VDEVICE(INTEL, MID_PMU_MRFL_DRV_DEV_ID), 0},
+	{}
+};
+
+MODULE_DEVICE_TABLE(pci, mid_pm_ids);
+
+char s0ix[5] = "s0ix";
+
+module_param_call(s0ix, set_extended_cstate_mode,
+		get_extended_cstate_mode, NULL, 0644);
+
+MODULE_PARM_DESC(s0ix,
+	"setup extended c state s0ix mode [s0i3|s0i1|lmp3|"
+				"i1i3|lpi1|lpi3|s0ix|none]");
+
+/**
+ * This function set all devices in d0i0 and deactivates pmu driver.
+ * The function is used before IFWI update as it needs devices to be
+ * in d0i0 during IFWI update. Reboot is needed to work pmu
+ * driver properly again. After calling this function and IFWI
+ * update, system is always rebooted as IFWI update function,
+ * intel_scu_ipc_medfw_upgrade() is called from mrst_emergency_reboot().
+ */
+int pmu_set_devices_in_d0i0(void)
+{
+	int status;
+	struct pmu_ss_states cur_pmssc;
+
+	/* Ignore request until we have initialized */
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	cur_pmssc.pmu2_states[0] = D0I0_MASK;
+	cur_pmssc.pmu2_states[1] = D0I0_MASK;
+	cur_pmssc.pmu2_states[2] = D0I0_MASK;
+	cur_pmssc.pmu2_states[3] = D0I0_MASK;
+
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	mid_pmu_cxt->shutdown_started = true;
+
+	/* Issue the pmu command to PMU 2
+	 * flag is needed to distinguish between
+	 * S0ix vs interactive command in pmu_sc_irq()
+	 */
+	status = pmu_issue_interactive_command(&cur_pmssc, false, false);
+
+	if (unlikely(status != PMU_SUCCESS)) {	/* pmu command failed */
+		printk(KERN_CRIT "%s: Failed to Issue a PM command to PMU2\n",
+								__func__);
+		mid_pmu_cxt->shutdown_started = false;
+		goto unlock;
+	}
+
+	if (_pmu2_wait_not_busy()) {
+		pmu_dump_logs();
+		BUG();
+	}
+
+unlock:
+	up(&mid_pmu_cxt->scu_ready_sem);
+	return status;
+}
+EXPORT_SYMBOL(pmu_set_devices_in_d0i0);
+
+static int _pmu_read_status(int type)
+{
+	u32 temp;
+	union pmu_pm_status result;
+
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_sts);
+
+	/* extract the busy bit */
+	result.pmu_status_value = temp;
+
+	if (type == PMU_BUSY_STATUS)
+		return result.pmu_status_parts.pmu_busy;
+	else if (type == PMU_MODE_ID)
+		return result.pmu_status_parts.mode_id;
+
+	return 0;
+}
+
+int _pmu2_wait_not_busy(void)
+{
+	int pmu_busy_retry = PMU2_BUSY_TIMEOUT;
+
+	/* wait 500ms that the latest pmu command finished */
+	do {
+		if (_pmu_read_status(PMU_BUSY_STATUS) == 0)
+			return 0;
+
+		udelay(1);
+	} while (--pmu_busy_retry);
+
+	WARN(1, "pmu2 busy!");
+
+	return -EBUSY;
+}
+
+static int _pmu2_wait_not_busy_yield(void)
+{
+	int pmu_busy_retry = 50000; /* 500msec minimum */
+
+	/* wait for the latest pmu command finished */
+	do {
+		usleep_range(10, 500);
+
+		if (!_pmu_read_status(PMU_BUSY_STATUS))
+			return 0;
+	} while (--pmu_busy_retry);
+
+	WARN(1, "pmu2 busy!");
+
+	return -EBUSY;
+}
+
+static void pmu_write_subsys_config(struct pmu_ss_states *pm_ssc)
+{
+	/* South complex in Penwell has multiple registers for
+	 * PM_SSC, etc.
+	 */
+	writel(pm_ssc->pmu2_states[0], &mid_pmu_cxt->pmu_reg->pm_ssc[0]);
+	writel(pm_ssc->pmu2_states[1], &mid_pmu_cxt->pmu_reg->pm_ssc[1]);
+	writel(pm_ssc->pmu2_states[2], &mid_pmu_cxt->pmu_reg->pm_ssc[2]);
+	writel(pm_ssc->pmu2_states[3], &mid_pmu_cxt->pmu_reg->pm_ssc[3]);
+}
+
+void log_wakeup_irq(void)
+{
+	unsigned int irr = 0, vector = 0;
+	int offset = 0, irq = 0;
+	struct irq_desc *desc;
+	const char *act_name;
+
+	if ((mid_pmu_cxt->pmu_current_state != SYS_STATE_S3)
+	    || !mid_pmu_cxt->suspend_started)
+		return;
+
+	for (offset = (FIRST_EXTERNAL_VECTOR/32);
+	offset < (NR_VECTORS/32); offset++) {
+		irr = apic_read(APIC_IRR + (offset * 0x10));
+		while (irr) {
+			vector = __ffs(irr);
+			irr &= ~(1 << vector);
+			irq = __this_cpu_read(
+					vector_irq[vector + (offset * 32)]);
+			if (irq < 0)
+				continue;
+			pr_info("wakeup from  IRQ %d\n", irq);
+
+			desc = irq_to_desc(irq);
+
+			if ((desc) && (desc->action)) {
+				act_name = desc->action->name;
+				pr_info("IRQ %d,action name:%s\n",
+					irq,
+					(act_name) ? (act_name) : "no action");
+			}
+		}
+	}
+	return;
+}
+
+static int pmu_interrupt_pending(void)
+{
+	u32 temp;
+	union pmu_pm_ics result;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+	result.pmu_pm_ics_value = temp;
+
+	/* return the pm interrupt status int pending bit info */
+	return result.pmu_pm_ics_parts.int_pend;
+}
+
+static inline void pmu_clear_pending_interrupt(void)
+{
+	u32 temp;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+
+	/* write into the PM_ICS register */
+	writel(temp, &mid_pmu_cxt->pmu_reg->pm_ics);
+}
+
+static inline int pmu_read_interrupt_status(void)
+{
+	u32 temp;
+	union pmu_pm_ics result;
+
+	/* read the pm interrupt status register */
+	temp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+
+	result.pmu_pm_ics_value = temp;
+
+	if (result.pmu_pm_ics_parts.int_status == 0)
+		return PMU_FAILED;
+
+	/* return the pm interrupt status int pending bit info */
+	return result.pmu_pm_ics_parts.int_status;
+}
+
+/*This function is used for programming the wake capable devices*/
+static void pmu_prepare_wake(int s0ix_state)
+{
+
+	struct pmu_ss_states cur_pmsss;
+
+	/* setup the wake capable devices */
+	if (s0ix_state == MID_S3_STATE) {
+		writel(~IGNORE_S3_WKC0, &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+		writel(~IGNORE_S3_WKC1, &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+	}
+
+	if (platform_is(INTEL_ATOM_MFLD) || platform_is(INTEL_ATOM_CLV)) {
+
+		/* Re-program the sub systems state on wakeup as
+		 * the current SSS
+		 */
+		pmu_read_sss(&cur_pmsss);
+
+		writel(cur_pmsss.pmu2_states[0],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[0]);
+		writel(cur_pmsss.pmu2_states[1],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[1]);
+		writel(cur_pmsss.pmu2_states[2],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[2]);
+		writel(cur_pmsss.pmu2_states[3],
+				&mid_pmu_cxt->pmu_reg->pm_wssc[3]);
+	}
+}
+
+int mid_s0ix_enter(int s0ix_state)
+{
+	int ret = 0;
+
+	if (unlikely(!pmu_ops || !pmu_ops->enter))
+		goto ret;
+
+	/* check if we can acquire scu_ready_sem
+	 * if we are not able to then do a c6 */
+	if (down_trylock(&mid_pmu_cxt->scu_ready_sem))
+		goto ret;
+
+	/* If PMU is busy, we'll retry on next C6 */
+	if (unlikely(_pmu_read_status(PMU_BUSY_STATUS))) {
+		up(&mid_pmu_cxt->scu_ready_sem);
+		pr_debug("mid_pmu_cxt->scu_read_sem is up\n");
+		goto ret;
+	}
+
+	pmu_prepare_wake(s0ix_state);
+
+	/* no need to proceed if schedule pending */
+	if (unlikely(need_resched())) {
+		pmu_stat_clear();
+		up(&mid_pmu_cxt->scu_ready_sem);
+		goto ret;
+	}
+
+	/* entry function for pmu driver ops */
+	if (pmu_ops->enter(s0ix_state))
+		ret = s0ix_state;
+
+ret:
+	return ret;
+}
+
+/**
+ * pmu_sc_irq - pmu driver interrupt handler
+ * Context: interrupt context
+ */
+static irqreturn_t pmu_sc_irq(int irq, void *ignored)
+{
+	int status;
+	irqreturn_t ret = IRQ_NONE;
+	int wake_source;
+
+	/* check if interrup pending bit is set, if not ignore interrupt */
+	if (unlikely(!pmu_interrupt_pending())) {
+		goto ret_no_clear;
+	}
+
+	/* read the interrupt status */
+	status = pmu_read_interrupt_status();
+	if (unlikely(status == PMU_FAILED))
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "Invalid interrupt source\n");
+
+	switch (status) {
+	case INVALID_INT:
+		goto ret_no_clear;
+
+	case CMD_COMPLETE_INT:
+		break;
+
+	case CMD_ERROR_INT:
+		mid_pmu_cxt->cmd_error_int++;
+		break;
+
+	case SUBSYS_POW_ERR_INT:
+	case NO_ACKC6_INT:
+	case S0ix_MISS_INT:
+		pmu_stat_error(status);
+		break;
+
+	case WAKE_RECEIVED_INT:
+		wake_source = pmu_get_wake_source();
+		trace_printk("wake_from_lss%d\n",
+				wake_source);
+		pmu_stat_end();
+		break;
+	case TRIGGERERR:
+		pmu_dump_logs();
+		BUG();
+		break;
+	}
+
+	pmu_stat_clear();
+
+	/* clear the interrupt pending bit */
+	pmu_clear_pending_interrupt();
+
+	if (pmu_ops->wakeup)
+		pmu_ops->wakeup();
+
+	if (platform_is(INTEL_ATOM_MFLD) ||
+				platform_is(INTEL_ATOM_CLV)) {
+		mid_pmu_cxt->s0ix_entered = 0;
+		/* S0ix case release it */
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+
+	ret = IRQ_HANDLED;
+ret_no_clear:
+	return ret;
+}
+
+void pmu_set_s0ix_complete(void)
+{
+	if (pmu_ops->set_s0ix_complete)
+		pmu_ops->set_s0ix_complete();
+}
+EXPORT_SYMBOL(pmu_set_s0ix_complete);
+
+bool pmu_is_s0ix_in_progress(void)
+{
+	bool state = false;
+
+	if (pmu_initialized && mid_pmu_cxt->s0ix_entered)
+		state = true;
+
+	return state;
+}
+EXPORT_SYMBOL(pmu_is_s0ix_in_progress);
+
+static inline u32 find_index_in_hash(struct pci_dev *pdev, int *found)
+{
+	u32 h_index;
+	int i;
+
+	/* assuming pdev is not null */
+	WARN_ON(pdev == NULL);
+
+	/*assuming pdev pionter will not change from platfrom
+	 *boot to shutdown*/
+	h_index = jhash_1word((u32) (long) pdev,
+		 MID_PCI_INDEX_HASH_INITVALUE) & MID_PCI_INDEX_HASH_MASK;
+
+	/* assume not found */
+	*found = 0;
+
+	for (i = 0; i < MID_PCI_INDEX_HASH_SIZE; i++) {
+		if (likely(mid_pmu_cxt->pci_dev_hash[h_index].pdev == pdev)) {
+			*found = 1;
+			break;
+		}
+
+		/* assume no deletions, hence there shouldn't be any
+		 * gaps ie., NULL's */
+		if (unlikely(mid_pmu_cxt->pci_dev_hash[h_index].pdev == NULL)) {
+			/* found NULL, that means we wont have
+			 * it in hash */
+			break;
+		}
+
+		h_index = (h_index+1)%MID_PCI_INDEX_HASH_SIZE;
+	}
+
+	/* Assume hash table wont be full */
+	WARN_ON(i == MID_PCI_INDEX_HASH_SIZE);
+
+	return h_index;
+}
+
+static int get_pci_to_pmu_index(struct pci_dev *pdev)
+{
+	int pm, type;
+	unsigned int base_class;
+	unsigned int sub_class;
+	u8 ss;
+	int index = PMU_FAILED;
+	u32 h_index;
+	int found;
+
+	h_index = find_index_in_hash(pdev, &found);
+
+	if (found)
+		return (int)mid_pmu_cxt->pci_dev_hash[h_index].index;
+
+	/* if not found, h_index would be where
+	 * we can insert this */
+
+	base_class = pdev->class >> 16;
+	sub_class  = (pdev->class & SUB_CLASS_MASK) >> 8;
+	pm = pci_find_capability(pdev, PCI_CAP_ID_VNDR);
+
+	/* read the logical sub system id & cap if present */
+	pci_read_config_byte(pdev, pm + 4, &ss);
+
+	type = ss & LOG_SS_MASK;
+	ss = ss & LOG_ID_MASK;
+
+	if ((base_class == PCI_BASE_CLASS_DISPLAY) && !sub_class)
+		index = 1;
+	else if ((base_class == PCI_BASE_CLASS_MULTIMEDIA) &&
+			(sub_class == ISP_SUB_CLASS))
+				index = ISP_POS;
+	else if (type) {
+		WARN_ON(ss >= MAX_LSS_POSSIBLE);
+		index = mid_pmu_cxt->pmu1_max_devs + ss;
+	}
+
+	if (index != PMU_FAILED) {
+		/* insert into hash table */
+		mid_pmu_cxt->pci_dev_hash[h_index].pdev = pdev;
+
+		/* assume index never exceeds 0xff */
+		WARN_ON(index > 0xFF);
+
+		mid_pmu_cxt->pci_dev_hash[h_index].index = (u8)index;
+
+		if (index < mid_pmu_cxt->pmu1_max_devs) {
+			set_mid_pci_ss_idx(index, 0);
+			set_mid_pci_ss_pos(index, (u8)index);
+			set_mid_pci_pmu_num(index, PMU_NUM_1);
+		} else if (index >= mid_pmu_cxt->pmu1_max_devs &&
+			   index < (mid_pmu_cxt->pmu1_max_devs +
+						mid_pmu_cxt->pmu2_max_devs)) {
+			set_mid_pci_ss_idx(index,
+					(u8)(ss / mid_pmu_cxt->ss_per_reg));
+			set_mid_pci_ss_pos(index,
+					(u8)(ss % mid_pmu_cxt->ss_per_reg));
+			set_mid_pci_pmu_num(index, PMU_NUM_2);
+		} else {
+			index = PMU_FAILED;
+		}
+
+		WARN_ON(index == PMU_FAILED);
+	}
+
+	return index;
+}
+
+static void get_pci_lss_info(struct pci_dev *pdev)
+{
+	int index, pm;
+	unsigned int base_class;
+	unsigned int sub_class;
+	u8 ss, cap;
+	int i;
+	base_class = pdev->class >> 16;
+	sub_class  = (pdev->class & SUB_CLASS_MASK) >> 8;
+
+	pm = pci_find_capability(pdev, PCI_CAP_ID_VNDR);
+
+	/* read the logical sub system id & cap if present */
+	pci_read_config_byte(pdev, pm + 4, &ss);
+	pci_read_config_byte(pdev, pm + 5, &cap);
+
+	/* get the index for the copying of ss info */
+	index = get_pci_to_pmu_index(pdev);
+
+	if ((index == PMU_FAILED) || (index >= MAX_DEVICES))
+		return;
+
+	/* initialize gfx subsystem info */
+	if ((base_class == PCI_BASE_CLASS_DISPLAY) && !sub_class) {
+		set_mid_pci_log_id(index, (u32)index);
+		set_mid_pci_cap(index, PM_SUPPORT);
+	} else if ((base_class == PCI_BASE_CLASS_MULTIMEDIA) &&
+		(sub_class == ISP_SUB_CLASS)) {
+			set_mid_pci_log_id(index, (u32)index);
+			set_mid_pci_cap(index, PM_SUPPORT);
+	} else if (ss && cap) {
+		set_mid_pci_log_id(index, (u32)(ss & LOG_ID_MASK));
+		set_mid_pci_cap(index, cap);
+	}
+
+	for (i = 0; i < PMU_MAX_LSS_SHARE &&
+		get_mid_pci_drv(index, i); i++) {
+		/* do nothing */
+	}
+
+	WARN_ON(i >= PMU_MAX_LSS_SHARE);
+
+	if (i < PMU_MAX_LSS_SHARE) {
+		set_mid_pci_drv(index, i, pdev);
+		set_mid_pci_power_state(index, i, PCI_D3hot);
+	}
+}
+
+static void pmu_enumerate(void)
+{
+	struct pci_dev *pdev = NULL;
+	unsigned int base_class;
+
+	while ((pdev = pci_get_device(PCI_ID_ANY, PCI_ID_ANY, pdev)) != NULL) {
+		if (platform_is(INTEL_ATOM_MRFLD) &&
+			pdev->device == MID_MRFL_HDMI_DRV_DEV_ID)
+			continue;
+
+		/* find the base class info */
+		base_class = pdev->class >> 16;
+
+		if (base_class == PCI_BASE_CLASS_BRIDGE)
+			continue;
+
+		get_pci_lss_info(pdev);
+	}
+}
+
+void pmu_read_sss(struct pmu_ss_states *pm_ssc)
+{
+	pm_ssc->pmu2_states[0] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[0]);
+	pm_ssc->pmu2_states[1] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[1]);
+	pm_ssc->pmu2_states[2] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[2]);
+	pm_ssc->pmu2_states[3] =
+			readl(&mid_pmu_cxt->pmu_reg->pm_sss[3]);
+}
+
+
+/*
+ * For all devices in this lss, we check what is the weakest power state
+ *
+ * Thus we dont power down if another device needs more power
+ */
+
+static pci_power_t  pmu_pci_get_weakest_state_for_lss(int lss_index,
+				struct pci_dev *pdev, pci_power_t state)
+{
+	int i;
+	pci_power_t weakest = state;
+
+	for (i = 0; i < PMU_MAX_LSS_SHARE; i++) {
+		if (get_mid_pci_drv(lss_index, i) == pdev)
+			set_mid_pci_power_state(lss_index, i, state);
+
+		if (get_mid_pci_drv(lss_index, i) &&
+			(get_mid_pci_power_state(lss_index, i) < weakest))
+			weakest = get_mid_pci_power_state(lss_index, i);
+	}
+	return weakest;
+}
+
+int pmu_pci_to_indexes(struct pci_dev *pdev, int *index,
+				int *pmu_num, int *ss_idx, int *ss_pos)
+{
+	int i;
+
+	i = get_pci_to_pmu_index(pdev);
+	if (i == PMU_FAILED)
+		return PMU_FAILED;
+
+	*index		= i;
+	*ss_pos		= get_mid_pci_ss_pos(i);
+	*ss_idx		= get_mid_pci_ss_idx(i);
+	*pmu_num	= get_mid_pci_pmu_num(i);
+
+	return PMU_SUCCESS;
+}
+
+static bool update_nc_device_states(int i, pci_power_t state)
+{
+	int status = 0;
+	int islands = 0;
+	int reg;
+
+	/* store the display status */
+	if (i == GFX_LSS_INDEX) {
+		mid_pmu_cxt->display_off = (state != PCI_D0);
+		return true;
+	}
+
+	/*Update the Camera status per ISP Driver Suspended/Resumed
+	* ISP power islands are also updated accordingly, otherwise Dx state
+	* in PMCSR refuses to change.
+	*/
+	else if (i == ISP_POS) {
+		if (platform_is(INTEL_ATOM_MFLD) ||
+				 platform_is(INTEL_ATOM_CLV)) {
+			islands = APM_ISP_ISLAND | APM_IPH_ISLAND;
+			reg = APM_REG_TYPE;
+		} else if (platform_is(INTEL_ATOM_MRFLD)) {
+			islands = TNG_ISP_ISLAND;
+			reg = ISP_SS_PM0;
+		} else
+			return false;
+		status = pmu_nc_set_power_state(islands,
+			(state != PCI_D0) ?
+			OSPM_ISLAND_DOWN : OSPM_ISLAND_UP,
+			reg);
+		if (status)
+			return false;
+		mid_pmu_cxt->camera_off = (state != PCI_D0);
+		return true;
+	}
+
+	return false;
+}
+
+void init_nc_device_states(void)
+{
+#if !IS_ENABLED(CONFIG_VIDEO_ATOMISP)
+	mid_pmu_cxt->camera_off = false;
+#endif
+
+#ifndef GFX_ENABLE
+	/* If Gfx is disabled
+	 * assume s0ix is not blocked
+	 * from gfx side
+	 */
+	mid_pmu_cxt->display_off = true;
+#endif
+
+	return;
+}
+
+/* FIXME::Currently HSI Modem 7060 (BZ# 28529) is having a issue and
+* it will not go to Low Power State on CVT. So Standby will not work
+* if HSI is enabled.
+* We can choose between Standby/HSI based on enable_stadby 1/0.
+*/
+unsigned int enable_standby __read_mostly;
+module_param(enable_standby, uint, 0000);
+
+/* FIXME:: We have issues with S0ix/S3 enabling by default
+ * with display lockup, HSIC etc., so have a boot time option
+ * to enable S0ix/S3
+ */
+unsigned int enable_s3 __read_mostly = 1;
+int set_enable_s3(const char *val, struct kernel_param *kp)
+{
+	int rv = param_set_int(val, kp);
+	if (rv)
+		return rv;
+
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		if (!enable_s3)
+			__pm_stay_awake(mid_pmu_cxt->pmu_wake_lock);
+		else
+			__pm_relax(mid_pmu_cxt->pmu_wake_lock);
+	}
+
+	return 0;
+}
+module_param_call(enable_s3, set_enable_s3, param_get_uint,
+				&enable_s3, S_IRUGO | S_IWUSR);
+
+/* FIXME:: We have issues with S0ix/S3 enabling by default
+ * with display lockup, HSIC etc., so have a boot time option
+ * to enable S0ix/S3
+ */
+unsigned int enable_s0ix __read_mostly = 1;
+int set_enable_s0ix(const char *val, struct kernel_param *kp)
+{
+	int rv = param_set_int(val, kp);
+	if (rv)
+		return rv;
+
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	if (platform_is(INTEL_ATOM_MRFLD)) {
+		if (!enable_s0ix) {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+
+			/* Ignore C2, C3, C4, C5 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 3);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+			/* For now ignore C7, C8, C9, C10 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 6);
+			mid_pmu_cxt->cstate_ignore |= (1 << 7);
+			mid_pmu_cxt->cstate_ignore |= (1 << 8);
+			mid_pmu_cxt->cstate_ignore |= (1 << 9);
+
+			/* Restrict platform Cx state to C6 */
+			pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+						(CSTATE_EXIT_LATENCY_S0i1-1));
+		} else {
+			mid_pmu_cxt->cstate_ignore =
+				~((1 << CPUIDLE_STATE_MAX) - 1);
+
+			/* Ignore C2, C3, C4, C5 states */
+			mid_pmu_cxt->cstate_ignore |= (1 << 1);
+			mid_pmu_cxt->cstate_ignore |= (1 << 2);
+			mid_pmu_cxt->cstate_ignore |= (1 << 3);
+			mid_pmu_cxt->cstate_ignore |= (1 << 4);
+
+			pm_qos_update_request(mid_pmu_cxt->cstate_qos,
+							PM_QOS_DEFAULT_VALUE);
+		}
+	}
+
+	return 0;
+}
+module_param_call(enable_s0ix, set_enable_s0ix, param_get_uint,
+				&enable_s0ix, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss0 __read_mostly = IGNORE_SSS0;
+module_param(pmu_ignore_lss0, uint, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss1 __read_mostly = IGNORE_SSS1;
+module_param(pmu_ignore_lss1, uint, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss2 __read_mostly = IGNORE_SSS2;
+module_param(pmu_ignore_lss2, uint, S_IRUGO | S_IWUSR);
+
+unsigned int pmu_ignore_lss3 __read_mostly = IGNORE_SSS3;
+module_param(pmu_ignore_lss3, uint, S_IRUGO | S_IWUSR);
+
+int pmu_set_emmc_to_d0i0_atomic(void)
+{
+	u32 pm_cmd_val;
+	u32 new_value;
+	int sub_sys_pos, sub_sys_index;
+	struct pmu_ss_states cur_pmssc;
+	int status = 0;
+
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	/* LSS 01 is index = 0, pos = 1 */
+	sub_sys_index	= EMMC0_LSS / mid_pmu_cxt->ss_per_reg;
+	sub_sys_pos	= EMMC0_LSS % mid_pmu_cxt->ss_per_reg;
+
+	memset(&cur_pmssc, 0, sizeof(cur_pmssc));
+
+	/*
+	 * Give time for possible previous PMU operation to finish in
+	 * case where SCU is functioning normally. For SCU crashed case
+	 * PMU may stay busy but check if the emmc is accessible.
+	 */
+	status = _pmu2_wait_not_busy();
+	if (status) {
+		dev_err(&mid_pmu_cxt->pmu_dev->dev,
+			"PMU2 busy, ignoring as emmc might be already d0i0\n");
+		status = 0;
+	}
+
+	pmu_read_sss(&cur_pmssc);
+
+	/* set D0i0 the LSS bits */
+	pm_cmd_val =
+		(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+	new_value = cur_pmssc.pmu2_states[sub_sys_index] &
+						(~pm_cmd_val);
+	if (new_value == cur_pmssc.pmu2_states[sub_sys_index])
+		goto err;
+
+	status = _pmu2_wait_not_busy();
+	if (status)
+		goto err;
+
+	cur_pmssc.pmu2_states[sub_sys_index] = new_value;
+
+	/* Request SCU for PM interrupt enabling */
+	writel(PMU_PANIC_EMMC_UP_REQ_CMD, mid_pmu_cxt->emergeny_emmc_up_addr);
+
+	status = pmu_issue_interactive_command(&cur_pmssc, false, false);
+
+	if (unlikely(status != PMU_SUCCESS)) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+			 "Failed to Issue a PM command to PMU2\n");
+		goto err;
+
+	}
+
+	/*
+	 * Wait for interactive command to complete.
+	 * If we dont wait, there is a possibility that
+	 * the driver may access the device before its
+	 * powered on in SCU.
+	 *
+	 */
+	if (_pmu2_wait_not_busy()) {
+		pmu_dump_logs();
+		BUG();
+	}
+
+err:
+
+	return status;
+}
+
+
+#define SAVED_HISTORY_ADDRESS_NUM	10
+#define SAVED_HISTORY_NUM		20
+#define PCI_MAX_RECORD_NUM		10
+
+struct saved_nc_power_history {
+	unsigned long long ts;
+	unsigned short pci;
+	unsigned short cpu:4;
+	unsigned short state_type:8;
+	unsigned short real_change:2;
+	int reg_type;
+	int islands;
+	void *address[SAVED_HISTORY_ADDRESS_NUM];
+};
+
+static atomic_t saved_nc_power_history_current = ATOMIC_INIT(-1);
+static struct saved_nc_power_history all_history[SAVED_HISTORY_NUM];
+static struct saved_nc_power_history *get_new_record_history(void)
+{
+	unsigned int ret =
+		atomic_add_return(1, &saved_nc_power_history_current);
+	return &all_history[ret%SAVED_HISTORY_NUM];
+}
+
+static unsigned short pci_need_record[PCI_MAX_RECORD_NUM] = { 0x08c8, 0x0130, };
+static int num_pci_need_record = 2;
+module_param_array(pci_need_record, ushort, &num_pci_need_record, 0644);
+MODULE_PARM_DESC(pci_need_record,
+		"devices need be traced power state transition.");
+
+static bool pci_need_record_power_state(struct pci_dev *pdev)
+{
+	int i;
+	for (i = 0; i < num_pci_need_record; i++)
+		if (pdev->device == pci_need_record[i])
+			return true;
+
+	return false;
+}
+
+static void print_saved_record(struct saved_nc_power_history *record)
+{
+	int i;
+	unsigned long long ts = record->ts;
+	unsigned long nanosec_rem = do_div(ts, 1000000000);
+
+	printk(KERN_INFO "----\n");
+	printk(KERN_INFO "ts[%5lu.%06lu] cpu[%d] is pci[%04x] reg_type[%d] "
+			"state_type[%d] islands[%x] real_change[%d]\n",
+		(unsigned long)ts,
+		nanosec_rem / 1000,
+		record->cpu,
+		record->pci,
+		record->reg_type,
+		record->state_type,
+		record->islands,
+		record->real_change);
+	for (i = 0; i < SAVED_HISTORY_ADDRESS_NUM; i++) {
+		printk(KERN_INFO "%pf real_addr[%p]\n",
+			record->address[i],
+			record->address[i]);
+	}
+}
+
+int verify_stack_ok(unsigned int *good_ebp, unsigned int *_ebp)
+{
+	return ((unsigned int)_ebp & 0xffffe000) ==
+		((unsigned int)good_ebp & 0xffffe000);
+}
+
+size_t backtrace_safe(void **array, size_t max_size)
+{
+	unsigned int *_ebp, *base_ebp;
+	unsigned int *caller;
+	unsigned int i;
+
+	asm ("movl %%ebp, %0"
+		: "=r" (_ebp)
+	    );
+
+	base_ebp = _ebp;
+	caller = (unsigned int *) *(_ebp+1);
+
+	for (i = 0; i < max_size; i++)
+		array[i] = 0;
+	for (i = 0; i < max_size; i++) {
+		array[i] = caller;
+		_ebp = (unsigned int *) *_ebp;
+		if (!verify_stack_ok(base_ebp, _ebp))
+			break;
+		caller = (unsigned int *) *(_ebp+1);
+	}
+
+	return i + 1;
+}
+
+void dump_nc_power_history(void)
+{
+	int i, start;
+	unsigned int total = atomic_read(&saved_nc_power_history_current);
+
+	start = total % SAVED_HISTORY_NUM;
+	printk(KERN_INFO "<----current timestamp\n");
+	printk(KERN_INFO "start[%d] saved[%d]\n",
+			start, total);
+	for (i = start; i >= 0; i--)
+		print_saved_record(&all_history[i]);
+	for (i = SAVED_HISTORY_NUM - 1; i > start; i--)
+		print_saved_record(&all_history[i]);
+}
+EXPORT_SYMBOL(dump_nc_power_history);
+
+static int debug_read_history(char *page, char **start, off_t off,
+		int count, int *eof, void *data)
+{
+	unsigned long len = 0;
+	page[len] = 0;
+
+	dump_nc_power_history();
+	return len;
+}
+
+static int debug_write_read_history_entry(struct file *file,
+		const char __user *buffer, unsigned long count, void *data)
+{
+	char buf[20] = "0";
+	unsigned long len = min((unsigned long)sizeof(buf) - 1, count);
+	u32 islands;
+	u32 on;
+	int ret;
+
+	/*do nothing if platform is nether medfield or clv*/
+	if (!platform_is(INTEL_ATOM_MFLD) && !platform_is(INTEL_ATOM_CLV))
+		return count;
+
+	if (copy_from_user(buf, buffer, len))
+		return -1;
+
+	buf[len] = 0;
+
+	ret = sscanf(buf, "%x%x", &islands, &on);
+	if (ret == 2)
+		pmu_nc_set_power_state(islands, on, OSPM_REG_TYPE);
+
+	return count;
+}
+
+static int __init debug_read_history_entry(void)
+{
+	struct proc_dir_entry *res = NULL;
+	res = create_proc_entry("debug_read_history", S_IRUGO | S_IWUSR, NULL);
+	if (res) {
+		res->write_proc = debug_write_read_history_entry;
+		res->read_proc = debug_read_history;
+	}
+	return 0;
+}
+device_initcall(debug_read_history_entry);
+
+/**
+ * pmu_nc_set_power_state - Callback function is used by all the devices
+ * in north complex for a platform  specific device power on/shutdown.
+ * Following assumptions are made by this function
+ *
+ * Every new request starts from scratch with no assumptions
+ * on previous/pending request to Punit.
+ * Caller is responsible to retry if request fails.
+ * Avoids multiple requests to Punit if target state is
+ * already in the expected state.
+ * spin_locks guarantee serialized access to these registers
+ * and avoid concurrent access from 2d/3d, VED, VEC, ISP & IPH.
+ *
+ */
+int pmu_nc_set_power_state(int islands, int state_type, int reg)
+{
+	unsigned long flags;
+	struct saved_nc_power_history *record = NULL;
+	int ret = 0;
+	int change;
+
+	spin_lock_irqsave(&mid_pmu_cxt->nc_ready_lock, flags);
+
+	record = get_new_record_history();
+	record->cpu = raw_smp_processor_id();
+	record->ts = cpu_clock(record->cpu);
+	record->islands = islands;
+	record->pci = 0;
+	record->state_type = state_type;
+	backtrace_safe(record->address, SAVED_HISTORY_ADDRESS_NUM);
+	record->real_change = 0;
+	record->reg_type = reg;
+
+	if (pmu_ops->nc_set_power_state)	{
+		ret = pmu_ops->nc_set_power_state(islands, state_type,
+								reg, &change);
+		if (change) {
+			record->real_change = 1;
+			record->ts = cpu_clock(record->cpu);
+		}
+	}
+
+	spin_unlock_irqrestore(&mid_pmu_cxt->nc_ready_lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL(pmu_nc_set_power_state);
+
+/**
+ * pmu_nc_get_power_state - Callback function is used to
+ * query power status of all the devices in north complex.
+ * Following assumptions are made by this function
+ *
+ * Every new request starts from scratch with no assumptions
+ * on previous/pending request to Punit.
+ * Caller is responsible to retry if request fails.
+ * Avoids multiple requests to Punit if target state is
+ * already in the expected state.
+ * spin_locks guarantee serialized access to these registers
+ * and avoid concurrent access from 2d/3d, VED, VEC, ISP & IPH.
+ *
+ */
+int pmu_nc_get_power_state(int island, int reg_type)
+{
+	u32 pwr_sts;
+	unsigned long flags;
+	int i, lss;
+	int ret = -EINVAL;
+
+	/*do nothing if platform is nether medfield or clv*/
+	if (!platform_is(INTEL_ATOM_MFLD) && !platform_is(INTEL_ATOM_CLV))
+		return 0;
+
+	spin_lock_irqsave(&mid_pmu_cxt->nc_ready_lock, flags);
+
+	switch (reg_type) {
+	case APM_REG_TYPE:
+		pwr_sts = inl(mid_pmu_cxt->apm_base + APM_STS);
+		break;
+	case OSPM_REG_TYPE:
+		pwr_sts = inl(mid_pmu_cxt->ospm_base + OSPM_PM_SSS);
+		break;
+	default:
+		pr_err("%s: invalid argument 'island': %d.\n",
+				 __func__, island);
+		goto unlock;
+	}
+
+	for (i = 0; i < OSPM_MAX_POWER_ISLANDS; i++) {
+		lss = island & (0x1 << i);
+		if (lss) {
+			ret = (pwr_sts >> (2 * i)) & 0x3;
+			break;
+		}
+	}
+
+unlock:
+	spin_unlock_irqrestore(&mid_pmu_cxt->nc_ready_lock, flags);
+	return ret;
+}
+EXPORT_SYMBOL(pmu_nc_get_power_state);
+
+/*
+* update_dev_res - Calulates & Updates the device residency when
+* a device state change occurs.
+* Computation of respective device residency starts when
+* its first state tranisition happens after the pmu driver
+* is initialised.
+*
+*/
+void update_dev_res(int index, pci_power_t state)
+{
+	if (state != PCI_D0) {
+		if (mid_pmu_cxt->pmu_dev_res[index].start == 0) {
+			mid_pmu_cxt->pmu_dev_res[index].start = cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_entry =
+				mid_pmu_cxt->pmu_dev_res[index].start;
+				mid_pmu_cxt->pmu_dev_res[index].d0i0_acc = 0;
+		} else{
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_entry =
+							cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i0_acc +=
+			(mid_pmu_cxt->pmu_dev_res[index].d0i3_entry -
+				 mid_pmu_cxt->pmu_dev_res[index].d0i0_entry);
+		}
+	} else {
+		if (mid_pmu_cxt->pmu_dev_res[index].start == 0) {
+			mid_pmu_cxt->pmu_dev_res[index].start =
+						 cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i0_entry
+				= mid_pmu_cxt->pmu_dev_res[index].start;
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_acc = 0;
+		} else {
+			mid_pmu_cxt->pmu_dev_res[index].d0i0_entry =
+						 cpu_clock(0);
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_acc +=
+			(mid_pmu_cxt->pmu_dev_res[index].d0i0_entry -
+			mid_pmu_cxt->pmu_dev_res[index].d0i3_entry);
+		}
+	}
+	mid_pmu_cxt->pmu_dev_res[index].state = state;
+}
+
+/**
+ * pmu_pci_set_power_state - Callback function is used by all the PCI devices
+ *			for a platform  specific device power on/shutdown.
+ *
+ */
+int __ref pmu_pci_set_power_state(struct pci_dev *pdev, pci_power_t state)
+{
+	u32 new_value;
+	int i = 0;
+	u32 pm_cmd_val, chk_val;
+	int sub_sys_pos, sub_sys_index;
+	int pmu_num;
+	struct pmu_ss_states cur_pmssc;
+	int status = 0;
+	int retry_times = 0;
+	ktime_t calltime, delta, rettime;
+	struct saved_nc_power_history *record = NULL;
+	bool d3_cold = false;
+
+	/* Ignore callback from devices until we have initialized */
+	if (unlikely((!pmu_initialized)))
+		return 0;
+
+	might_sleep();
+
+	/* Try to acquire the scu_ready_sem, if not
+	 * get blocked, until pmu_sc_irq() releases */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	/*get LSS index corresponding to pdev, its position in
+	 *32 bit register and its register numer*/
+	status =
+		pmu_pci_to_indexes(pdev, &i, &pmu_num,
+				&sub_sys_index,  &sub_sys_pos);
+
+	if (status)
+		goto unlock;
+
+	if (pci_need_record_power_state(pdev)) {
+		record = get_new_record_history();
+		record->cpu = raw_smp_processor_id();
+		record->ts = cpu_clock(record->cpu);
+		record->islands = 0;
+		record->reg_type = 0;
+		record->pci = pdev->device;
+		record->state_type = state;
+		backtrace_safe(record->address, SAVED_HISTORY_ADDRESS_NUM);
+		record->real_change = 0;
+	}
+
+	/* Ignore HDMI HPD driver d0ix on LSS 0 on MRFLD */
+	if (platform_is(INTEL_ATOM_MRFLD) &&
+			pdev->device == MID_MRFL_HDMI_DRV_DEV_ID)
+			goto unlock;
+
+	/*in case a LSS is assigned to more than one pdev, we need
+	  *to find the shallowest state the LSS should be put into*/
+	state = pmu_pci_get_weakest_state_for_lss(i, pdev, state);
+
+	/*If the LSS corresponds to northcomplex device, update
+	  *the status and return*/
+	if (update_nc_device_states(i, state)) {
+		if (mid_pmu_cxt->pmu_dev_res[i].state == state)
+			goto nc_done;
+		else {
+			if (i < MAX_DEVICES)
+				update_dev_res(i, state);
+			goto nc_done;
+		}
+	}
+
+	/* initialize the current pmssc states */
+	memset(&cur_pmssc, 0, sizeof(cur_pmssc));
+
+	status = _pmu2_wait_not_busy();
+
+	if (status)
+		goto unlock;
+
+	pmu_read_sss(&cur_pmssc);
+
+	/* Read the pm_cmd val & update the value */
+	pm_cmd_val =
+		(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+	/* First clear the LSS bits */
+	new_value = cur_pmssc.pmu2_states[sub_sys_index] &
+						(~pm_cmd_val);
+	mid_pmu_cxt->os_sss[sub_sys_index] &= ~pm_cmd_val;
+
+	if (state != PCI_D0) {
+		pm_cmd_val =
+			(pci_to_platform_state(state) <<
+				(sub_sys_pos * BITS_PER_LSS));
+
+		new_value |= pm_cmd_val;
+
+		mid_pmu_cxt->os_sss[sub_sys_index] |= pm_cmd_val;
+	}
+
+	new_value &= ~mid_pmu_cxt->ignore_lss[sub_sys_index];
+
+	/* nothing to do, so dont do it... */
+	if (new_value == cur_pmssc.pmu2_states[sub_sys_index])
+		goto unlock;
+
+	cur_pmssc.pmu2_states[sub_sys_index] = new_value;
+
+	/* Check if the state is D3_cold or D3_Hot in TNG platform*/
+	if (platform_is(INTEL_ATOM_MRFLD) && (state == PCI_D3cold))
+		d3_cold = true;
+
+	/* Issue the pmu command to PMU 2
+	 * flag is needed to distinguish between
+	 * S0ix vs interactive command in pmu_sc_irq()
+	 */
+	status = pmu_issue_interactive_command(&cur_pmssc, false, d3_cold);
+
+	if (unlikely(status != PMU_SUCCESS)) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+			 "Failed to Issue a PM command to PMU2\n");
+		goto unlock;
+	}
+
+	calltime = ktime_get();
+retry:
+	/*
+	 * Wait for interactive command to complete.
+	 * If we dont wait, there is a possibility that
+	 * the driver may access the device before its
+	 * powered on in SCU.
+	 *
+	 */
+	status = _pmu2_wait_not_busy_yield();
+	if (unlikely(status)) {
+		rettime = ktime_get();
+		delta = ktime_sub(rettime, calltime);
+		retry_times++;
+
+		printk(KERN_CRIT "%s: D0ix transition failure: %04x %04X %s %20s:\n",
+				__func__,
+				pdev->vendor, pdev->device,
+				dev_name(&pdev->dev),
+				dev_driver_string(&pdev->dev));
+		printk(KERN_CRIT "interrupt pending = %d\n",
+				pmu_interrupt_pending());
+		printk(KERN_CRIT "pmu_busy_status = %d\n",
+				_pmu_read_status(PMU_BUSY_STATUS));
+		printk(KERN_CRIT "suspend_started = %d\n",
+				mid_pmu_cxt->suspend_started);
+		printk(KERN_CRIT "shutdown_started = %d\n",
+				mid_pmu_cxt->shutdown_started);
+		printk(KERN_CRIT "camera_off = %d display_off = %d\n",
+				mid_pmu_cxt->camera_off,
+				mid_pmu_cxt->display_off);
+		printk(KERN_CRIT "s0ix_possible = 0x%x\n",
+				mid_pmu_cxt->s0ix_possible);
+		printk(KERN_CRIT "s0ix_entered = 0x%x\n",
+				mid_pmu_cxt->s0ix_entered);
+		printk(KERN_CRIT "pmu_current_state = %d\n",
+				mid_pmu_cxt->pmu_current_state);
+		printk(KERN_CRIT "PMU is BUSY! retry_times[%d] total_delay[%lli]ms. Retry ...\n",
+				retry_times, (long long) ktime_to_ms(delta));
+		pmu_dump_logs();
+
+		trigger_all_cpu_backtrace();
+		if (retry_times < 60)
+			goto retry;
+		else
+			BUG();
+	}
+	if (record) {
+		record->real_change = 1;
+		record->ts = cpu_clock(record->cpu);
+	}
+
+	if (pmu_ops->set_power_state_ops)
+		pmu_ops->set_power_state_ops(state);
+
+	/* update stats */
+	inc_d0ix_stat((i-mid_pmu_cxt->pmu1_max_devs),
+				pci_to_platform_state(state));
+
+	/* check if tranisition to requested state has happened */
+	pmu_read_sss(&cur_pmssc);
+
+	chk_val = cur_pmssc.pmu2_states[sub_sys_index] &
+		(D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+	new_value &= (D0I3_MASK << (sub_sys_pos * BITS_PER_LSS));
+
+	if ((chk_val == new_value) && (i < MAX_DEVICES))
+		update_dev_res(i, state);
+
+	WARN_ON(chk_val != new_value);
+
+nc_done:
+#if !IS_ENABLED(CONFIG_VIDEO_ATOMISP)
+	/* ATOMISP is always powered up on system-resume path. It needs
+	 * to be turned off here if there is no driver to do it. */
+	if (!mid_pmu_cxt->camera_off) {
+		/* power down isp */
+		pmu_nc_set_power_state(APM_ISP_ISLAND | APM_IPH_ISLAND,
+				       OSPM_ISLAND_DOWN, APM_REG_TYPE);
+		/* power down DPHY */
+		new_value = intel_mid_msgbus_read32(0x09, 0x03);
+		new_value |= 0x300;
+		intel_mid_msgbus_write32(0x09, 0x03, new_value);
+		mid_pmu_cxt->camera_off = true;
+	}
+#endif
+
+unlock:
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return status;
+}
+
+pci_power_t platfrom_pmu_choose_state(int lss)
+{
+	pci_power_t state = PCI_D3hot;
+
+	if (pmu_ops->pci_choose_state)
+		state = pmu_ops->pci_choose_state(lss);
+
+	return state;
+}
+
+/* return platform specific deepest states that the device can enter */
+pci_power_t pmu_pci_choose_state(struct pci_dev *pdev)
+{
+	int i;
+	int sub_sys_pos, sub_sys_index;
+	int status;
+	int device_lss;
+	int pmu_num;
+
+	pci_power_t state = PCI_D3hot;
+
+	if (pmu_initialized) {
+		status =
+		pmu_pci_to_indexes(pdev, &i, &pmu_num,
+					&sub_sys_index,  &sub_sys_pos);
+
+		if ((status == PMU_SUCCESS) &&
+			(pmu_num == PMU_NUM_2)) {
+
+			device_lss =
+				(sub_sys_index * mid_pmu_cxt->ss_per_reg) +
+								sub_sys_pos;
+
+			state = platfrom_pmu_choose_state(device_lss);
+		}
+	}
+
+	return state;
+}
+
+int pmu_issue_interactive_command(struct pmu_ss_states *pm_ssc, bool ioc,
+					bool d3_cold)
+{
+	u32 tmp;
+	u32 command;
+
+	if (_pmu2_wait_not_busy()) {
+		dev_err(&mid_pmu_cxt->pmu_dev->dev,
+			"SCU BUSY. Operation not permitted\n");
+		return PMU_FAILED;
+	}
+
+	/* enable interrupts in PMU2 so that interrupts are
+	 * propagated when ioc bit for a particular set
+	 * command is set
+	 */
+	/* Enable the hardware interrupt */
+	tmp = readl(&mid_pmu_cxt->pmu_reg->pm_ics);
+	tmp |= 0x100;/* Enable interrupts */
+	writel(tmp, &mid_pmu_cxt->pmu_reg->pm_ics);
+
+	/* Configure the sub systems for pmu2 */
+	pmu_write_subsys_config(pm_ssc);
+
+	command = (ioc) ? INTERACTIVE_IOC_VALUE : INTERACTIVE_VALUE;
+
+	 /* Special handling for PCI_D3cold in Tangier */
+	if (d3_cold)
+		command |= PM_CMD_D3_COLD;
+
+	/* send interactive command to SCU */
+	writel(command, &mid_pmu_cxt->pmu_reg->pm_cmd);
+
+	pmu_log_command(command, pm_ssc);
+
+	return 0;
+}
+
+/* Reads the status of each driver and updates the LSS values.
+ * To be called with scu_ready_sem mutex held, and pmu_config
+ * initialized with '0's
+ */
+static void update_all_lss_states(struct pmu_ss_states *pmu_config)
+{
+	int i;
+	u32 PCIALLDEV_CFG[4] = {0, 0, 0, 0};
+
+	if (platform_is(INTEL_ATOM_MFLD) || platform_is(INTEL_ATOM_CLV)) {
+		for (i = 0; i < MAX_DEVICES; i++) {
+			int pmu_num = get_mid_pci_pmu_num(i);
+			struct pci_dev *pdev = get_mid_pci_drv(i, 0);
+
+			if ((pmu_num == PMU_NUM_2) && pdev) {
+				int ss_idx, ss_pos;
+				pci_power_t state;
+
+				ss_idx = get_mid_pci_ss_idx(i);
+				ss_pos = get_mid_pci_ss_pos(i);
+				state = pdev->current_state;
+				/* The case of device not probed yet:
+				 * Force D0i3 */
+				if (state == PCI_UNKNOWN)
+					state = pmu_pci_choose_state(pdev);
+
+				/* By default its set to '0' hence
+				 * no need to update PCI_D0 state
+				 */
+				state = pmu_pci_get_weakest_state_for_lss
+							(i, pdev, state);
+
+				pmu_config->pmu2_states[ss_idx] |=
+				 (pci_to_platform_state(state) <<
+					(ss_pos * BITS_PER_LSS));
+
+				PCIALLDEV_CFG[ss_idx] |=
+					(D0I3_MASK << (ss_pos * BITS_PER_LSS));
+			}
+		}
+	}
+
+	platform_update_all_lss_states(pmu_config, PCIALLDEV_CFG);
+}
+
+static int pmu_init(void)
+{
+	int status;
+	struct pmu_ss_states pmu_config;
+	struct pmu_suspend_config *ss_config;
+	int ret = 0;
+	int retry_times = 0;
+
+
+	dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "PMU Driver loaded\n");
+	spin_lock_init(&mid_pmu_cxt->nc_ready_lock);
+
+	/* enumerate the PCI configuration space */
+	pmu_enumerate();
+
+	/* initialize the stats for pmu driver */
+	pmu_stats_init();
+
+	/* register platform pmu ops */
+	platform_set_pmu_ops();
+
+	/* platform specific initialization */
+	if (pmu_ops->init) {
+		status = pmu_ops->init();
+		if (status) {
+			dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				"pmu_ops->init failed\n");
+			goto out_err1;
+		}
+	}
+
+	/* initialize the state variables here */
+	ss_config = kzalloc(sizeof(struct pmu_suspend_config), GFP_KERNEL);
+
+	if (ss_config == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+			"Allocation of memory for ss_config has failed\n");
+		status = PMU_FAILED;
+		goto out_err1;
+	}
+
+	memset(&pmu_config, 0, sizeof(pmu_config));
+
+	ss_config->ss_state = pmu_config;
+
+	/* initialize for the autonomous S0i3 */
+	mid_pmu_cxt->ss_config = ss_config;
+
+	/* setup the wake capable devices */
+	mid_pmu_cxt->ss_config->wake_state.wake_enable[0] = WAKE_ENABLE_0;
+	mid_pmu_cxt->ss_config->wake_state.wake_enable[1] = WAKE_ENABLE_1;
+
+	/* setup the ignore lss list */
+	mid_pmu_cxt->ignore_lss[0] = pmu_ignore_lss0;
+	mid_pmu_cxt->ignore_lss[1] = pmu_ignore_lss1;
+	mid_pmu_cxt->ignore_lss[2] = pmu_ignore_lss2;
+	mid_pmu_cxt->ignore_lss[3] = pmu_ignore_lss3;
+
+	/*set wkc to appropriate value suitable for s0ix*/
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[0],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[1],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+
+	/* Acquire the scu_ready_sem */
+	down(&mid_pmu_cxt->scu_ready_sem);
+
+	/* Now we have initialized the driver
+	 * Allow drivers to get blocked in
+	 * pmu_pci_set_power_state(), until we finish
+	 * first interactive command.
+	 */
+
+	pmu_initialized = true;
+
+	/* get the current status of each of the driver
+	 * and update it in SCU
+	 */
+	update_all_lss_states(&pmu_config);
+
+	status = pmu_issue_interactive_command(&pmu_config, false,
+						false);
+	if (status != PMU_SUCCESS) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,\
+		 "Failure from pmu mode change to interactive."
+		" = %d\n", status);
+		status = PMU_FAILED;
+		up(&mid_pmu_cxt->scu_ready_sem);
+		goto out_err2;
+	}
+
+	/*
+	 * Wait for interactive command to complete.
+	 * If we dont wait, there is a possibility that
+	 * the driver may access the device before its
+	 * powered on in SCU.
+	 *
+	 */
+retry:
+	ret = _pmu2_wait_not_busy();
+	if (unlikely(ret)) {
+		retry_times++;
+		if (retry_times < 60) {
+			usleep_range(10, 500);
+			goto retry;
+		} else {
+			pmu_dump_logs();
+			BUG();
+		}
+	}
+
+	/* In cases were gfx is not enabled
+	 * this will enable s0ix immediately
+	 */
+	if (pmu_ops->set_power_state_ops)
+		pmu_ops->set_power_state_ops(PCI_D3hot);
+
+	up(&mid_pmu_cxt->scu_ready_sem);
+
+	return PMU_SUCCESS;
+
+out_err2:
+	kfree(ss_config);
+	mid_pmu_cxt->ss_config = NULL;
+out_err1:
+	return status;
+}
+
+/**
+ * mid_pmu_probe - This is the function where most of the PMU driver
+ *		   initialization happens.
+ */
+static int
+mid_pmu_probe(struct pci_dev *dev, const struct pci_device_id *pci_id)
+{
+	int ret;
+	struct mrst_pmu_reg __iomem *pmu;
+	u32 data;
+
+	mid_pmu_cxt->pmu_wake_lock =
+				wakeup_source_register("pmu_wake_lock");
+
+	if (!mid_pmu_cxt->pmu_wake_lock) {
+		pr_err("%s: unable to register pmu wake source.\n", __func__);
+		return -ENOMEM;
+	}
+
+	/* Init the device */
+	ret = pci_enable_device(dev);
+	if (ret) {
+		pr_err("Mid PM device cant be enabled\n");
+		goto out_err0;
+	}
+
+	/* store the dev */
+	mid_pmu_cxt->pmu_dev = dev;
+	dev_warn(&dev->dev, "PMU DRIVER Probe called\n");
+
+	ret = pci_request_regions(dev, PMU_DRV_NAME);
+	if (ret < 0) {
+		pr_err("pci request region has failed\n");
+		goto out_err1;
+	}
+
+	mid_pmu_cxt->pmu1_max_devs = PMU1_MAX_DEVS;
+	mid_pmu_cxt->pmu2_max_devs = PMU2_MAX_DEVS;
+	mid_pmu_cxt->ss_per_reg = 16;
+
+	/* Following code is used to map address required for NC PM
+	 * which is not needed for all platforms
+	 */
+	if (platform_is(INTEL_ATOM_MFLD) || platform_is(INTEL_ATOM_CLV)) {
+		data = intel_mid_msgbus_read32(OSPM_PUNIT_PORT, OSPM_APMBA);
+		mid_pmu_cxt->apm_base = data & 0xffff;
+
+		data = intel_mid_msgbus_read32(OSPM_PUNIT_PORT, OSPM_OSPMBA);
+		mid_pmu_cxt->ospm_base = data & 0xffff;
+	}
+
+	/* Map the memory of pmu1 PMU reg base */
+	pmu = pci_iomap(dev, 0, 0);
+	if (pmu == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				"Unable to map the PMU2 address space\n");
+		ret = PMU_FAILED;
+		goto out_err2;
+	}
+
+	mid_pmu_cxt->pmu_reg = pmu;
+
+	/* Map the memory of emergency emmc up */
+	mid_pmu_cxt->emergeny_emmc_up_addr =
+		ioremap_nocache(PMU_PANIC_EMMC_UP_ADDR, 4);
+	if (mid_pmu_cxt->emergeny_emmc_up_addr == NULL) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+		"Unable to map the emergency emmc up address space\n");
+		ret = PMU_FAILED;
+		goto out_err3;
+	}
+
+	if (request_irq(dev->irq, pmu_sc_irq, IRQF_NO_SUSPEND, PMU_DRV_NAME,
+			NULL)) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "Registering isr has failed\n");
+		ret = PMU_FAILED;
+		goto out_err4;
+	}
+
+	/* call pmu init() for initialization of pmu interface */
+	ret = pmu_init();
+	if (ret != PMU_SUCCESS) {
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "PMU initialization has failed\n");
+		goto out_err5;
+	}
+	dev_warn(&mid_pmu_cxt->pmu_dev->dev, "after pmu initialization\n");
+
+	mid_pmu_cxt->pmu_init_time =
+		cpu_clock(raw_smp_processor_id());
+
+#ifdef CONFIG_PM_DEBUG
+	/*
+	 * FIXME: Since S3 is not enabled yet we need to take
+	 * a wake lock here. Else S3 will be triggered on display
+	 * time out and platform will hang
+	 */
+	if (platform_is(INTEL_ATOM_MRFLD) && !enable_s3)
+		__pm_stay_awake(mid_pmu_cxt->pmu_wake_lock);
+#endif
+
+	return 0;
+
+out_err5:
+	free_irq(dev->irq, &pmu_sc_irq);
+out_err4:
+	iounmap(mid_pmu_cxt->emergeny_emmc_up_addr);
+	mid_pmu_cxt->emergeny_emmc_up_addr = NULL;
+out_err3:
+	iounmap(mid_pmu_cxt->pmu_reg);
+	mid_pmu_cxt->base_addr.pmu1_base = NULL;
+	mid_pmu_cxt->base_addr.pmu2_base = NULL;
+out_err2:
+	pci_release_region(dev, 0);
+out_err1:
+	pci_disable_device(dev);
+out_err0:
+	wakeup_source_unregister(mid_pmu_cxt->pmu_wake_lock);
+	return ret;
+}
+
+static void mid_pmu_remove(struct pci_dev *dev)
+{
+	/* Freeing up the irq */
+	free_irq(dev->irq, &pmu_sc_irq);
+
+	if (pmu_ops->remove)
+		pmu_ops->remove();
+
+	iounmap(mid_pmu_cxt->emergeny_emmc_up_addr);
+	mid_pmu_cxt->emergeny_emmc_up_addr = NULL;
+
+	pci_iounmap(dev, mid_pmu_cxt->pmu_reg);
+	mid_pmu_cxt->base_addr.pmu1_base = NULL;
+	mid_pmu_cxt->base_addr.pmu2_base = NULL;
+
+	/* disable the current PCI device */
+	pci_release_region(dev, 0);
+	pci_disable_device(dev);
+
+	wakeup_source_unregister(mid_pmu_cxt->pmu_wake_lock);
+}
+
+static void mid_pmu_shutdown(struct pci_dev *dev)
+{
+	dev_dbg(&mid_pmu_cxt->pmu_dev->dev, "Mid PM mid_pmu_shutdown called\n");
+
+	if (mid_pmu_cxt) {
+		down(&mid_pmu_cxt->scu_ready_sem);
+		mid_pmu_cxt->shutdown_started = true;
+		up(&mid_pmu_cxt->scu_ready_sem);
+	}
+}
+
+static struct pci_driver driver = {
+	.name = PMU_DRV_NAME,
+	.id_table = mid_pm_ids,
+	.probe = mid_pmu_probe,
+	.remove = mid_pmu_remove,
+	.shutdown = mid_pmu_shutdown
+};
+
+static int standby_enter(void)
+{
+	u32 temp = 0;
+	int s3_state = mid_state_to_sys_state(MID_S3_STATE);
+
+	if (mid_s0ix_enter(MID_S3_STATE) != MID_S3_STATE) {
+		pmu_set_s0ix_complete();
+		return -EINVAL;
+	}
+
+	/* time stamp for end of s3 entry */
+	time_stamp_for_sleep_state_latency(s3_state, false, true);
+
+	__monitor((void *) &temp, 0, 0);
+	smp_mb();
+	__mwait(mid_pmu_cxt->s3_hint, 1);
+
+	/* time stamp for start of s3 exit */
+	time_stamp_for_sleep_state_latency(s3_state, true, false);
+
+	pmu_set_s0ix_complete();
+
+	/*set wkc to appropriate value suitable for s0ix*/
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[0],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[0]);
+	writel(mid_pmu_cxt->ss_config->wake_state.wake_enable[1],
+		       &mid_pmu_cxt->pmu_reg->pm_wkc[1]);
+
+	if (platform_is(INTEL_ATOM_MRFLD))
+		up(&mid_pmu_cxt->scu_ready_sem);
+
+	return 0;
+}
+
+static int mid_suspend_begin(suspend_state_t state)
+{
+	mid_pmu_cxt->suspend_started = true;
+	pmu_s3_stats_update(1);
+	return 0;
+}
+
+static int mid_suspend_valid(suspend_state_t state)
+{
+	int ret = 0;
+
+	switch (state) {
+	case PM_SUSPEND_ON:
+	case PM_SUSPEND_MEM:
+		/* check if we are ready */
+		if (likely(pmu_initialized))
+			ret = 1;
+	break;
+	}
+
+	return ret;
+}
+
+static int mid_suspend_prepare(void)
+{
+	return 0;
+}
+
+static int mid_suspend_prepare_late(void)
+{
+	return 0;
+}
+
+static int mid_suspend_enter(suspend_state_t state)
+{
+	int ret;
+
+	if (state != PM_SUSPEND_MEM)
+		return -EINVAL;
+
+	trace_printk("s3_entry\n");
+	ret = standby_enter();
+	trace_printk("s3_exit %d\n", ret);
+	if (ret != 0)
+		dev_dbg(&mid_pmu_cxt->pmu_dev->dev,
+				"Failed to enter S3 status: %d\n", ret);
+
+	return ret;
+}
+
+static void mid_suspend_end(void)
+{
+	pmu_s3_stats_update(0);
+	mid_pmu_cxt->suspend_started = false;
+}
+
+static const struct platform_suspend_ops mid_suspend_ops = {
+	.begin = mid_suspend_begin,
+	.valid = mid_suspend_valid,
+	.prepare = mid_suspend_prepare,
+	.prepare_late = mid_suspend_prepare_late,
+	.enter = mid_suspend_enter,
+	.end = mid_suspend_end,
+};
+
+/**
+ * mid_pci_register_init - register the PMU driver as PCI device
+ */
+static int __init mid_pci_register_init(void)
+{
+	int ret;
+
+	mid_pmu_cxt = kzalloc(sizeof(struct mid_pmu_dev), GFP_KERNEL);
+
+	if (mid_pmu_cxt == NULL)
+		return -ENOMEM;
+
+	init_nc_device_states();
+
+	/* initialize the semaphores */
+	sema_init(&mid_pmu_cxt->scu_ready_sem, 1);
+
+	/* registering PCI device */
+	ret = pci_register_driver(&driver);
+	suspend_set_ops(&mid_suspend_ops);
+
+	return ret;
+}
+fs_initcall(mid_pci_register_init);
+
+void pmu_power_off(void)
+{
+	/* wait till SCU is ready */
+	if (!_pmu2_wait_not_busy())
+		writel(S5_VALUE, &mid_pmu_cxt->pmu_reg->pm_cmd);
+
+	else {
+		/* If PM_BUSY bit is not clear issue COLD_OFF */
+		WARN(1, "%s: pmu busy bit not cleared.\n", __func__);
+		rpmsg_send_generic_simple_command(IPCMSG_COLD_RESET, 1);
+	}
+}
+
+static void __exit mid_pci_cleanup(void)
+{
+	suspend_set_ops(NULL);
+
+	/* registering PCI device */
+	pci_unregister_driver(&driver);
+
+	if (mid_pmu_cxt) {
+		pmu_stats_finish();
+		kfree(mid_pmu_cxt->ss_config);
+	}
+
+	kfree(mid_pmu_cxt);
+}
+module_exit(mid_pci_cleanup);
diff --git a/arch/x86/platform/intel-mid/intel_soc_pmu.h b/arch/x86/platform/intel-mid/intel_soc_pmu.h
new file mode 100644
index 000000000000..4e94e9f7aeed
--- /dev/null
+++ b/arch/x86/platform/intel-mid/intel_soc_pmu.h
@@ -0,0 +1,507 @@
+/*
+ * intel_soc_pmu.h
+ * Copyright (c) 2012, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ *
+ */
+#ifndef _MID_PMU_H_
+#define _MID_PMU_H_
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/delay.h>
+#include <linux/debugfs.h>
+#include <linux/seq_file.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/pci.h>
+#include <linux/semaphore.h>
+#include <linux/completion.h>
+#include <linux/spinlock.h>
+#include <linux/timer.h>
+#include <linux/jhash.h>
+#include <linux/suspend.h>
+#include <linux/workqueue.h>
+#include <linux/nmi.h>
+#include <linux/pm_qos.h>
+#include <linux/pm_wakeup.h>
+#include <asm/apic.h>
+#include <asm/intel_scu_ipc.h>
+#include <linux/intel_mid_pm.h>
+
+#include "intel_soc_mdfld.h"
+#include "intel_soc_clv.h"
+#include "intel_soc_mrfld.h"
+
+#define MID_PMU_MFLD_DRV_DEV_ID                 0x0828
+#define MID_PMU_CLV_DRV_DEV_ID			0x08EC
+#define MID_PMU_MRFL_DRV_DEV_ID			0x11A1
+
+#define MID_MRFL_HDMI_DRV_DEV_ID		0x11A6
+
+/* SRAM address where PANIC START is written */
+#define PMU_PANIC_EMMC_UP_ADDR			0xFFFF3080
+#define PMU_PANIC_EMMC_UP_REQ_CMD		0xDEADBEEF
+
+#define MAX_DEVICES	(PMU1_MAX_DEVS + PMU2_MAX_DEVS)
+#define PMU_MAX_LSS_SHARE 4
+
+#define PMU2_BUSY_TIMEOUT			500000
+#define HSU0_PCI_ID				0x81c
+#define HSU1_PCI_ID				0x81b
+#define HSI_PCI_ID				0x833
+
+#define PCI_ID_ANY	(~0)
+
+#define MODE_ID_MAGIC_NUM			1
+
+#define   LOG_ID_MASK				0x7F
+#define   SUB_CLASS_MASK			0xFF00
+
+
+/* Definition for C6 Offload MSR Address */
+#define MSR_C6OFFLOAD_CTL_REG			0x120
+
+#define MSR_C6OFFLOAD_SET_LOW			1
+#define MSR_C6OFFLOAD_SET_HIGH			0
+
+#define C6OFFLOAD_BIT_MASK			0x2
+#define C6OFFLOAD_BIT				0x2
+
+#define PMU_DRV_NAME				"intel_pmu_driver"
+
+#define MID_PCI_INDEX_HASH_BITS		8 /*size 256*/
+#define MID_PCI_INDEX_HASH_SIZE		(1<<MID_PCI_INDEX_HASH_BITS)
+#define MID_PCI_INDEX_HASH_MASK		(MID_PCI_INDEX_HASH_SIZE-1)
+
+/* some random number for initvalue */
+#define	MID_PCI_INDEX_HASH_INITVALUE	0x27041975
+
+/*
+ * Values for programming the PM_CMD register based on the PM
+ * architecture speci
+*/
+
+#define S5_VALUE	0x309D2601
+#define S0I1_VALUE	0X30992601
+#define LPMP3_VALUE	0X40492601
+#define S0I3_VALUE	0X309B2601
+#define FAST_ON_OFF_VALUE	0X309E2601
+#define INTERACTIVE_VALUE	0X00002201
+#define INTERACTIVE_IOC_VALUE	0X00002301
+
+#define WAKE_ENABLE_0		0xffffffff
+#define WAKE_ENABLE_1		0xffffffff
+#define INVALID_WAKE_SRC	0xFFFF
+
+#define LOG_SS_MASK		0x80
+
+#define D0I0_MASK		0
+#define D0I1_MASK		1
+#define D0I2_MASK		2
+#define D0I3_MASK		3
+
+#define BITS_PER_LSS		2
+#define MAX_LSS_POSSIBLE	64
+#define SS_IDX_MASK		0x3
+#define SS_POS_MASK		0xF
+
+#define PMU_BASE_ADDR(pmu_num) ((pmu_num == 0) ? \
+				(u32) base_addr.pmu1_base :\
+				(u32) base_addr.pmu2_base);
+
+#define SSMSK(mask, lss) ((mask) << ((lss) * 2))
+#define SSWKC(lss) (1 << (lss))
+
+/* North Complex Power management */
+#define OSPM_PUNIT_PORT         0x04
+#define OSPM_OSPMBA             0x78
+#define OSPM_PM_SSC             0x20
+#define OSPM_PM_SSS             0x30
+
+#define OSPM_APMBA              0x7a
+#define APM_CMD                 0x0
+#define APM_STS                 0x04
+#define PM_CMD_D3_COLD		(0x1 << 21)
+
+/* Size of command logging array */
+#define LOG_SIZE	5
+
+enum sys_state {
+	SYS_STATE_S0I0,
+	SYS_STATE_S0I1,
+	SYS_STATE_S0I2,
+	SYS_STATE_S0I3,
+	SYS_STATE_S3,
+	SYS_STATE_S5,
+	SYS_STATE_MAX
+};
+
+enum int_status {
+	INVALID_INT = 0,
+	CMD_COMPLETE_INT = 1,
+	CMD_ERROR_INT = 2,
+	WAKE_RECEIVED_INT = 3,
+	SUBSYS_POW_ERR_INT = 4,
+	S0ix_MISS_INT = 5,
+	NO_ACKC6_INT = 6,
+	TRIGGERERR = 7,
+	INVALID_SRC_INT
+};
+
+enum pmu_number {
+	PMU_NUM_1,
+	PMU_NUM_2,
+	PMU_MAX_DEVS
+};
+
+enum pmu_ss_state {
+	SS_STATE_D0I0 = 0,
+	SS_STATE_D0I1 = 1,
+	SS_STATE_D0I2 = 2,
+	SS_STATE_D0I3 = 3
+};
+
+
+struct pmu_ss_states {
+	unsigned long pmu1_states;
+	unsigned long pmu2_states[4];
+};
+
+struct pci_dev_info {
+	u8 ss_pos;
+	u8 ss_idx;
+	u8 pmu_num;
+
+	u32 log_id;
+	u32 cap;
+	struct pci_dev *drv[PMU_MAX_LSS_SHARE];
+	pci_power_t power_state[PMU_MAX_LSS_SHARE];
+};
+
+struct pmu_wake_ss_states {
+	unsigned long wake_enable[2];
+	unsigned long pmu1_wake_states;
+	unsigned long pmu2_wake_states[4];
+};
+
+struct pmu_suspend_config {
+	struct pmu_ss_states ss_state;
+	struct pmu_wake_ss_states wake_state;
+};
+
+struct pci_dev_index {
+	struct pci_dev	*pdev;
+	u8		index;
+};
+
+/* PMU register interface */
+struct mrst_pmu_reg {
+	u32 pm_sts;             /* 0x00 */
+	u32 pm_cmd;             /* 0x04 */
+	u32 pm_ics;             /* 0x08 */
+	u32 _resv1;
+	u32 pm_wkc[2];          /* 0x10 */
+	u32 pm_wks[2];          /* 0x18 */
+	u32 pm_ssc[4];          /* 0x20 */
+	u32 pm_sss[4];          /* 0x30 */
+	u32 pm_wssc[4];         /* 0x40 */
+	u32 pm_c3c4;            /* 0x50 */
+	u32 pm_c5c6;            /* 0x54 */
+	u32 pm_msic;            /* 0x58 */
+};
+
+struct mid_pmu_cmd_log {
+	struct timespec ts;
+	u32 command;
+	struct pmu_ss_states pm_ssc;
+};
+
+struct mid_pmu_irq_log {
+	struct timespec ts;
+	u32 status;
+};
+
+struct mid_pmu_ipc_log {
+	struct timespec ts;
+	u32 command;
+};
+
+struct mid_pmu_pmu_irq_log {
+	struct timespec ts;
+	u8 status;
+};
+
+struct mid_pmu_ipc_irq_log {
+	struct timespec ts;
+};
+
+union pmu_pm_status {
+	struct {
+		u32 pmu_rev:8;
+		u32 pmu_busy:1;
+		u32 mode_id:4;
+		u32 Reserved:19;
+	} pmu_status_parts;
+	u32 pmu_status_value;
+};
+
+union pmu_pm_ics {
+	struct {
+		u32 int_status:8;
+		u32 int_enable:1;
+		u32 int_pend:1;
+		/* New bit added in TNG to indicate device wakes*/
+		u32 sw_int_status:1;
+		u32 reserved:21;
+	} pmu_pm_ics_parts;
+	u32 pmu_pm_ics_value;
+};
+
+struct intel_mid_base_addr {
+	u32 *pmu1_base;
+	void __iomem *pmu2_base;
+	u32 *pm_table_base;
+	u32 __iomem *offload_reg;
+};
+
+#define MAX_PMU_LOG_STATES	(S0I3_STATE_IDX - C4_STATE_IDX + 1)
+
+struct mid_pmu_stats {
+	u64 err_count[3];
+	u64 count;
+	u64 time;
+	u64 last_entry;
+	u64 last_try;
+	u64 first_entry;
+	u32 demote_count[MAX_PMU_LOG_STATES];
+	u32 display_blocker_count;
+	u32 camera_blocker_count;
+	u32 blocker_count[MAX_LSS_POSSIBLE];
+};
+
+struct device_residency {
+	u64 d0i0_entry;
+	u64 d0i3_entry;
+	u64 d0i0_acc;
+	u64 d0i3_acc;
+	u64 start;
+	pci_power_t state;
+};
+
+struct mid_pmu_dev {
+	bool suspend_started;
+	bool shutdown_started;
+	bool camera_off;
+	bool display_off;
+
+	u32 apm_base;
+	u32 ospm_base;
+	u32 pmu1_max_devs;
+	u32 pmu2_max_devs;
+	u32 ss_per_reg;
+	u32 d0ix_stat[MAX_LSS_POSSIBLE][SS_STATE_D0I3+1];
+	u32 num_wakes[MAX_DEVICES][SYS_STATE_MAX];
+	u32 ignore_lss[4];
+	u32 os_sss[4];
+#ifdef CONFIG_PM_DEBUG
+	u32 cstate_ignore;
+	struct pm_qos_request *cstate_qos;
+#endif
+
+	u32 __iomem *emergeny_emmc_up_addr;
+	u64 pmu_init_time;
+
+	int cmd_error_int;
+	int s0ix_possible;
+	int s0ix_entered;
+
+#ifdef LOG_PMU_EVENTS
+	int cmd_log_idx;
+	int ipc_log_idx;
+	int ipc_irq_log_idx;
+	int pmu_irq_log_idx;
+#endif
+
+	enum sys_state  pmu_current_state;
+
+	struct pci_dev_info pci_devs[MAX_DEVICES];
+	struct pci_dev_index
+		pci_dev_hash[MID_PCI_INDEX_HASH_SIZE];
+	struct intel_mid_base_addr base_addr;
+	struct mrst_pmu_reg	__iomem *pmu_reg;
+	struct semaphore scu_ready_sem;
+	struct mid_pmu_stats pmu_stats[SYS_STATE_MAX];
+	struct device_residency pmu_dev_res[MAX_DEVICES];
+	struct delayed_work log_work;
+
+#ifdef LOG_PMU_EVENTS
+	struct mid_pmu_cmd_log cmd_log[LOG_SIZE];
+	struct mid_pmu_ipc_log ipc_log[LOG_SIZE];
+	struct mid_pmu_ipc_irq_log ipc_irq_log[LOG_SIZE];
+	struct mid_pmu_pmu_irq_log pmu_irq_log[LOG_SIZE];
+#endif
+	struct wakeup_source *pmu_wake_lock;
+
+	struct pmu_suspend_config *ss_config;
+	struct pci_dev *pmu_dev;
+
+	spinlock_t nc_ready_lock;
+
+	int s3_hint;
+};
+
+struct platform_pmu_ops {
+	int (*init)(void);
+	void (*prepare)(int);
+	bool (*enter)(int);
+	void (*wakeup)(void);
+	void (*remove)(void);
+	pci_power_t (*pci_choose_state) (int);
+	void (*set_power_state_ops) (int);
+	void (*set_s0ix_complete) (void);
+	int (*nc_set_power_state) (int, int, int, int *);
+};
+
+extern char s0ix[5];
+extern struct platform_pmu_ops mfld_pmu_ops;
+extern struct platform_pmu_ops clv_pmu_ops;
+extern struct platform_pmu_ops mrfld_pmu_ops;
+extern struct platform_pmu_ops *get_platform_ops(void);
+extern void mfld_s0ix_sram_save_cleanup(void);
+extern void pmu_stats_init(void);
+extern void pmu_s3_stats_update(int enter);
+extern void pmu_stats_finish(void);
+extern void mfld_s0ix_sram_restore(u32 s0ix);
+extern void pmu_stat_error(u8 err_type);
+extern void pmu_stat_end(void);
+extern void pmu_stat_start(enum sys_state type);
+extern int pmu_pci_to_indexes(struct pci_dev *pdev, int *index,
+				int *pmu_num, int *ss_idx, int *ss_pos);
+extern struct mid_pmu_dev *mid_pmu_cxt;
+extern void platform_set_pmu_ops(void);
+extern void pmu_read_sss(struct pmu_ss_states *pm_ssc);
+extern int pmu_issue_interactive_command(struct pmu_ss_states *pm_ssc,
+				bool ioc, bool d3_cold);
+extern int _pmu2_wait_not_busy(void);
+extern u32 get_s0ix_val_set_pm_ssc(int);
+extern int pmu_get_wake_source(void);
+extern bool pmu_initialized;
+extern struct platform_pmu_ops *pmu_ops;
+extern void platform_update_all_lss_states(struct pmu_ss_states *, int *);
+extern int set_extended_cstate_mode(const char *val, struct kernel_param *kp);
+extern int get_extended_cstate_mode(char *buffer, struct kernel_param *kp);
+extern int byt_pmu_nc_set_power_state(int islands, int state_type, int reg);
+extern int byt_pmu_nc_get_power_state(int islands, int reg);
+
+#ifdef LOG_PMU_EVENTS
+extern void pmu_log_pmu_irq(int status);
+extern void pmu_log_command(u32 command, struct pmu_ss_states *pm_ssc);
+extern void pmu_dump_logs(void);
+#endif
+
+/* Accessor function for pci_devs start */
+static inline void pmu_stat_clear(void)
+{
+	mid_pmu_cxt->pmu_current_state = SYS_STATE_S0I0;
+}
+
+static inline struct pci_dev *get_mid_pci_drv(int lss_index, int i)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].drv[i];
+}
+
+static inline pci_power_t get_mid_pci_power_state(int lss_index, int i)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].power_state[i];
+}
+
+static inline u8 get_mid_pci_ss_idx(int lss_index)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].ss_idx & SS_IDX_MASK;
+}
+
+static inline u8 get_mid_pci_ss_pos(int lss_index)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].ss_pos & SS_POS_MASK;
+}
+
+static inline u8 get_mid_pci_pmu_num(int lss_index)
+{
+	return mid_pmu_cxt->pci_devs[lss_index].pmu_num;
+}
+
+static inline void set_mid_pci_drv(int lss_index,
+					int i, struct pci_dev *pdev)
+{
+	mid_pmu_cxt->pci_devs[lss_index].drv[i] = pdev;
+}
+
+static inline void set_mid_pci_power_state(int lss_index,
+					int i, pci_power_t state)
+{
+	mid_pmu_cxt->pci_devs[lss_index].power_state[i] = state;
+}
+
+static inline void set_mid_pci_ss_idx(int lss_index, u8 ss_idx)
+{
+	mid_pmu_cxt->pci_devs[lss_index].ss_idx = ss_idx;
+}
+
+static inline void set_mid_pci_ss_pos(int lss_index, u8 ss_pos)
+{
+	mid_pmu_cxt->pci_devs[lss_index].ss_pos = ss_pos;
+}
+
+static inline void set_mid_pci_pmu_num(int lss_index, u8 pmu_num)
+{
+	mid_pmu_cxt->pci_devs[lss_index].pmu_num = pmu_num;
+}
+
+static inline void set_mid_pci_log_id(int lss_index, u32 log_id)
+{
+	mid_pmu_cxt->pci_devs[lss_index].log_id = log_id;
+}
+
+static inline void set_mid_pci_cap(int lss_index, u32 cap)
+{
+	mid_pmu_cxt->pci_devs[lss_index].cap = cap;
+}
+
+static inline u32 get_d0ix_stat(int lss_index, int state)
+{
+	return mid_pmu_cxt->d0ix_stat[lss_index][state];
+}
+
+static inline void inc_d0ix_stat(int lss_index, int state)
+{
+	mid_pmu_cxt->d0ix_stat[lss_index][state]++;
+}
+
+static inline void clear_d0ix_stats(void)
+{
+	memset(mid_pmu_cxt->d0ix_stat, 0, sizeof(mid_pmu_cxt->d0ix_stat));
+}
+
+/* Accessor functions for pci_devs end */
+
+static inline bool nc_device_state(void)
+{
+	return !mid_pmu_cxt->display_off || !mid_pmu_cxt->camera_off;
+}
+
+#endif
diff --git a/drivers/pci/Makefile b/drivers/pci/Makefile
index 0c3efcffa83b..5651527c6358 100644
--- a/drivers/pci/Makefile
+++ b/drivers/pci/Makefile
@@ -34,6 +34,7 @@ obj-$(CONFIG_PCI_IOV) += iov.o
 # Some architectures use the generic PCI setup functions
 #
 obj-$(CONFIG_X86) += setup-bus.o
+obj-$(CONFIG_ATOM_SOC_POWER) += pci-atom_soc.o
 obj-$(CONFIG_ALPHA) += setup-bus.o setup-irq.o
 obj-$(CONFIG_ARM) += setup-bus.o setup-irq.o
 obj-$(CONFIG_UNICORE32) += setup-bus.o setup-irq.o
diff --git a/drivers/pci/pci-atom_soc.c b/drivers/pci/pci-atom_soc.c
new file mode 100644
index 000000000000..edc3e2337ba6
--- /dev/null
+++ b/drivers/pci/pci-atom_soc.c
@@ -0,0 +1,78 @@
+/*
+ * pci-atom_soc.c - register Intel MID PCI plaform ops
+ *
+ * Copyright (c) 2013, Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify it
+ * under the terms and conditions of the GNU General Public License,
+ * version 2, as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope it will be useful, but WITHOUT
+ * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
+ * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for
+ * more details.
+ *
+ * You should have received a copy of the GNU General Public License along with
+ * this program; if not, write to the Free Software Foundation, Inc.,
+ * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.
+ */
+
+#include <linux/init.h>
+#include <linux/intel_mid_pm.h>
+#include <linux/kernel.h>
+
+#include "pci.h"
+
+static bool mid_pci_power_manageable(struct pci_dev *dev)
+{
+	return true;
+}
+
+static pci_power_t mid_pci_choose_state(struct pci_dev *pdev)
+{
+	return PCI_D3hot;
+}
+
+static int mid_pci_sleep_wake(struct pci_dev *dev, bool enable)
+{
+	return 0;
+}
+
+static int mid_pci_run_wake(struct pci_dev *dev, bool enable)
+{
+	return 0;
+}
+
+static struct pci_platform_pm_ops mid_pci_platform_pm = {
+	.is_manageable = mid_pci_power_manageable,
+	.choose_state = mid_pci_choose_state,
+	.sleep_wake = mid_pci_sleep_wake,
+	.run_wake = mid_pci_run_wake,
+	.set_state = pmu_pci_set_power_state,
+	.choose_state = pmu_pci_choose_state,
+};
+
+/**
+ * mid_pci_init - It registers callback function for all the PCI devices
+ * for platform specific device power on/shutdown acticities.
+ */
+static int __init mid_pci_init(void)
+{
+	if (boot_cpu_data.x86 != 6)
+		return 0;
+
+	/*
+	 * n.b. this model check does not uniquely identify the platform,
+	 * and additional checks are necessary inside the pmu driver
+	 */
+	switch (boot_cpu_data.x86_model) {
+	case INTEL_ATOM_MFLD:
+	case INTEL_ATOM_CLV:
+	case INTEL_ATOM_MRFLD:
+		pci_set_platform_pm(&mid_pci_platform_pm);
+		break;
+	}
+
+	return 0;
+}
+arch_initcall(mid_pci_init);
-- 
2.37.3

